  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2020-11-11 14:59:11,811] {__init__.py:50} INFO - Using executor CeleryExecutor
[2020-11-11 14:59:11,818] {scheduler_job.py:1367} INFO - Starting the scheduler
[2020-11-11 14:59:11,818] {scheduler_job.py:1375} INFO - Running execute loop for -1 seconds
[2020-11-11 14:59:11,818] {scheduler_job.py:1376} INFO - Processing each file at most -1 times
[2020-11-11 14:59:11,818] {scheduler_job.py:1379} INFO - Searching for files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-11 14:59:11,820] {scheduler_job.py:1381} INFO - There are 25 files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-11 14:59:11,821] {scheduler_job.py:1438} INFO - Resetting orphaned tasks for active dag runs
[2020-11-11 14:59:11,827] {dag_processing.py:562} INFO - Launched DagFileProcessorManager with pid: 71040
[2020-11-11 14:59:11,830] {settings.py:55} INFO - Configured default timezone <Timezone [UTC]>
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2020-11-11 15:25:25,614] {__init__.py:50} INFO - Using executor CeleryExecutor
[2020-11-11 15:25:25,638] {scheduler_job.py:1367} INFO - Starting the scheduler
[2020-11-11 15:25:25,638] {scheduler_job.py:1375} INFO - Running execute loop for -1 seconds
[2020-11-11 15:25:25,638] {scheduler_job.py:1376} INFO - Processing each file at most -1 times
[2020-11-11 15:25:25,638] {scheduler_job.py:1379} INFO - Searching for files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-11 15:25:25,671] {scheduler_job.py:1381} INFO - There are 25 files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-11 15:25:25,673] {scheduler_job.py:1438} INFO - Resetting orphaned tasks for active dag runs
[2020-11-11 15:25:25,694] {dag_processing.py:562} INFO - Launched DagFileProcessorManager with pid: 5172
[2020-11-11 15:25:25,699] {settings.py:55} INFO - Configured default timezone <Timezone [UTC]>
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2020-11-11 15:45:59,703] {__init__.py:50} INFO - Using executor CeleryExecutor
[2020-11-11 15:45:59,710] {scheduler_job.py:1367} INFO - Starting the scheduler
[2020-11-11 15:45:59,710] {scheduler_job.py:1375} INFO - Running execute loop for -1 seconds
[2020-11-11 15:45:59,710] {scheduler_job.py:1376} INFO - Processing each file at most -1 times
[2020-11-11 15:45:59,710] {scheduler_job.py:1379} INFO - Searching for files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-11 15:45:59,712] {scheduler_job.py:1381} INFO - There are 26 files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-11 15:45:59,713] {scheduler_job.py:1438} INFO - Resetting orphaned tasks for active dag runs
[2020-11-11 15:45:59,719] {dag_processing.py:562} INFO - Launched DagFileProcessorManager with pid: 10153
[2020-11-11 15:45:59,721] {settings.py:55} INFO - Configured default timezone <Timezone [UTC]>
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2020-11-11 15:55:13,052] {__init__.py:50} INFO - Using executor CeleryExecutor
[2020-11-11 15:55:13,060] {scheduler_job.py:1367} INFO - Starting the scheduler
[2020-11-11 15:55:13,060] {scheduler_job.py:1375} INFO - Running execute loop for -1 seconds
[2020-11-11 15:55:13,060] {scheduler_job.py:1376} INFO - Processing each file at most -1 times
[2020-11-11 15:55:13,060] {scheduler_job.py:1379} INFO - Searching for files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-11 15:55:13,063] {scheduler_job.py:1381} INFO - There are 26 files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-11 15:55:13,063] {scheduler_job.py:1438} INFO - Resetting orphaned tasks for active dag runs
[2020-11-11 15:55:13,069] {dag_processing.py:562} INFO - Launched DagFileProcessorManager with pid: 12815
[2020-11-11 15:55:13,071] {settings.py:55} INFO - Configured default timezone <Timezone [UTC]>
[2020-11-11 16:15:40,271] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:00:00+00:00 [scheduled]>
[2020-11-11 16:15:40,274] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-11 16:15:40,274] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:15:40,276] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:00:00+00:00 [scheduled]>
[2020-11-11 16:15:40,283] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:00:00+00:00 [queued]>
[2020-11-11 16:15:40,284] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 0, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:15:40,284] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T00:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:15:52,303] {scheduler_job.py:961} INFO - 11 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:00:00+00:00 [scheduled]>
[2020-11-11 16:15:52,313] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 11 task instances ready to be queued
[2020-11-11 16:15:52,314] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:15:52,315] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:15:52,315] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:15:52,316] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:15:52,316] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:15:52,317] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:15:52,317] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:15:52,318] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:15:52,318] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:15:52,319] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:15:52,319] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:15:52,328] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:00:00+00:00 [scheduled]>
[2020-11-11 16:15:52,360] {scheduler_job.py:1158} INFO - Setting the following 11 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:00:00+00:00 [queued]>
[2020-11-11 16:15:52,360] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 0, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:15:52,360] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T00:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:15:52,360] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 0, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:15:52,361] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T00:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:15:52,361] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 0, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:15:52,361] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T00:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:15:52,361] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 0, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:15:52,361] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T00:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:15:52,362] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 0, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:15:52,362] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T00:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:15:52,362] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 0, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:15:52,362] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T00:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:15:52,362] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 0, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:15:52,362] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T00:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:15:52,362] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 0, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:15:52,363] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T00:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:15:52,363] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 0, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:15:52,363] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T00:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:15:52,363] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 0, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:15:52,363] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T00:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:15:52,363] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 0, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:15:52,364] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T00:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:15:52,502] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 00:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:04,319] {scheduler_job.py:961} INFO - 11 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:05:00+00:00 [scheduled]>
[2020-11-11 16:16:04,323] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 123 open slots and 11 task instances ready to be queued
[2020-11-11 16:16:04,324] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:16:04,324] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:16:04,324] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:16:04,324] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:16:04,324] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:16:04,325] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:16:04,325] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:16:04,325] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:16:04,325] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:16:04,325] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:16:04,326] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:16:04,329] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:05:00+00:00 [scheduled]>
[2020-11-11 16:16:04,343] {scheduler_job.py:1158} INFO - Setting the following 11 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:05:00+00:00 [queued]>
[2020-11-11 16:16:04,343] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 0, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:16:04,343] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T00:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:04,343] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 0, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:04,343] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T00:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:04,344] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 0, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:04,344] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T00:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:04,344] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 0, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:04,344] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T00:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:04,344] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 0, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:04,344] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T00:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:04,344] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 0, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:04,344] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T00:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:04,344] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 0, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:04,344] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T00:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:04,345] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 0, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:04,345] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T00:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:04,345] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 0, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:04,345] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T00:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:04,345] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 0, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:04,345] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T00:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:04,345] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 0, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:04,345] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T00:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:04,515] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 00:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:16,304] {scheduler_job.py:961} INFO - 12 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:10:00+00:00 [scheduled]>
[2020-11-11 16:16:16,307] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 122 open slots and 12 task instances ready to be queued
[2020-11-11 16:16:16,307] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:16:16,307] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:16:16,307] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:16:16,307] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:16:16,307] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:16:16,307] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:16:16,307] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:16:16,308] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:16:16,308] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:16:16,308] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:16:16,308] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:16:16,308] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:16:16,308] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:16:16,308] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:16:16,310] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:10:00+00:00 [scheduled]>
[2020-11-11 16:16:16,322] {scheduler_job.py:1158} INFO - Setting the following 10 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:10:00+00:00 [queued]>
[2020-11-11 16:16:16,322] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 0, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:16:16,322] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T00:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:16,322] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 0, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:16,322] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T00:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:16,323] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 0, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:16,323] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T00:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:16,323] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 0, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:16,323] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T00:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:16,323] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 0, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:16,323] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T00:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:16,323] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 0, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:16,323] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T00:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:16,323] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 0, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:16,323] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T00:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:16,324] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 0, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:16,324] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T00:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:16,324] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 0, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:16,324] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T00:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:16,324] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 0, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:16,324] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T00:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:16,553] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 00:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:16,556] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 00:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:16,559] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 00:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:16,562] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 00:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:16,565] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 00:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:16,582] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 00:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:16,585] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 00:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:16,587] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 00:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:16,590] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 00:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:16,599] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 00:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:16,607] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 00:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:28,313] {scheduler_job.py:961} INFO - 14 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:15:00+00:00 [scheduled]>
[2020-11-11 16:16:28,316] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 124 open slots and 14 task instances ready to be queued
[2020-11-11 16:16:28,316] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:16:28,316] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:16:28,316] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:16:28,316] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:16:28,316] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:16:28,316] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:16:28,316] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:16:28,317] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:16:28,317] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:16:28,317] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:16:28,317] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:16:28,317] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:16:28,317] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:16:28,317] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:16:28,317] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:16:28,317] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:16:28,319] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:15:00+00:00 [scheduled]>
[2020-11-11 16:16:28,332] {scheduler_job.py:1158} INFO - Setting the following 12 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:15:00+00:00 [queued]>
[2020-11-11 16:16:28,333] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 0, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:16:28,333] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T00:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:28,333] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 0, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:28,333] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T00:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:28,333] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 0, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:28,333] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T00:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:28,333] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 0, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:28,333] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T00:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:28,334] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 0, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:28,334] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T00:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:28,334] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 0, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:28,334] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T00:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:28,334] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 0, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:28,335] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T00:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:28,335] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 0, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:28,335] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T00:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:28,336] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 0, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:28,336] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T00:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:28,336] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 0, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:28,336] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T00:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:28,337] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 0, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:28,337] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T00:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:28,337] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 0, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:28,337] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T00:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:28,541] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 00:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:28,544] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 00:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:28,545] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 00:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:28,547] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 00:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:28,548] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 00:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:28,550] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 00:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:28,553] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 00:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:28,557] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 00:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:28,564] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 00:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:28,574] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 00:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:28,582] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 00:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:40,346] {scheduler_job.py:961} INFO - 13 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:20:00+00:00 [scheduled]>
[2020-11-11 16:16:40,358] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 119 open slots and 13 task instances ready to be queued
[2020-11-11 16:16:40,359] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:16:40,359] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:16:40,360] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:16:40,360] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:16:40,361] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:16:40,361] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:16:40,362] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:16:40,362] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:16:40,362] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:16:40,363] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:16:40,364] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:16:40,364] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:16:40,365] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:16:40,365] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:16:40,366] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:16:40,367] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:16:40,367] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:16:40,368] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:16:40,368] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:16:40,379] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:20:00+00:00 [scheduled]>
[2020-11-11 16:16:40,402] {scheduler_job.py:1158} INFO - Setting the following 7 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:20:00+00:00 [queued]>
[2020-11-11 16:16:40,402] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 0, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:16:40,403] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T00:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:40,403] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 0, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:40,403] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T00:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:40,404] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 0, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:40,404] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T00:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:40,404] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 0, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:40,404] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T00:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:40,405] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 0, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:40,405] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T00:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:40,405] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 0, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:40,405] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T00:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:40,406] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 0, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:40,406] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T00:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:40,581] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 00:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:40,584] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 00:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:40,586] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 00:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:40,589] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 00:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:40,591] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 00:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:40,602] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 00:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:40,604] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 00:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:40,607] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 00:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:40,610] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 00:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:40,612] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 00:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:52,363] {scheduler_job.py:961} INFO - 19 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:25:00+00:00 [scheduled]>
[2020-11-11 16:16:52,375] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 19 task instances ready to be queued
[2020-11-11 16:16:52,376] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:16:52,376] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:16:52,377] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:16:52,377] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:16:52,378] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:16:52,378] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:16:52,379] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:16:52,379] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:16:52,379] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:16:52,380] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:16:52,380] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:16:52,380] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:16:52,381] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:16:52,381] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:16:52,381] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:16:52,382] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:16:52,382] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:16:52,382] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:16:52,383] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:16:52,383] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:16:52,383] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:16:52,384] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:16:52,389] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:00:00+00:00 [scheduled]>
[2020-11-11 16:16:52,414] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:25:00+00:00 [queued]>
[2020-11-11 16:16:52,415] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 0, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:16:52,415] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T00:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:52,415] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 0, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:16:52,415] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T00:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:52,416] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 0, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:52,416] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T00:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:52,416] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 0, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:52,416] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T00:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:52,416] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 0, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:52,416] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T00:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:52,417] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 0, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:52,417] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T00:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:52,417] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 0, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:52,417] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T00:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:52,417] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 0, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:52,417] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T00:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:52,418] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 0, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:52,418] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T00:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:52,418] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 0, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:52,418] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T00:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:52,418] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 0, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:52,418] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T00:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:52,418] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 0, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:52,419] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T00:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:52,419] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 0, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:52,419] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T00:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:52,419] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 0, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:52,419] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T00:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:52,420] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 0, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:52,420] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T00:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:52,420] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 0, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:16:52,420] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T00:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:16:52,674] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 00:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:52,678] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 00:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:52,680] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 00:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:52,682] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 00:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:52,687] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 00:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:52,690] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 00:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:52,696] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 00:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:52,703] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 00:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:52,707] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 00:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:52,715] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 00:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:52,720] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 00:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:16:52,728] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 00:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:04,371] {scheduler_job.py:961} INFO - 14 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:30:00+00:00 [scheduled]>
[2020-11-11 16:17:04,378] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 115 open slots and 14 task instances ready to be queued
[2020-11-11 16:17:04,378] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:17:04,379] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:17:04,379] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:17:04,379] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:04,379] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:04,379] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:04,380] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:04,380] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:04,380] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:04,380] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:04,380] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:04,380] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:04,381] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:04,381] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:04,381] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:04,381] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:04,381] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:04,382] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:04,382] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:04,382] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:04,382] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:04,382] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:04,382] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:04,383] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:04,383] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:04,387] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:30:00+00:00 [scheduled]>
[2020-11-11 16:17:04,397] {scheduler_job.py:1158} INFO - Setting the following 3 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:30:00+00:00 [queued]>
[2020-11-11 16:17:04,398] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 0, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:17:04,398] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T00:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:04,398] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 0, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:04,398] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T00:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:04,398] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 0, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:04,398] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T00:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:04,532] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 00:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:04,536] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 00:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:04,539] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 00:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:04,542] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 00:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:04,547] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 00:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:04,550] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 00:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:04,552] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 00:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:04,555] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 00:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:16,381] {scheduler_job.py:961} INFO - 24 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:35:00+00:00 [scheduled]>
[2020-11-11 16:17:16,387] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 24 task instances ready to be queued
[2020-11-11 16:17:16,387] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:17:16,387] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:17:16,388] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:17:16,388] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:17:16,388] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:17:16,388] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:17:16,388] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:17:16,389] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:17:16,389] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:17:16,389] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:17:16,389] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:17:16,389] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:17:16,389] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:17:16,390] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:17:16,390] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:17:16,390] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:17:16,390] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:16,390] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:16,390] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:16,391] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:16,391] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:16,391] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:16,391] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:16,391] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:16,391] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:16,391] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:16,392] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:16,392] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:16,392] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:16,392] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:16,392] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:16,392] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:16,396] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:35:00+00:00 [scheduled]>
[2020-11-11 16:17:16,416] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:30:00+00:00 [queued]>
[2020-11-11 16:17:16,416] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 0, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:17:16,416] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T00:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:16,416] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 0, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:16,416] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T00:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:16,417] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 0, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:16,417] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T00:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:16,417] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 0, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:16,417] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T00:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:16,417] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 0, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:16,417] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T00:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:16,417] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 0, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:16,417] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T00:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:16,417] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 0, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:16,418] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T00:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:16,418] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 0, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:16,418] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T00:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:16,418] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 0, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:16,418] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T00:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:16,418] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 0, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:16,418] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T00:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:16,418] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 0, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:16,419] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T00:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:16,419] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 0, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:16,419] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T00:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:16,419] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 0, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:16,419] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T00:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:16,419] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 0, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:16,419] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T00:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:16,419] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 0, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:16,419] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T00:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:16,419] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 0, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:16,420] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T00:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:16,643] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 00:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:16,648] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 00:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:16,650] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 00:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:16,651] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 00:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:16,653] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 00:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:16,662] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 00:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:16,672] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 00:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:16,677] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 00:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:16,687] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 00:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:16,698] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 00:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:16,710] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 00:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:16,721] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 00:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:16,729] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 00:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:16,731] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 00:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:16,733] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 00:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:28,370] {scheduler_job.py:961} INFO - 19 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:40:00+00:00 [scheduled]>
[2020-11-11 16:17:28,373] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 114 open slots and 19 task instances ready to be queued
[2020-11-11 16:17:28,373] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:17:28,374] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:17:28,374] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:28,374] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:28,374] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:28,374] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:28,374] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:28,374] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:28,374] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:28,375] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:28,375] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:28,375] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:28,375] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:28,376] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:28,376] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:28,376] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:28,376] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:28,376] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:28,376] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:28,376] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:28,376] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:28,376] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:28,377] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:28,377] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:28,377] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:28,377] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:28,377] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:28,377] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:28,377] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:28,377] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:28,377] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:28,377] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:28,378] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:28,378] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:28,378] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:28,378] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:28,381] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:35:00+00:00 [scheduled]>
[2020-11-11 16:17:28,389] {scheduler_job.py:1158} INFO - Setting the following 2 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:35:00+00:00 [queued]>
[2020-11-11 16:17:28,390] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 0, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:17:28,390] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T00:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:28,391] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 0, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:28,392] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T00:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:28,500] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 00:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:28,503] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 00:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:28,505] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 00:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:42,415] {scheduler_job.py:961} INFO - 29 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:45:00+00:00 [scheduled]>
[2020-11-11 16:17:42,425] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 29 task instances ready to be queued
[2020-11-11 16:17:42,426] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:17:42,426] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:17:42,427] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:17:42,427] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:17:42,427] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:17:42,427] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:17:42,427] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:17:42,428] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:17:42,428] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:17:42,428] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:17:42,428] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:17:42,429] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:17:42,429] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:17:42,429] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:17:42,429] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:17:42,430] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:17:42,430] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:42,430] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:42,430] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:42,431] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:42,431] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:42,431] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:42,431] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:42,432] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:42,432] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:42,432] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:42,432] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:42,432] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:42,432] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:42,433] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:42,433] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:42,433] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:42,433] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:42,433] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:42,433] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:42,433] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:42,434] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:42,434] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:42,434] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:42,434] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:42,435] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:42,435] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:42,439] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:45:00+00:00 [scheduled]>
[2020-11-11 16:17:42,458] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:40:00+00:00 [queued]>
[2020-11-11 16:17:42,458] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 0, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:17:42,458] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T00:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:42,458] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 0, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:42,458] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T00:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:42,459] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 0, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:42,459] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T00:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:42,459] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 0, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:42,459] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T00:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:42,459] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 0, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:42,459] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T00:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:42,459] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 0, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:42,459] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T00:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:42,460] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 0, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:42,460] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T00:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:42,460] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 0, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:42,460] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T00:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:42,460] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 0, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:42,460] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T00:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:42,460] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 0, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:42,460] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T00:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:42,460] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 0, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:42,460] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T00:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:42,461] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 0, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:42,461] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T00:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:42,461] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 0, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:42,461] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T00:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:42,461] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 0, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:42,461] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T00:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:42,461] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 0, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:42,461] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T00:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:42,461] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 0, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:42,461] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T00:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:42,749] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 00:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:42,752] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 00:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:42,754] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 00:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:42,755] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 00:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:42,758] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 00:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:42,760] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 00:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:42,766] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 00:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:42,785] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 00:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:42,789] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 00:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:42,803] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 00:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:42,817] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 00:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:42,827] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 00:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:42,835] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 00:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:42,843] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 00:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:42,861] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 00:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:42,877] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 00:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:54,426] {scheduler_job.py:961} INFO - 24 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:50:00+00:00 [scheduled]>
[2020-11-11 16:17:54,433] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 116 open slots and 24 task instances ready to be queued
[2020-11-11 16:17:54,434] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:17:54,434] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:17:54,434] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:17:54,434] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:17:54,434] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:54,435] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:54,435] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:54,435] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:54,435] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:54,435] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:54,436] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:54,436] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:54,436] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:54,436] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:54,436] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:54,436] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:54,437] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:54,437] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:54,437] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:54,437] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:54,437] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:54,437] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:54,438] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:54,438] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:54,438] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:54,438] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:54,438] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:54,439] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:54,439] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:54,439] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:54,439] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:54,439] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:54,439] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:54,439] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:54,440] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:54,440] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:54,440] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:54,440] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:54,440] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:54,440] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:54,440] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:54,441] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:54,441] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:17:54,441] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:17:54,444] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:45:00+00:00 [scheduled]>
[2020-11-11 16:17:54,453] {scheduler_job.py:1158} INFO - Setting the following 4 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 00:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:45:00+00:00 [queued]>
[2020-11-11 16:17:54,454] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 0, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:17:54,454] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T00:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:54,454] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 0, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:54,454] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T00:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:54,454] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 0, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:54,454] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T00:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:54,454] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 0, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:17:54,454] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T00:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:17:54,577] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 00:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:17:54,580] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 00:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:06,422] {scheduler_job.py:961} INFO - 33 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:55:00+00:00 [scheduled]>
[2020-11-11 16:18:06,428] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 33 task instances ready to be queued
[2020-11-11 16:18:06,429] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:18:06,429] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:18:06,429] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:18:06,429] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:18:06,430] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:18:06,430] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:18:06,430] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:18:06,430] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:18:06,430] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:18:06,430] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:18:06,431] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:18:06,431] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:18:06,431] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:18:06,431] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:18:06,431] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:18:06,432] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:18:06,432] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:06,432] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:06,432] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:06,433] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:06,433] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:06,433] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:06,433] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:06,433] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:06,434] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:06,434] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:06,436] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:06,437] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:06,437] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:06,437] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:06,438] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:06,438] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:06,439] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:06,439] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:06,439] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:06,439] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:06,440] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:06,440] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:06,440] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:06,440] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:06,440] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:06,440] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:06,441] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:06,441] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:06,441] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:06,441] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:06,441] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:06,442] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:06,442] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:06,442] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:06,446] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:55:00+00:00 [scheduled]>
[2020-11-11 16:18:06,466] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 00:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:50:00+00:00 [queued]>
[2020-11-11 16:18:06,466] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 1, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:18:06,467] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T01:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:06,467] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 0, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:06,467] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T00:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:06,467] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 0, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:06,467] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T00:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:06,467] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 0, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:06,467] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T00:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:06,467] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 0, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:06,467] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T00:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:06,468] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 0, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:06,468] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T00:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:06,468] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 0, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:06,468] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T00:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:06,468] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 0, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:06,468] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T00:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:06,468] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 0, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:06,468] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T00:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:06,468] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 0, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:06,469] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T00:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:06,469] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 0, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:06,469] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T00:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:06,469] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 0, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:06,469] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T00:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:06,469] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 0, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:06,469] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T00:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:06,469] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 0, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:06,469] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T00:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:06,469] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 0, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:06,469] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T00:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:06,470] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 0, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:06,470] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T00:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:06,700] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 00:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:06,703] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 00:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:06,705] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 00:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:06,707] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 00:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:06,708] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 00:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:06,710] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 00:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:06,718] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 00:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:06,729] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 00:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:06,745] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 00:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:06,750] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 00:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:06,761] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 00:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:06,774] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 00:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:06,775] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 00:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:06,779] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 00:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:06,788] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 00:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:06,798] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 00:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:18,449] {scheduler_job.py:961} INFO - 28 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:00:00+00:00 [scheduled]>
[2020-11-11 16:18:18,454] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 28 task instances ready to be queued
[2020-11-11 16:18:18,468] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:18:18,469] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:18,469] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:18,470] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:18,470] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:18,471] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:18,471] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:18,472] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:18,472] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:18,473] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:18,473] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:18,474] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:18,474] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:18,475] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:18,475] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:18,476] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:18,476] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:18,477] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:18,477] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:18,478] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:18,478] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:18,479] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:18,479] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:18,479] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:18,480] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:18,480] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:18,481] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:18,481] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:18,482] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:18,482] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:18,482] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:18,483] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:18,483] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:18,484] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:18,484] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:18,485] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:18,485] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:18,486] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:18,486] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:18,486] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:18,487] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:18,487] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:18,488] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:18,488] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:18,489] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:18,489] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:18,489] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:18,490] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:18,490] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:18,491] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:18,491] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:18,492] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:18,493] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:18,494] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:18,495] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:18,507] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:05:00+00:00 [scheduled]>
[2020-11-11 16:18:18,526] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:05:00+00:00 [queued]>
[2020-11-11 16:18:18,526] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 1, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:18:18,526] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T01:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:18,602] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 00:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:18,605] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 00:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:18,606] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 00:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:18,608] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 01:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:30,458] {scheduler_job.py:961} INFO - 40 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:05:00+00:00 [scheduled]>
[2020-11-11 16:18:30,466] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 40 task instances ready to be queued
[2020-11-11 16:18:30,467] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:18:30,467] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:18:30,467] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:18:30,468] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:18:30,468] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:18:30,468] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:18:30,468] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:18:30,469] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:18:30,469] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:18:30,469] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:18:30,469] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:18:30,469] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:18:30,470] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:18:30,470] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:18:30,470] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:18:30,470] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:18:30,471] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:30,471] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:30,471] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:30,471] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:30,471] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:30,472] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:30,472] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:30,472] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:30,472] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:30,472] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:30,472] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:30,473] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:30,473] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:30,473] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:30,473] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:30,473] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:30,473] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:30,474] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:30,474] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:30,474] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:30,474] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:30,474] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:30,475] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:30,475] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:30,475] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:30,475] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:30,475] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:30,475] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:30,476] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:30,476] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:30,476] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:30,476] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:30,476] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:30,476] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:30,477] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:30,477] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:30,477] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:30,477] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:30,477] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:30,477] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:30,477] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:30,478] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:30,478] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:30,478] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:30,478] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:30,478] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:30,478] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:30,478] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:30,482] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:00:00+00:00 [scheduled]>
[2020-11-11 16:18:30,497] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 00:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 00:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 00:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 00:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 00:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 00:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 00:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 00:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 00:55:00+00:00 [queued]>
[2020-11-11 16:18:30,497] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 1, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:18:30,498] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T01:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:30,498] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 1, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:30,498] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T01:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:30,498] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 0, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:30,498] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T00:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:30,498] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 1, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:30,498] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T01:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:30,499] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 0, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:30,499] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T00:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:30,499] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 1, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:30,499] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T01:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:30,500] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 0, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:30,500] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T00:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:30,500] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 1, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:30,500] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T01:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:30,500] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 0, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:30,500] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T00:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:30,500] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 1, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:30,500] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T01:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:30,500] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 0, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:30,500] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T00:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:30,501] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 1, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:30,501] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T01:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:30,501] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 0, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:30,501] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T00:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:30,501] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 0, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:30,501] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T00:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:30,501] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 0, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:30,501] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T00:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:30,501] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 0, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:30,502] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T00:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:30,681] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 00:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:30,684] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 00:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:30,685] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 00:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:30,687] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 00:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:30,689] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 00:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:30,690] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 00:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:30,697] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 00:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:30,701] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 00:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:30,709] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 00:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:30,710] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 00:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:30,721] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 00:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:30,723] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 00:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:30,724] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 00:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:30,736] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 00:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:30,738] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 00:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:30,742] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 01:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:42,447] {scheduler_job.py:961} INFO - 35 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:10:00+00:00 [scheduled]>
[2020-11-11 16:18:42,451] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 114 open slots and 35 task instances ready to be queued
[2020-11-11 16:18:42,452] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:18:42,452] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:18:42,452] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,452] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,452] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,453] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,453] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,453] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,453] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,453] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,453] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,454] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,454] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,454] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,454] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,454] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,454] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,455] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,455] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,455] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,455] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,455] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,455] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,455] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,456] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,456] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,456] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,456] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,456] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,456] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,457] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,457] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,457] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,457] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,457] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,457] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,458] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,458] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,458] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,458] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,458] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,458] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,459] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,459] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,459] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,459] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,459] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,459] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,459] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,460] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,460] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,460] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,460] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,460] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,460] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,461] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,461] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,461] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,461] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,461] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,461] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,462] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,462] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,462] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,462] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,462] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,462] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:42,462] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:42,466] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:00:00+00:00 [scheduled]>
[2020-11-11 16:18:42,475] {scheduler_job.py:1158} INFO - Setting the following 2 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:00:00+00:00 [queued]>
[2020-11-11 16:18:42,476] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 1, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:18:42,476] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T01:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:42,476] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 1, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:42,476] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T01:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:42,571] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 01:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:54,489] {scheduler_job.py:961} INFO - 45 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:15:00+00:00 [scheduled]>
[2020-11-11 16:18:54,500] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 45 task instances ready to be queued
[2020-11-11 16:18:54,501] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:18:54,501] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:18:54,502] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:18:54,502] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:18:54,502] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:18:54,503] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:18:54,503] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:18:54,503] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:18:54,503] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:18:54,504] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:18:54,504] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:18:54,504] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:18:54,504] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:18:54,505] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:18:54,505] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:18:54,505] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:18:54,505] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:54,505] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:54,506] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:54,506] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:54,507] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:54,507] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:54,507] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:54,507] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:54,508] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:54,508] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:54,508] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:54,508] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:54,508] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:54,509] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:54,509] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:54,509] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:54,509] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:54,509] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:54,509] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:54,510] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:54,510] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:54,510] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:54,510] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:54,510] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:54,510] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:54,511] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:54,511] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:54,511] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:54,511] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:54,511] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:54,511] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:54,512] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:54,512] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:54,512] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:54,512] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:54,512] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:54,513] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:54,513] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:54,513] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:54,513] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:54,513] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:54,513] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:54,513] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:54,514] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:54,514] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:54,514] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:54,514] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:54,514] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:54,514] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:54,514] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:54,515] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:54,515] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:54,515] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:54,515] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:54,515] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:54,515] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:54,515] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:18:54,516] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:18:54,519] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:10:00+00:00 [scheduled]>
[2020-11-11 16:18:54,538] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:05:00+00:00 [queued]>
[2020-11-11 16:18:54,539] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 1, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:18:54,539] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T01:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:54,539] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 1, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:54,539] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T01:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:54,539] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 1, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:54,539] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T01:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:54,539] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 1, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:54,539] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T01:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:54,540] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 1, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:54,540] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T01:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:54,540] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 1, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:54,540] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T01:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:54,540] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 1, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:54,540] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T01:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:54,540] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 1, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:54,540] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T01:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:54,540] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 1, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:54,540] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T01:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:54,541] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 1, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:54,541] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T01:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:54,541] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 1, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:54,541] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T01:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:54,541] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 1, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:54,541] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T01:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:54,541] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 1, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:54,541] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T01:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:54,541] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 1, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:54,541] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T01:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:54,542] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 1, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:54,542] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T01:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:54,542] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 1, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:18:54,542] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T01:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:18:54,765] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 01:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:54,769] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 01:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:54,771] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 01:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:54,774] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 00:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:54,777] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 00:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:54,781] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 00:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:54,787] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 00:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:54,789] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 00:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:54,802] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 01:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:54,805] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 00:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:54,810] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 00:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:54,812] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 01:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:54,818] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 01:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:54,820] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 00:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:54,826] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 00:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:18:54,833] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 01:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:06,468] {scheduler_job.py:961} INFO - 39 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:20:00+00:00 [scheduled]>
[2020-11-11 16:19:06,471] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 115 open slots and 39 task instances ready to be queued
[2020-11-11 16:19:06,471] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:19:06,471] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:19:06,471] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:19:06,472] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,472] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,472] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,472] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,472] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,472] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,472] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,472] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,472] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,472] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,473] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,473] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,473] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,473] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,473] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,473] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,473] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,473] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,473] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,473] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,473] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,474] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,474] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,474] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,474] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,474] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,474] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,474] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,474] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,474] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,474] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,474] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,475] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,475] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,475] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,475] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,475] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,475] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,475] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,475] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,475] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,475] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,476] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,476] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,476] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,476] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,476] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,476] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,476] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,476] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,476] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,476] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,476] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,477] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,477] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,477] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,477] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,477] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,477] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,477] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,477] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,477] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,477] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,477] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,478] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,478] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,478] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,478] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,478] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,478] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,478] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:06,478] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:06,480] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:10:00+00:00 [scheduled]>
[2020-11-11 16:19:06,488] {scheduler_job.py:1158} INFO - Setting the following 3 tasks to queued state:
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:10:00+00:00 [queued]>
[2020-11-11 16:19:06,488] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 1, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:19:06,488] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T01:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:06,489] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 1, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:19:06,489] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T01:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:06,489] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 1, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:19:06,489] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T01:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:06,572] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 01:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:06,575] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 01:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:18,477] {scheduler_job.py:961} INFO - 38 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:20:00+00:00 [scheduled]>
[2020-11-11 16:19:18,480] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 38 task instances ready to be queued
[2020-11-11 16:19:18,480] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:19:18,480] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:19:18,480] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:19:18,480] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:19:18,480] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:19:18,480] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:19:18,480] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:19:18,481] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:19:18,481] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:19:18,481] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:19:18,481] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:19:18,481] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:19:18,481] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:19:18,481] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:19:18,481] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:19:18,481] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:19:18,481] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:18,481] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:18,482] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:18,482] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:18,482] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:18,482] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:18,482] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:18,482] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:18,482] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:18,482] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:18,482] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:18,482] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:18,483] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:18,483] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:18,483] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:18,483] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:18,483] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:18,483] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:18,483] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:18,483] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:18,483] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:18,483] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:18,483] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:18,484] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:18,484] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:18,484] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:18,484] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:18,484] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:18,484] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:18,484] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:18,484] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:18,484] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:18,484] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:18,484] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:18,485] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:18,485] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:18,485] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:18,485] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:18,485] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:18,485] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:18,485] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:18,485] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:18,485] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:18,485] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:18,488] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:20:00+00:00 [scheduled]>
[2020-11-11 16:19:18,522] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:15:00+00:00 [queued]>
[2020-11-11 16:19:18,523] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 1, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:19:18,523] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T01:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:18,524] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 1, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:19:18,524] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T01:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:18,525] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 1, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:19:18,525] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T01:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:18,526] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 1, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:19:18,526] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T01:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:18,526] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 1, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:19:18,527] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T01:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:18,527] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 1, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:19:18,527] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T01:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:18,527] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 1, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:19:18,527] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T01:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:18,527] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 1, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:19:18,527] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T01:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:18,527] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 1, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:19:18,527] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T01:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:18,527] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 1, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:19:18,527] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T01:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:18,528] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 1, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:19:18,528] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T01:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:18,528] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 1, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:19:18,528] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T01:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:18,528] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 1, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:19:18,528] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T01:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:18,528] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 1, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:19:18,528] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T01:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:18,528] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 1, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:19:18,528] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T01:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:18,528] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 1, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:19:18,529] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T01:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:18,723] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 01:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:18,726] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 01:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:18,735] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 01:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:18,736] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 01:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:18,745] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 01:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:18,747] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 01:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:18,757] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 01:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:18,759] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 01:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:18,760] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 01:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:18,767] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 01:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:18,769] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 01:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:18,771] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 01:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:18,775] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 01:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:18,787] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 01:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:18,788] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 01:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:30,509] {scheduler_job.py:961} INFO - 22 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:20:00+00:00 [scheduled]>
[2020-11-11 16:19:30,521] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 112 open slots and 22 task instances ready to be queued
[2020-11-11 16:19:30,521] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:30,522] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:30,523] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:30,523] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:30,524] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:30,525] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:30,525] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:30,525] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:30,526] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:30,526] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:30,527] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:30,527] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:30,528] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:30,528] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:30,529] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:30,529] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:30,529] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:30,530] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:30,530] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:30,531] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:30,531] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:30,531] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:30,532] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:30,532] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:30,533] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:30,533] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:30,534] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:30,534] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:30,534] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:30,535] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:30,535] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:30,536] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:30,536] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:30,536] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:30,537] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:30,537] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:30,538] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:30,538] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:30,539] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:30,539] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:30,539] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:30,540] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:30,540] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:30,541] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:30,548] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	
[2020-11-11 16:19:30,587] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 01:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:30,589] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 01:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:30,590] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 01:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:42,510] {scheduler_job.py:961} INFO - 24 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:20:00+00:00 [scheduled]>
[2020-11-11 16:19:42,513] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 24 task instances ready to be queued
[2020-11-11 16:19:42,513] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:19:42,513] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:19:42,513] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:19:42,513] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:19:42,513] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:19:42,513] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:19:42,513] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:19:42,514] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:19:42,514] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:19:42,514] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:19:42,514] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:19:42,514] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:19:42,514] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:19:42,514] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:19:42,514] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:19:42,514] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:19:42,514] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:42,514] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:42,515] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:42,515] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:42,515] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:42,515] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:42,515] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:42,515] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:42,515] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:42,515] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:42,515] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:42,515] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:42,516] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:42,516] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:42,516] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:42,516] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:42,518] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:35:00+00:00 [scheduled]>
[2020-11-11 16:19:42,532] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:20:00+00:00 [queued]>
[2020-11-11 16:19:42,533] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 0, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:19:42,533] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T00:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:42,533] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 0, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:19:42,533] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T00:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:42,533] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 0, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:19:42,533] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T00:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:42,533] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 0, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:19:42,533] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T00:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:42,534] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 0, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:19:42,534] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T00:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:42,534] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 0, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:19:42,534] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T00:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:42,534] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 0, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:19:42,535] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T00:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:42,535] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 1, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:19:42,535] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T01:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:42,535] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 1, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:19:42,535] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T01:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:42,535] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 1, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:19:42,535] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T01:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:42,535] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 1, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:19:42,535] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T01:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:42,535] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 1, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:19:42,536] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T01:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:42,536] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 1, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:19:42,536] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T01:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:42,536] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 1, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:19:42,536] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T01:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:42,536] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 1, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:19:42,536] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T01:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:42,536] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 1, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:19:42,536] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T01:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:42,704] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 01:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:42,707] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 01:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:42,709] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 01:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:42,711] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 01:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:42,713] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 01:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:42,715] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 01:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:42,720] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 01:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:42,727] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 01:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:42,729] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 01:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:42,733] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 01:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:42,748] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 01:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:42,753] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 01:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:42,755] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 01:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:42,765] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 01:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:42,770] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 01:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:42,773] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 01:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:54,529] {scheduler_job.py:961} INFO - 8 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:15:00+00:00 [scheduled]>
[2020-11-11 16:19:54,539] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 119 open slots and 8 task instances ready to be queued
[2020-11-11 16:19:54,539] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:19:54,539] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:19:54,540] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:19:54,540] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:19:54,540] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:19:54,541] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:19:54,541] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:19:54,541] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:19:54,541] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:19:54,546] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:10:00+00:00 [scheduled]>
[2020-11-11 16:19:54,594] {scheduler_job.py:1158} INFO - Setting the following 7 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 00:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:10:00+00:00 [queued]>
[2020-11-11 16:19:54,594] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 0, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:19:54,595] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T00:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:54,596] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 0, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:19:54,596] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T00:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:54,597] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 0, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:19:54,597] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T00:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:54,597] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 0, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:19:54,598] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T00:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:54,598] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 1, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:19:54,599] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T01:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:54,599] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 1, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:19:54,600] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T01:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:54,601] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 1, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:19:54,601] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T01:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:19:54,763] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 00:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:54,766] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 00:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:54,768] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 00:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:54,770] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 00:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:54,781] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 00:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:54,783] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 00:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:19:54,785] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 00:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:06,519] {scheduler_job.py:961} INFO - 3 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:20:00+00:00 [scheduled]>
[2020-11-11 16:20:06,523] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 3 task instances ready to be queued
[2020-11-11 16:20:06,524] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:20:06,524] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:20:06,524] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:20:06,528] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:20:00+00:00 [scheduled]>
[2020-11-11 16:20:06,538] {scheduler_job.py:1158} INFO - Setting the following 3 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:20:00+00:00 [queued]>
[2020-11-11 16:20:06,538] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 1, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:20:06,539] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T01:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:06,539] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 1, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:20:06,539] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T01:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:06,540] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 1, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:20:06,540] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T01:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:06,616] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 01:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:06,619] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 01:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:06,620] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 01:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:06,622] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 01:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:06,623] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 01:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:06,624] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 01:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:06,626] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 01:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:06,627] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 01:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:06,628] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 01:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:06,629] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 00:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:06,631] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 00:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:06,632] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 00:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:06,633] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 00:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:06,635] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 01:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:06,636] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 01:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:06,638] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 01:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:20,549] {scheduler_job.py:961} INFO - 11 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:25:00+00:00 [scheduled]>
[2020-11-11 16:20:20,560] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 11 task instances ready to be queued
[2020-11-11 16:20:20,561] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:20:20,561] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:20:20,562] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:20:20,562] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:20:20,563] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:20:20,563] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:20:20,564] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:20:20,564] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:20:20,564] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:20:20,565] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:20:20,565] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:20:20,574] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:25:00+00:00 [scheduled]>
[2020-11-11 16:20:20,598] {scheduler_job.py:1158} INFO - Setting the following 11 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:25:00+00:00 [queued]>
[2020-11-11 16:20:20,599] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 1, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:20:20,600] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T01:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:20,600] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 1, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:20,600] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T01:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:20,600] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 1, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:20,600] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T01:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:20,601] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 1, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:20,601] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T01:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:20,601] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 1, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:20,601] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T01:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:20,601] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 1, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:20,602] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T01:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:20,602] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 1, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:20,602] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T01:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:20,602] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 1, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:20,602] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T01:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:20,603] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 1, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:20,603] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T01:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:20,603] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 1, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:20,603] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T01:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:20,603] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 1, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:20,603] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T01:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:20,786] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 01:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:20,790] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 01:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:20,792] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 01:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:32,544] {scheduler_job.py:961} INFO - 11 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:30:00+00:00 [scheduled]>
[2020-11-11 16:20:32,548] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 122 open slots and 11 task instances ready to be queued
[2020-11-11 16:20:32,548] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:20:32,548] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:20:32,549] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:20:32,549] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:20:32,549] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:20:32,549] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:20:32,549] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:20:32,549] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:20:32,550] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:20:32,550] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:20:32,550] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:20:32,550] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:20:32,553] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:30:00+00:00 [scheduled]>
[2020-11-11 16:20:32,567] {scheduler_job.py:1158} INFO - Setting the following 10 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:30:00+00:00 [queued]>
[2020-11-11 16:20:32,568] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 1, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:20:32,568] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T01:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:32,568] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 1, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:32,568] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T01:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:32,569] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 1, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:32,569] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T01:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:32,569] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 1, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:32,569] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T01:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:32,570] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 1, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:32,570] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T01:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:32,570] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 1, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:32,570] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T01:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:32,570] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 1, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:32,571] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T01:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:32,571] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 1, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:32,571] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T01:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:32,571] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 1, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:32,571] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T01:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:32,571] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 1, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:32,572] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T01:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:32,780] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 01:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:44,573] {scheduler_job.py:961} INFO - 13 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:35:00+00:00 [scheduled]>
[2020-11-11 16:20:44,583] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 13 task instances ready to be queued
[2020-11-11 16:20:44,583] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:20:44,583] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:20:44,584] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:20:44,584] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:20:44,584] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:20:44,585] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:20:44,585] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:20:44,585] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:20:44,585] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:20:44,586] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:20:44,586] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:20:44,586] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:20:44,586] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:20:44,591] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:25:00+00:00 [scheduled]>
[2020-11-11 16:20:44,615] {scheduler_job.py:1158} INFO - Setting the following 13 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:35:00+00:00 [queued]>
[2020-11-11 16:20:44,615] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 1, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:20:44,615] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T01:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:44,616] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 1, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:20:44,616] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T01:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:44,616] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 1, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:44,617] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T01:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:44,617] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 1, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:44,617] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T01:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:44,617] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 1, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:44,618] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T01:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:44,618] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 1, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:44,618] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T01:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:44,618] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 1, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:44,619] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T01:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:44,619] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 1, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:44,619] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T01:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:44,619] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 1, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:44,620] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T01:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:44,620] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 1, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:44,620] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T01:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:44,620] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 1, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:44,620] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T01:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:44,621] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 1, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:44,621] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T01:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:44,621] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 1, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:44,621] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T01:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:44,826] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 01:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:44,830] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 01:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:44,832] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 01:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:44,834] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 01:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:44,836] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 01:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:44,839] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 01:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:44,851] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 01:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:44,853] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 01:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:44,855] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 01:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:44,857] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 01:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:44,860] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 01:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:56,583] {scheduler_job.py:961} INFO - 11 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:40:00+00:00 [scheduled]>
[2020-11-11 16:20:56,595] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 117 open slots and 11 task instances ready to be queued
[2020-11-11 16:20:56,596] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:20:56,596] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:20:56,597] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:20:56,597] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:20:56,598] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:20:56,598] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:20:56,599] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:20:56,599] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:20:56,600] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:20:56,600] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:20:56,601] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:20:56,601] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:20:56,601] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:20:56,602] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:20:56,602] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:20:56,603] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:20:56,603] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:20:56,610] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:40:00+00:00 [scheduled]>
[2020-11-11 16:20:56,622] {scheduler_job.py:1158} INFO - Setting the following 5 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:40:00+00:00 [queued]>
[2020-11-11 16:20:56,622] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 1, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:20:56,623] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T01:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:56,623] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 1, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:56,623] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T01:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:56,623] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 1, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:56,623] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T01:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:56,623] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 1, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:56,623] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T01:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:56,624] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 1, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:20:56,624] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T01:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:20:56,767] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 01:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:56,770] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 01:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:56,773] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 01:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:56,774] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 01:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:56,776] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 01:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:56,777] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 01:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:56,779] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 01:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:56,781] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 01:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:56,784] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 01:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:56,786] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 01:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:20:56,788] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 01:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:08,596] {scheduler_job.py:961} INFO - 19 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:45:00+00:00 [scheduled]>
[2020-11-11 16:21:08,604] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 19 task instances ready to be queued
[2020-11-11 16:21:08,605] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:21:08,605] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:21:08,606] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:21:08,606] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:21:08,606] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:21:08,607] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:21:08,607] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:21:08,607] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:21:08,608] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:21:08,608] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:21:08,608] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:21:08,608] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:21:08,609] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:21:08,609] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:21:08,609] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:21:08,610] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:21:08,610] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:08,610] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:08,610] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:08,611] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:08,611] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:08,611] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:08,618] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:45:00+00:00 [scheduled]>
[2020-11-11 16:21:08,654] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:40:00+00:00 [queued]>
[2020-11-11 16:21:08,654] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 1, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:21:08,655] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T01:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:08,655] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 1, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:08,655] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T01:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:08,656] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 1, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:08,656] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T01:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:08,657] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 1, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:08,657] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T01:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:08,657] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 1, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:08,657] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T01:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:08,658] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 1, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:08,658] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T01:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:08,658] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 1, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:08,659] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T01:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:08,659] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 1, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:08,659] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T01:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:08,660] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 1, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:08,660] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T01:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:08,660] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 1, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:08,661] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T01:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:08,661] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 1, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:08,661] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T01:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:08,661] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 1, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:08,662] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T01:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:08,662] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 1, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:08,662] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T01:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:08,663] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 1, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:08,663] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T01:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:08,663] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 1, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:08,664] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T01:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:08,664] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 1, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:08,664] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T01:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:08,880] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 01:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:08,884] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 01:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:08,886] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 01:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:08,888] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 01:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:08,890] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 01:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:08,891] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 01:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:08,895] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 01:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:08,903] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 01:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:08,909] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 01:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:08,911] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 01:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:08,918] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 01:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:08,927] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 01:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:20,591] {scheduler_job.py:961} INFO - 14 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:50:00+00:00 [scheduled]>
[2020-11-11 16:21:20,595] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 14 task instances ready to be queued
[2020-11-11 16:21:20,595] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:21:20,596] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:20,596] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:20,596] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:20,596] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:20,596] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:20,596] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:20,596] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:20,597] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:20,597] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:20,597] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:20,597] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:20,597] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:20,597] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:20,597] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:20,597] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:20,598] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:20,598] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:20,598] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:20,598] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:20,598] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:20,598] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:20,598] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:20,598] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:20,599] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:20,599] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:20,599] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:20,602] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:55:00+00:00 [scheduled]>
[2020-11-11 16:21:20,610] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 01:55:00+00:00 [queued]>
[2020-11-11 16:21:20,611] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 1, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:21:20,611] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T01:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:20,705] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 01:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:20,708] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 01:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:20,709] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 01:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:20,710] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 01:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:20,711] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 01:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:32,619] {scheduler_job.py:961} INFO - 25 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:55:00+00:00 [scheduled]>
[2020-11-11 16:21:32,627] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 25 task instances ready to be queued
[2020-11-11 16:21:32,628] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:21:32,628] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:21:32,629] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:21:32,629] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:21:32,630] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:21:32,630] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:21:32,630] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:21:32,631] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:21:32,631] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:21:32,633] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:21:32,633] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:21:32,633] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:21:32,633] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:21:32,634] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:21:32,634] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:21:32,634] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:21:32,634] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:32,634] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:32,634] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:32,634] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:32,635] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:32,635] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:32,635] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:32,635] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:32,635] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:32,636] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:32,636] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:32,638] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:32,639] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:32,639] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:32,639] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:32,639] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:32,640] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:32,640] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:32,643] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:55:00+00:00 [scheduled]>
[2020-11-11 16:21:32,660] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 01:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 01:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 01:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 01:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:50:00+00:00 [queued]>
[2020-11-11 16:21:32,660] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 2, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:21:32,660] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T02:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:32,661] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 1, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:32,661] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T01:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:32,661] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 1, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:32,661] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T01:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:32,661] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 1, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:32,661] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T01:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:32,661] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 1, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:32,661] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T01:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:32,662] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 1, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:32,662] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T01:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:32,662] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 1, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:32,662] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T01:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:32,662] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 1, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:32,662] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T01:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:32,662] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 1, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:32,663] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T01:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:32,663] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 1, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:32,663] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T01:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:32,663] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 1, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:32,663] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T01:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:32,663] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 1, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:32,663] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T01:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:32,663] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 1, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:32,663] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T01:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:32,663] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 1, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:32,663] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T01:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:32,664] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 1, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:32,664] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T01:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:32,664] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 1, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:32,664] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T01:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:32,932] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 01:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:32,936] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 01:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:32,938] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 01:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:32,940] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 01:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:32,941] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 01:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:32,945] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 01:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:32,957] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 01:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:32,974] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 01:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:32,976] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 01:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:32,978] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 01:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:32,979] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 01:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:32,982] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 01:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:32,990] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 01:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:33,013] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 01:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:33,015] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 01:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:33,018] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 01:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:44,625] {scheduler_job.py:961} INFO - 20 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:00:00+00:00 [scheduled]>
[2020-11-11 16:21:44,636] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 115 open slots and 20 task instances ready to be queued
[2020-11-11 16:21:44,636] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:21:44,637] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:21:44,637] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:21:44,637] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:44,638] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:44,638] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:44,638] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:44,639] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:44,639] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:44,639] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:44,639] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:44,640] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:44,640] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:44,640] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:44,641] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:44,641] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:44,641] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:44,642] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:44,642] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:44,642] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:44,643] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:44,643] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:44,643] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:44,643] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:44,645] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:44,645] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:44,645] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:44,646] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:44,646] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:44,646] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:44,647] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:44,647] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:44,647] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:44,648] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:44,648] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:44,648] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:44,649] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:44,656] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:55:00+00:00 [scheduled]>
[2020-11-11 16:21:44,672] {scheduler_job.py:1158} INFO - Setting the following 3 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 01:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 01:55:00+00:00 [queued]>
[2020-11-11 16:21:44,673] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 2, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:21:44,674] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T02:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:44,674] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 1, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:44,674] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T01:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:44,675] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 1, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:44,675] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T01:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:44,801] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 02:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:56,613] {scheduler_job.py:961} INFO - 30 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:05:00+00:00 [scheduled]>
[2020-11-11 16:21:56,616] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 30 task instances ready to be queued
[2020-11-11 16:21:56,616] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:21:56,616] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:21:56,616] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:21:56,617] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:21:56,617] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:21:56,617] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:21:56,617] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:21:56,617] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:21:56,617] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:21:56,617] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:21:56,617] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:21:56,617] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:21:56,617] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:21:56,618] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:21:56,618] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:21:56,618] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:21:56,618] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:56,618] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:56,618] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:56,618] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:56,618] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:56,618] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:56,618] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:56,618] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:56,619] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:56,619] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:56,619] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:56,619] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:56,619] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:56,619] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:56,619] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:56,619] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:56,619] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:56,619] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:56,619] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:56,620] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:56,620] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:56,620] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:56,620] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:56,620] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:56,620] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:56,620] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:56,620] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:21:56,620] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:21:56,623] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:05:00+00:00 [scheduled]>
[2020-11-11 16:21:56,637] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 01:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 01:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 01:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 01:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:00:00+00:00 [queued]>
[2020-11-11 16:21:56,638] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 2, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:21:56,638] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T02:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:56,638] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 2, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:56,638] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T02:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:56,638] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 2, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:56,638] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T02:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:56,638] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 2, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:56,638] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T02:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:56,638] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 2, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:56,639] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T02:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:56,639] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 2, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:56,639] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T02:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:56,639] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 2, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:56,639] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T02:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:56,639] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 2, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:56,639] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T02:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:56,639] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 1, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:56,639] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T01:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:56,639] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 2, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:56,639] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T02:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:56,640] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 1, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:56,640] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T01:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:56,640] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 2, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:56,640] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T02:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:56,640] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 1, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:56,640] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T01:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:56,640] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 2, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:56,640] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T02:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:56,640] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 1, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:56,640] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T01:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:56,641] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 2, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:21:56,641] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T02:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:21:56,840] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 01:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:56,843] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 01:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:56,845] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 01:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:56,847] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 01:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:56,849] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 01:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:56,851] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 01:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:56,855] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 01:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:56,860] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 01:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:56,863] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 01:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:56,873] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 01:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:56,879] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 01:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:56,885] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 01:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:56,893] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 01:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:56,900] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 01:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:56,905] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 01:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:21:56,916] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 02:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:08,624] {scheduler_job.py:961} INFO - 25 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:10:00+00:00 [scheduled]>
[2020-11-11 16:22:08,626] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 25 task instances ready to be queued
[2020-11-11 16:22:08,626] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:22:08,627] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:08,627] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:08,627] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:08,627] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:08,627] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:08,627] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:08,627] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:08,627] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:08,627] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:08,627] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:08,628] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:08,628] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:08,628] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:08,628] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:08,628] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:08,628] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:08,628] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:08,628] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:08,628] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:08,628] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:08,628] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:08,628] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:08,629] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:08,629] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:08,629] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:08,629] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:08,629] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:08,630] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:08,630] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:08,630] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:08,630] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:08,631] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:08,631] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:08,631] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:08,632] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:08,632] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:08,633] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:08,633] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:08,633] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:08,634] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:08,634] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:08,634] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:08,635] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:08,635] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:08,636] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:08,636] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:08,636] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:08,637] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:08,641] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:15:00+00:00 [scheduled]>
[2020-11-11 16:22:08,650] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:15:00+00:00 [queued]>
[2020-11-11 16:22:08,650] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 2, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:22:08,651] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T02:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:08,728] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 01:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:08,730] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 01:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:08,732] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 02:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:20,666] {scheduler_job.py:961} INFO - 37 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:15:00+00:00 [scheduled]>
[2020-11-11 16:22:20,675] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 37 task instances ready to be queued
[2020-11-11 16:22:20,676] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:22:20,676] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:22:20,677] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:22:20,677] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:22:20,677] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:22:20,678] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:22:20,678] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:22:20,678] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:22:20,678] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:22:20,679] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:22:20,679] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:22:20,679] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:22:20,680] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:22:20,680] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:22:20,680] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:22:20,681] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:22:20,681] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:20,681] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:20,682] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:20,682] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:20,682] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:20,682] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:20,683] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:20,683] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:20,683] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:20,684] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:20,684] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:20,684] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:20,685] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:20,685] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:20,685] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:20,685] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:20,686] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:20,686] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:20,686] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:20,687] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:20,687] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:20,687] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:20,688] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:20,688] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:20,688] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:20,688] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:20,689] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:20,689] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:20,689] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:20,690] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:20,690] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:20,690] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:20,690] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:20,691] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:20,691] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:20,691] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:20,692] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:20,692] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:20,692] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:20,693] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:20,693] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:20,693] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:20,700] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:10:00+00:00 [scheduled]>
[2020-11-11 16:22:20,728] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:05:00+00:00 [queued]>
[2020-11-11 16:22:20,729] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 2, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:22:20,729] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T02:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:20,729] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 2, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:22:20,729] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T02:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:20,730] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 2, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:22:20,730] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T02:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:20,730] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 2, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:22:20,730] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T02:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:20,730] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 2, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:22:20,730] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T02:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:20,731] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 2, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:22:20,731] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T02:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:20,731] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 2, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:22:20,731] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T02:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:20,731] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 2, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:22:20,731] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T02:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:20,731] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 2, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:22:20,732] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T02:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:20,732] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 2, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:22:20,732] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T02:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:20,732] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 2, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:22:20,732] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T02:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:20,732] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 2, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:22:20,732] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T02:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:20,733] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 2, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:22:20,733] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T02:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:20,733] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 2, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:22:20,733] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T02:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:20,733] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 2, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:22:20,733] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T02:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:20,734] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 2, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:22:20,734] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T02:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:20,919] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 02:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:20,922] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 02:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:20,923] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 02:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:20,925] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 02:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:20,927] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 01:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:20,928] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 01:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:20,933] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 02:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:20,937] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 02:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:20,942] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 02:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:20,946] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 02:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:20,960] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 02:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:20,964] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 01:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:20,966] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 02:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:20,968] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 01:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:20,972] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 02:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:20,974] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 02:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:32,653] {scheduler_job.py:961} INFO - 32 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:20:00+00:00 [scheduled]>
[2020-11-11 16:22:32,657] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 32 task instances ready to be queued
[2020-11-11 16:22:32,657] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:22:32,657] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:32,657] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:32,657] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:32,658] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:32,658] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:32,658] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:32,658] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:32,658] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:32,658] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:32,659] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:32,659] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:32,659] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:32,659] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:32,659] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:32,659] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:32,659] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:32,660] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:32,660] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:32,660] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:32,660] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:32,660] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:32,660] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:32,661] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:32,661] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:32,661] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:32,661] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:32,661] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:32,661] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:32,661] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:32,662] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:32,662] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:32,662] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:32,662] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:32,662] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:32,662] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:32,662] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:32,663] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:32,663] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:32,663] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:32,663] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:32,663] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:32,663] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:32,663] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:32,664] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:32,664] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:32,664] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:32,664] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:32,664] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:32,664] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:32,665] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:32,665] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:32,665] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:32,665] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:32,665] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:32,665] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:32,665] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:32,666] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:32,666] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:32,666] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:32,666] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:32,666] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:32,666] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:32,670] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:25:00+00:00 [scheduled]>
[2020-11-11 16:22:32,678] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:25:00+00:00 [queued]>
[2020-11-11 16:22:32,679] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 2, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:22:32,679] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T02:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:32,751] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 02:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:46,665] {scheduler_job.py:961} INFO - 43 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:25:00+00:00 [scheduled]>
[2020-11-11 16:22:46,668] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 43 task instances ready to be queued
[2020-11-11 16:22:46,668] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:22:46,668] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:22:46,668] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:22:46,668] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:22:46,668] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:22:46,668] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:22:46,668] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:22:46,669] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:22:46,669] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:22:46,669] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:22:46,669] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:22:46,669] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:22:46,669] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:22:46,669] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:22:46,669] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:22:46,669] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:22:46,669] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:46,669] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:46,670] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:46,670] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:46,670] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:46,670] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:46,670] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:46,670] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:46,670] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:46,670] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:46,670] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:46,670] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:46,671] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:46,671] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:46,671] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:46,671] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:46,671] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:46,671] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:46,671] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:46,671] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:46,671] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:46,671] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:46,671] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:46,672] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:46,672] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:46,672] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:46,672] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:46,672] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:46,672] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:46,672] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:46,672] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:46,672] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:46,672] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:46,672] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:46,673] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:46,673] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:46,673] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:46,673] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:46,673] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:46,673] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:46,673] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:46,673] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:46,673] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:46,673] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:46,673] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:46,674] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:46,674] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:46,674] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:46,674] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:46,674] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:46,674] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:46,674] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:46,674] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:46,674] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:46,676] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:20:00+00:00 [scheduled]>
[2020-11-11 16:22:46,692] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:15:00+00:00 [queued]>
[2020-11-11 16:22:46,693] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 2, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:22:46,693] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T02:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:46,693] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 2, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:22:46,693] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T02:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:46,693] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 2, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:22:46,693] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T02:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:46,693] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 2, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:22:46,693] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T02:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:46,694] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 2, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:22:46,694] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T02:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:46,694] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 2, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:22:46,694] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T02:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:46,694] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 2, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:22:46,694] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T02:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:46,694] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 2, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:22:46,694] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T02:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:46,694] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 2, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:22:46,694] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T02:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:46,695] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 2, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:22:46,695] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T02:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:46,695] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 2, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:22:46,695] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T02:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:46,695] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 2, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:22:46,695] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T02:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:46,695] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 2, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:22:46,695] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T02:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:46,695] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 2, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:22:46,696] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T02:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:46,696] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 2, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:22:46,696] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T02:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:46,696] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 2, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:22:46,696] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T02:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:46,881] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 02:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:46,884] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 02:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:46,886] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 02:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:46,888] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 02:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:46,890] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 02:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:46,891] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 02:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:46,902] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 02:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:46,904] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 02:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:46,906] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 02:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:46,918] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 02:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:46,920] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 02:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:46,922] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 02:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:46,930] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 02:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:46,932] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 02:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:46,934] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 02:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:46,942] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 02:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:22:58,677] {scheduler_job.py:961} INFO - 38 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:30:00+00:00 [scheduled]>
[2020-11-11 16:22:58,680] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 38 task instances ready to be queued
[2020-11-11 16:22:58,680] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:22:58,680] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,680] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,680] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,680] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,681] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,681] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,681] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,681] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,681] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,681] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,681] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,681] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,681] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,681] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,681] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,682] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,682] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,682] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,682] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,682] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,682] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,682] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,682] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,682] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,682] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,682] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,683] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,683] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,683] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,683] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,683] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,683] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,683] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,683] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,683] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,683] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,684] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,684] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,684] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,684] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,684] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,684] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,684] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,684] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,684] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,684] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,684] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,685] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,685] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,685] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,685] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,685] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,685] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,685] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,685] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,685] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,685] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,685] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,686] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,686] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,686] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,686] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,686] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,686] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,686] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,686] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,686] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,686] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,686] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,687] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,687] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,687] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,687] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:22:58,687] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:22:58,689] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:35:00+00:00 [scheduled]>
[2020-11-11 16:22:58,696] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:35:00+00:00 [queued]>
[2020-11-11 16:22:58,696] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 2, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:22:58,696] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T02:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:22:58,757] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 02:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:10,715] {scheduler_job.py:961} INFO - 50 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:35:00+00:00 [scheduled]>
[2020-11-11 16:23:10,723] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 50 task instances ready to be queued
[2020-11-11 16:23:10,723] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:23:10,723] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:23:10,724] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:23:10,724] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:23:10,724] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:23:10,724] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:23:10,724] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:23:10,725] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:23:10,725] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:23:10,725] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:23:10,725] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:23:10,726] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:23:10,726] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:23:10,726] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:23:10,726] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:23:10,726] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:23:10,726] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,727] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,727] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,727] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,727] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,727] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,728] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,728] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,728] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,728] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,728] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,728] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,729] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,729] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,729] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,729] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,729] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,730] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,730] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,730] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,730] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,730] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,730] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,731] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,731] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,731] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,731] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,731] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,731] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,731] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,732] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,732] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,732] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,732] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,732] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,732] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,732] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,733] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,733] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,733] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,733] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,733] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,733] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,733] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,734] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,734] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,734] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,734] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,734] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,734] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,734] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,735] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,735] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,735] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,735] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,735] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,735] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,735] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,736] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,736] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,736] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,736] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,736] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,736] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,736] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,736] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,737] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:10,737] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:10,740] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:25:00+00:00 [scheduled]>
[2020-11-11 16:23:10,759] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:20:00+00:00 [queued]>
[2020-11-11 16:23:10,760] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 2, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:23:10,761] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T02:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:10,761] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 2, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:10,762] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T02:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:10,762] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 2, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:10,762] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T02:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:10,763] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 2, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:10,763] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T02:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:10,764] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 2, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:10,764] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T02:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:10,765] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 2, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:10,765] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T02:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:10,766] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 2, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:10,766] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T02:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:10,767] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 2, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:10,767] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T02:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:10,767] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 2, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:10,768] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T02:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:10,768] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 2, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:10,769] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T02:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:10,769] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 2, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:10,770] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T02:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:10,770] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 2, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:10,770] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T02:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:10,771] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 2, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:10,771] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T02:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:10,772] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 2, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:10,772] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T02:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:10,773] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 2, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:10,773] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T02:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:10,774] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 2, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:10,774] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T02:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:10,966] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 02:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:10,969] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 02:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:10,971] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 02:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:10,972] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 02:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:10,974] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 02:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:10,976] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 02:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:10,985] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 02:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:11,000] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 02:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:11,002] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 02:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:11,004] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 02:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:11,012] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 02:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:11,016] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 02:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:11,018] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 02:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:11,026] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 02:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:11,028] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 02:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:11,030] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 02:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:22,724] {scheduler_job.py:961} INFO - 45 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:40:00+00:00 [scheduled]>
[2020-11-11 16:23:22,730] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 45 task instances ready to be queued
[2020-11-11 16:23:22,731] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:23:22,731] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,731] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,731] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,731] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,732] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,732] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,732] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,732] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,732] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,734] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,734] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,734] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,734] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,734] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,734] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,735] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,735] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,735] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,735] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,735] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,735] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,735] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,736] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,736] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,736] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,736] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,736] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,736] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,737] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,737] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,737] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,737] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,737] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,737] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,737] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,737] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,738] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,738] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,738] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,738] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,738] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,738] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,739] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,739] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,739] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,739] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,739] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,739] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,739] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,740] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,740] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,740] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,740] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,740] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,740] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,740] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,740] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,740] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,741] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,741] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,741] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,741] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,741] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,741] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,741] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,741] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,742] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,742] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,742] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,742] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,742] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,742] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,742] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,742] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,743] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,743] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,743] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,743] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,743] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,743] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,743] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,743] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,744] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,744] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,744] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,744] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,744] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:22,744] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:22,747] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:45:00+00:00 [scheduled]>
[2020-11-11 16:23:22,754] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:45:00+00:00 [queued]>
[2020-11-11 16:23:22,755] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 2, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:23:22,755] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T02:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:22,852] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 02:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:34,739] {scheduler_job.py:961} INFO - 55 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:45:00+00:00 [scheduled]>
[2020-11-11 16:23:34,750] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 55 task instances ready to be queued
[2020-11-11 16:23:34,750] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:23:34,751] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:23:34,751] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:23:34,751] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:23:34,752] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:23:34,752] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:23:34,752] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:23:34,753] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:23:34,753] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:23:34,753] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:23:34,753] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:23:34,754] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:23:34,754] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:23:34,754] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:23:34,754] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:23:34,754] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:23:34,755] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,755] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,755] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,755] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,756] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,756] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,756] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,756] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,756] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,757] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,757] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,757] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,757] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,757] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,758] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,758] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,758] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,758] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,759] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,759] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,759] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,759] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,759] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,759] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,760] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,760] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,760] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,760] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,760] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,760] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,761] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,761] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,761] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,761] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,761] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,761] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,762] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,762] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,762] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,762] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,762] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,762] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,763] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,763] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,763] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,763] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,763] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,763] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,764] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,764] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,764] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,764] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,764] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,764] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,764] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,765] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,765] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,765] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,765] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,765] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,765] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,765] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,766] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,766] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,766] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,766] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,766] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,766] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,766] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,767] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,767] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,767] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,767] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,767] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,767] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,767] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,768] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:34,768] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:34,771] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:35:00+00:00 [scheduled]>
[2020-11-11 16:23:34,787] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:30:00+00:00 [queued]>
[2020-11-11 16:23:34,787] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 2, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:34,787] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T02:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:34,788] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 2, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:34,788] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T02:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:34,788] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 2, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:34,788] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T02:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:34,788] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 2, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:34,788] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T02:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:34,788] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 2, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:34,788] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T02:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:34,788] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 2, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:34,788] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T02:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:34,789] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 2, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:34,789] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T02:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:34,789] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 2, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:34,789] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T02:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:34,789] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 2, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:34,789] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T02:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:34,789] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 2, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:34,789] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T02:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:34,790] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 2, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:34,790] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T02:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:34,790] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 2, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:34,790] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T02:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:34,790] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 2, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:34,790] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T02:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:34,790] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 2, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:34,790] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T02:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:34,790] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 2, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:34,790] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T02:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:34,790] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 2, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:34,791] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T02:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:35,274] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 02:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:35,277] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 02:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:35,278] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 02:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:35,407] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 02:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:35,408] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 02:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:35,410] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 02:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:35,412] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 02:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:35,421] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 02:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:35,429] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 02:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:35,430] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 02:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:35,437] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 02:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:35,438] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 02:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:35,440] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 02:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:35,453] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 02:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:35,462] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 02:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:35,464] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 02:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:46,745] {scheduler_job.py:961} INFO - 39 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:45:00+00:00 [scheduled]>
[2020-11-11 16:23:46,756] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 112 open slots and 39 task instances ready to be queued
[2020-11-11 16:23:46,757] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,758] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,758] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,758] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,759] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,759] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,760] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,760] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,761] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,761] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,762] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,762] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,762] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,762] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,763] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,763] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,763] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,763] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,763] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,763] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,763] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,763] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,763] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,764] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,764] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,764] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,764] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,764] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,764] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,764] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,764] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,764] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,764] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,765] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,765] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,765] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,765] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,765] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,765] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,765] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,765] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,765] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,765] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,765] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,766] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,766] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,766] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,766] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,766] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,766] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,766] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,766] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,766] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,766] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,766] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,767] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,767] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,767] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,767] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,767] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,767] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,767] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,767] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,767] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,767] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,767] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,768] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,768] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,768] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,768] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,768] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,768] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,768] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,768] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,768] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,768] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,768] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:46,768] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:46,771] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	
[2020-11-11 16:23:58,751] {scheduler_job.py:961} INFO - 41 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:45:00+00:00 [scheduled]>
[2020-11-11 16:23:58,753] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 41 task instances ready to be queued
[2020-11-11 16:23:58,754] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:23:58,754] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:23:58,754] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:23:58,754] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:23:58,754] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:23:58,754] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:23:58,754] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:23:58,754] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:23:58,754] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:23:58,754] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:23:58,754] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:23:58,755] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:23:58,755] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:23:58,755] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:23:58,755] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:23:58,755] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:23:58,755] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:58,755] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:58,755] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:58,755] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:58,755] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:58,755] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:58,756] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:58,756] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:58,756] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:58,756] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:58,756] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:58,756] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:58,756] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:58,756] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:58,756] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:58,756] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:58,756] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:58,757] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:58,757] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:58,757] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:58,757] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:58,757] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:58,757] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:58,757] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:58,757] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:58,757] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:58,757] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:58,757] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:58,758] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:58,758] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:58,758] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:58,758] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:58,758] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:58,758] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:58,758] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:58,758] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:58,758] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:58,758] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:58,758] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:58,758] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:58,759] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:58,759] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:58,759] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:58,759] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:58,759] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:58,759] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:58,759] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:58,759] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:58,759] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:23:58,759] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:23:58,761] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:40:00+00:00 [scheduled]>
[2020-11-11 16:23:58,776] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:35:00+00:00 [queued]>
[2020-11-11 16:23:58,777] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 2, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:58,777] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T02:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:58,777] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 2, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:58,777] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T02:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:58,777] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 2, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:58,777] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T02:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:58,777] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 2, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:58,777] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T02:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:58,777] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 2, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:58,778] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T02:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:58,778] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 2, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:58,778] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T02:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:58,778] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 2, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:58,779] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T02:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:58,779] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 2, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:58,779] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T02:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:58,779] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 2, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:58,779] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T02:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:58,779] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 2, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:58,779] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T02:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:58,779] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 2, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:58,779] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T02:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:58,779] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 2, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:58,780] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T02:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:58,780] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 2, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:58,780] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T02:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:58,780] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 2, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:58,780] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T02:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:58,780] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 2, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:58,780] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T02:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:58,780] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 2, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:23:58,780] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T02:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:23:58,931] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 02:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:58,933] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 02:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:58,935] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 02:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:58,937] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 02:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:58,939] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 02:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:58,940] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 02:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:58,943] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 02:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:58,946] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 02:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:58,954] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 02:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:58,958] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 02:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:58,963] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 02:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:58,967] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 02:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:58,972] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 02:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:58,977] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 02:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:58,983] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 02:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:23:58,989] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 02:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:10,752] {scheduler_job.py:961} INFO - 25 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:45:00+00:00 [scheduled]>
[2020-11-11 16:24:10,756] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 112 open slots and 25 task instances ready to be queued
[2020-11-11 16:24:10,757] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:10,757] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:10,757] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:10,757] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:10,757] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:10,757] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:10,758] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:10,758] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:10,758] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:10,758] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:10,758] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:10,758] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:10,758] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:10,759] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:10,759] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:10,759] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:10,759] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:10,759] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:10,759] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:10,759] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:10,760] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:10,760] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:10,760] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:10,760] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:10,760] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:10,760] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:10,760] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:10,761] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:10,761] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:10,761] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:10,761] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:10,761] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:10,761] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:10,761] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:10,761] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:10,762] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:10,762] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:10,762] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:10,762] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:10,762] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:10,762] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:10,762] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:10,762] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:10,763] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:10,763] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:10,763] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:10,763] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:10,763] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:10,763] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:10,763] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:10,767] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	
[2020-11-11 16:24:22,773] {scheduler_job.py:961} INFO - 26 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:45:00+00:00 [scheduled]>
[2020-11-11 16:24:22,783] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 26 task instances ready to be queued
[2020-11-11 16:24:22,784] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:24:22,785] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:24:22,785] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:24:22,786] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:24:22,786] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:24:22,786] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:24:22,787] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:24:22,787] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:24:22,788] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:24:22,788] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:24:22,789] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:24:22,789] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:24:22,789] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:24:22,790] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:24:22,790] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:24:22,791] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:24:22,791] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:22,791] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:22,792] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:22,792] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:22,793] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:22,793] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:22,794] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:22,794] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:22,795] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:22,795] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:22,795] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:22,796] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:22,796] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:22,797] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:22,797] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:22,797] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:22,798] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:22,798] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:22,799] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:22,799] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:22,809] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:45:00+00:00 [scheduled]>
[2020-11-11 16:24:22,837] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:45:00+00:00 [queued]>
[2020-11-11 16:24:22,837] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 1, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:24:22,838] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T01:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:22,838] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 1, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:24:22,838] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T01:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:22,838] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 1, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:24:22,839] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T01:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:22,839] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 1, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:24:22,839] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T01:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:22,839] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 2, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:24:22,839] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T02:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:22,840] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 2, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:24:22,840] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T02:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:22,840] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 2, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:24:22,840] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T02:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:22,840] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 2, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:24:22,840] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T02:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:22,841] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 2, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:24:22,841] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T02:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:22,841] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 2, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:24:22,841] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T02:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:22,841] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 2, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:24:22,842] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T02:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:22,842] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 2, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:24:22,842] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T02:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:22,842] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 2, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:24:22,842] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T02:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:22,842] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 2, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:24:22,843] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T02:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:22,843] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 2, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:24:22,843] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T02:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:22,843] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 2, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:24:22,843] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T02:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:23,041] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 02:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:23,044] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 02:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:23,045] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 02:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:23,048] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 02:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:23,049] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 02:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:23,051] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 02:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:23,058] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 02:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:23,060] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 02:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:23,065] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 02:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:23,067] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 02:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:23,079] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 02:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:23,081] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 02:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:23,083] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 02:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:23,085] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 02:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:23,094] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 02:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:23,101] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 02:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:34,768] {scheduler_job.py:961} INFO - 10 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:35:00+00:00 [scheduled]>
[2020-11-11 16:24:34,772] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 116 open slots and 10 task instances ready to be queued
[2020-11-11 16:24:34,772] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:24:34,772] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:24:34,772] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:24:34,772] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:24:34,773] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:34,773] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:34,773] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:34,773] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:34,773] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:34,773] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:34,773] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:34,773] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:34,774] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:34,774] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:34,774] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:24:34,774] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:24:34,777] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:05:00+00:00 [scheduled]>
[2020-11-11 16:24:34,788] {scheduler_job.py:1158} INFO - Setting the following 4 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 01:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:05:00+00:00 [queued]>
[2020-11-11 16:24:34,788] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 1, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:24:34,789] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T01:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:34,789] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 1, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:24:34,789] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T01:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:34,789] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 2, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:24:34,789] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T02:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:34,789] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 2, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:24:34,789] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T02:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:34,893] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 01:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:34,896] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 01:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:34,898] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 01:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:34,899] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 01:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:46,774] {scheduler_job.py:961} INFO - 9 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:45:00+00:00 [scheduled]>
[2020-11-11 16:24:46,777] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 9 task instances ready to be queued
[2020-11-11 16:24:46,777] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:24:46,777] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:24:46,777] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:24:46,778] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:24:46,778] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:24:46,778] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:24:46,778] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:24:46,778] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:24:46,778] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:24:46,780] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:45:00+00:00 [scheduled]>
[2020-11-11 16:24:46,794] {scheduler_job.py:1158} INFO - Setting the following 9 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:45:00+00:00 [queued]>
[2020-11-11 16:24:46,795] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 2, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:24:46,795] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T02:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:46,795] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 2, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:24:46,795] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T02:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:46,795] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 2, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:24:46,795] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T02:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:46,795] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 2, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:24:46,796] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T02:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:46,796] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 2, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:24:46,796] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T02:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:46,796] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 2, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:24:46,796] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T02:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:46,796] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 2, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:24:46,796] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T02:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:46,796] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 2, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:24:46,796] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T02:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:46,796] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 2, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:24:46,797] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T02:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:46,992] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 02:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:46,995] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 02:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:46,997] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 02:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:46,999] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 02:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:47,000] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 02:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:47,002] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 02:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:47,007] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 02:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:47,017] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 02:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:47,020] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 02:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:47,022] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 02:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:47,024] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 02:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:47,027] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 02:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:47,031] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 01:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:47,038] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 01:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:47,049] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 02:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:47,051] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 02:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:58,805] {scheduler_job.py:961} INFO - 11 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:50:00+00:00 [scheduled]>
[2020-11-11 16:24:58,816] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 11 task instances ready to be queued
[2020-11-11 16:24:58,817] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:24:58,817] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:24:58,818] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:24:58,818] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:24:58,818] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:24:58,819] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:24:58,819] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:24:58,820] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:24:58,820] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:24:58,821] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:24:58,821] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:24:58,831] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:50:00+00:00 [scheduled]>
[2020-11-11 16:24:58,870] {scheduler_job.py:1158} INFO - Setting the following 11 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 02:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:50:00+00:00 [queued]>
[2020-11-11 16:24:58,871] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 2, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:24:58,872] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T02:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:58,872] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 2, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:24:58,873] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T02:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:58,873] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 2, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:24:58,874] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T02:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:58,874] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 2, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:24:58,875] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T02:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:58,875] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 2, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:24:58,875] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T02:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:58,876] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 2, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:24:58,876] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T02:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:58,877] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 2, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:24:58,877] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T02:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:58,878] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 2, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:24:58,878] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T02:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:58,879] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 2, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:24:58,879] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T02:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:58,880] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 2, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:24:58,880] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T02:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:58,881] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 2, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:24:58,881] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T02:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:24:59,054] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 02:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:59,057] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 02:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:59,059] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 02:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:59,061] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 02:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:59,063] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 02:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:59,065] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 02:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:59,067] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 02:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:59,070] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 02:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:24:59,072] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 02:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:10,808] {scheduler_job.py:961} INFO - 11 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:55:00+00:00 [scheduled]>
[2020-11-11 16:25:10,813] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 121 open slots and 11 task instances ready to be queued
[2020-11-11 16:25:10,813] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:25:10,813] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:25:10,813] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:25:10,813] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:25:10,814] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:25:10,814] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:25:10,814] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:25:10,814] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:25:10,814] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:25:10,814] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:25:10,815] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:25:10,815] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:25:10,815] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:25:10,819] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:55:00+00:00 [scheduled]>
[2020-11-11 16:25:10,832] {scheduler_job.py:1158} INFO - Setting the following 9 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 02:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 02:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 02:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 02:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 02:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 02:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 02:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 02:55:00+00:00 [queued]>
[2020-11-11 16:25:10,832] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 3, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:25:10,832] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T03:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:10,832] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 2, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:10,832] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T02:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:10,833] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 2, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:10,833] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T02:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:10,833] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 2, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:10,833] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T02:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:10,833] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 2, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:10,833] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T02:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:10,833] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 2, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:10,833] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T02:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:10,833] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 2, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:10,834] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T02:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:10,834] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 2, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:10,834] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T02:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:10,834] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 2, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:10,834] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T02:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:11,050] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 02:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:22,829] {scheduler_job.py:961} INFO - 14 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:00:00+00:00 [scheduled]>
[2020-11-11 16:25:22,839] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 14 task instances ready to be queued
[2020-11-11 16:25:22,840] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:25:22,840] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:25:22,841] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:25:22,841] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:25:22,842] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:25:22,842] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:25:22,843] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:25:22,843] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:25:22,844] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:25:22,844] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:25:22,845] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:25:22,845] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:25:22,845] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:25:22,846] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:25:22,852] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:50:00+00:00 [scheduled]>
[2020-11-11 16:25:22,871] {scheduler_job.py:1158} INFO - Setting the following 14 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 02:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 02:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:00:00+00:00 [queued]>
[2020-11-11 16:25:22,871] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 3, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:25:22,872] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T03:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:22,872] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 2, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:25:22,872] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T02:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:22,872] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 3, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:22,872] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T03:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:22,873] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 3, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:22,873] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T03:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:22,873] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 3, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:22,873] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T03:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:22,873] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 3, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:22,873] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T03:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:22,873] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 3, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:22,873] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T03:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:22,874] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 3, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:22,874] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T03:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:22,874] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 3, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:22,874] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T03:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:22,874] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 3, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:22,874] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T03:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:22,874] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 2, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:22,875] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T02:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:22,875] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 3, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:22,875] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T03:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:22,875] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 2, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:22,875] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T02:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:22,875] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 3, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:22,875] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T03:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:23,091] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 02:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:23,094] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 02:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:23,096] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 02:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:23,098] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 02:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:23,099] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 02:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:23,101] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 02:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:23,105] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 02:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:23,109] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 02:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:23,121] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 02:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:23,122] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 02:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:23,134] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 03:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:34,821] {scheduler_job.py:961} INFO - 11 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:05:00+00:00 [scheduled]>
[2020-11-11 16:25:34,825] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 117 open slots and 11 task instances ready to be queued
[2020-11-11 16:25:34,825] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:25:34,825] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:25:34,825] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:25:34,825] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:25:34,826] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:25:34,826] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:25:34,826] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:25:34,826] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:25:34,826] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:25:34,826] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:25:34,827] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:25:34,827] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:25:34,827] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:25:34,827] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:25:34,827] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:25:34,827] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:25:34,828] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:25:34,831] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:05:00+00:00 [scheduled]>
[2020-11-11 16:25:34,845] {scheduler_job.py:1158} INFO - Setting the following 5 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:05:00+00:00 [queued]>
[2020-11-11 16:25:34,845] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 3, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:25:34,845] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T03:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:34,845] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 3, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:34,846] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T03:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:34,846] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 3, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:34,846] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T03:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:34,847] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 3, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:34,847] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T03:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:34,847] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 3, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:34,847] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T03:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:34,997] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 02:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:35,000] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 02:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:35,002] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 02:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:35,004] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 02:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:35,007] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 02:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:35,009] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 02:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:35,012] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 02:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:35,014] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 02:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:35,016] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 03:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:35,018] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 02:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:48,857] {scheduler_job.py:961} INFO - 19 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:10:00+00:00 [scheduled]>
[2020-11-11 16:25:48,867] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 19 task instances ready to be queued
[2020-11-11 16:25:48,868] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:25:48,869] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:25:48,869] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:25:48,870] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:25:48,870] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:25:48,870] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:25:48,871] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:25:48,871] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:25:48,872] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:25:48,872] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:25:48,873] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:25:48,873] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:25:48,873] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:25:48,874] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:25:48,874] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:25:48,875] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:25:48,875] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:25:48,875] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:25:48,876] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:25:48,876] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:25:48,877] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:25:48,877] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:25:48,886] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:10:00+00:00 [scheduled]>
[2020-11-11 16:25:48,912] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:05:00+00:00 [queued]>
[2020-11-11 16:25:48,912] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 3, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:25:48,912] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T03:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:48,913] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 3, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:48,913] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T03:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:48,913] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 3, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:48,913] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T03:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:48,913] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 3, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:48,913] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T03:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:48,913] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 3, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:48,913] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T03:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:48,913] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 3, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:48,913] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T03:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:48,914] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 3, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:48,914] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T03:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:48,914] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 3, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:48,914] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T03:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:48,914] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 3, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:48,914] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T03:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:48,914] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 3, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:48,914] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T03:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:48,914] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 3, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:48,915] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T03:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:48,915] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 3, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:48,915] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T03:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:48,915] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 3, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:48,915] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T03:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:48,915] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 3, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:48,915] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T03:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:48,915] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 3, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:48,915] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T03:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:48,915] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 3, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:25:48,916] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T03:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:25:49,087] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 03:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:49,090] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 03:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:49,093] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 03:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:49,095] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 03:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:49,097] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 03:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:49,100] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 03:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:49,115] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 03:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:49,117] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 03:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:49,119] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 02:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:49,131] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 03:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:49,133] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 02:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:49,139] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 03:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:25:49,141] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 03:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:00,846] {scheduler_job.py:961} INFO - 14 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:15:00+00:00 [scheduled]>
[2020-11-11 16:26:00,849] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 14 task instances ready to be queued
[2020-11-11 16:26:00,849] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:26:00,849] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:00,849] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:00,849] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:00,849] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:00,849] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:00,849] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:00,849] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:00,850] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:00,850] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:00,850] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:00,850] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:00,850] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:00,850] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:00,850] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:00,850] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:00,850] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:00,850] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:00,850] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:00,851] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:00,851] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:00,851] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:00,851] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:00,851] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:00,851] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:00,851] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:00,851] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:00,853] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:20:00+00:00 [scheduled]>
[2020-11-11 16:26:00,860] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:20:00+00:00 [queued]>
[2020-11-11 16:26:00,860] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 3, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:26:00,860] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T03:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:00,918] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 03:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:00,921] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 03:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:00,922] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 03:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:00,924] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 03:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:00,925] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 03:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:12,877] {scheduler_job.py:961} INFO - 25 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:20:00+00:00 [scheduled]>
[2020-11-11 16:26:12,884] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 25 task instances ready to be queued
[2020-11-11 16:26:12,884] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:26:12,884] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:26:12,885] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:26:12,885] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:26:12,885] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:26:12,885] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:26:12,886] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:26:12,886] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:26:12,886] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:26:12,886] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:26:12,886] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:26:12,887] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:26:12,887] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:26:12,887] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:26:12,887] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:26:12,887] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:26:12,887] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:12,888] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:12,888] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:12,888] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:12,888] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:12,888] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:12,889] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:12,889] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:12,889] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:12,889] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:12,889] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:12,889] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:12,890] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:12,890] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:12,890] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:12,890] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:12,890] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:12,890] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:12,894] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:20:00+00:00 [scheduled]>
[2020-11-11 16:26:12,913] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:15:00+00:00 [queued]>
[2020-11-11 16:26:12,913] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 3, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:26:12,914] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T03:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:12,914] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 3, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:26:12,914] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T03:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:12,914] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 3, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:26:12,914] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T03:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:12,914] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 3, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:26:12,914] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T03:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:12,914] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 3, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:26:12,914] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T03:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:12,915] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 3, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:26:12,915] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T03:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:12,915] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 3, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:26:12,915] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T03:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:12,915] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 3, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:26:12,915] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T03:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:12,915] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 3, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:26:12,915] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T03:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:12,915] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 3, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:26:12,915] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T03:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:12,915] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 3, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:26:12,916] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T03:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:12,916] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 3, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:26:12,916] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T03:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:12,916] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 3, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:26:12,916] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T03:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:12,916] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 3, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:26:12,916] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T03:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:12,916] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 3, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:26:12,916] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T03:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:12,916] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 3, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:26:12,916] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T03:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:13,100] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 03:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:13,103] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 03:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:13,105] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 03:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:13,106] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 03:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:13,108] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 03:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:13,110] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 03:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:13,114] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 03:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:13,125] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 03:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:13,127] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 03:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:13,130] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 03:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:13,134] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 03:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:13,141] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 03:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:13,144] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 03:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:13,147] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 03:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:13,153] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 03:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:13,165] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 03:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:24,866] {scheduler_job.py:961} INFO - 20 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:25:00+00:00 [scheduled]>
[2020-11-11 16:26:24,869] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 20 task instances ready to be queued
[2020-11-11 16:26:24,870] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:26:24,870] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:24,870] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:24,870] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:24,870] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:24,870] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:24,870] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:24,871] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:24,871] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:24,871] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:24,871] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:24,871] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:24,871] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:24,871] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:24,872] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:24,872] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:24,872] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:24,872] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:24,872] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:24,872] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:24,872] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:24,873] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:24,873] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:24,873] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:24,873] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:24,873] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:24,873] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:24,873] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:24,874] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:24,874] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:24,874] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:24,874] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:24,874] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:24,874] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:24,874] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:24,875] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:24,875] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:24,875] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:24,875] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:24,878] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:30:00+00:00 [scheduled]>
[2020-11-11 16:26:24,886] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:30:00+00:00 [queued]>
[2020-11-11 16:26:24,886] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 3, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:26:24,886] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T03:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:24,949] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 03:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:36,879] {scheduler_job.py:961} INFO - 32 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:30:00+00:00 [scheduled]>
[2020-11-11 16:26:36,882] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 32 task instances ready to be queued
[2020-11-11 16:26:36,882] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:26:36,882] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:26:36,882] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:26:36,882] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:26:36,882] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:26:36,883] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:26:36,883] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:26:36,883] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:26:36,883] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:26:36,883] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:26:36,883] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:26:36,883] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:26:36,883] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:26:36,883] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:26:36,883] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:26:36,883] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:26:36,884] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:36,884] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:36,884] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:36,884] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:36,884] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:36,884] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:36,884] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:36,884] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:36,884] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:36,884] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:36,885] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:36,885] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:36,885] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:36,885] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:36,885] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:36,885] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:36,885] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:36,885] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:36,885] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:36,885] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:36,885] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:36,886] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:36,886] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:36,886] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:36,886] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:36,886] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:36,886] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:36,886] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:36,886] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:36,886] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:36,886] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:36,886] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:36,888] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:25:00+00:00 [scheduled]>
[2020-11-11 16:26:36,905] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:20:00+00:00 [queued]>
[2020-11-11 16:26:36,905] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 3, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:26:36,905] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T03:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:36,905] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 3, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:26:36,905] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T03:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:36,905] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 3, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:26:36,905] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T03:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:36,906] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 3, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:26:36,906] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T03:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:36,906] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 3, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:26:36,906] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T03:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:36,906] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 3, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:26:36,907] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T03:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:36,907] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 3, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:26:36,907] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T03:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:36,907] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 3, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:26:36,907] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T03:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:36,907] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 3, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:26:36,907] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T03:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:36,907] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 3, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:26:36,907] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T03:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:36,908] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 3, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:26:36,908] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T03:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:36,908] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 3, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:26:36,908] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T03:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:36,908] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 3, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:26:36,908] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T03:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:36,908] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 3, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:26:36,908] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T03:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:36,908] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 3, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:26:36,908] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T03:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:36,908] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 3, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:26:36,909] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T03:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:37,089] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 03:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:37,092] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 03:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:37,094] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 03:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:37,095] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 03:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:37,097] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 03:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:37,098] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 03:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:37,109] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 03:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:37,113] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 03:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:37,115] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 03:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:37,121] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 03:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:37,123] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 03:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:37,126] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 03:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:37,137] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 03:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:37,145] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 03:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:37,147] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 03:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:37,149] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 03:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:26:48,915] {scheduler_job.py:961} INFO - 27 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:35:00+00:00 [scheduled]>
[2020-11-11 16:26:48,926] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 27 task instances ready to be queued
[2020-11-11 16:26:48,927] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:26:48,927] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:48,928] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:48,928] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:48,928] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:48,929] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:48,929] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:48,929] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:48,930] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:48,930] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:48,930] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:48,931] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:48,931] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:48,931] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:48,931] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:48,931] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:48,932] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:48,932] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:48,932] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:48,932] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:48,933] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:48,933] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:48,933] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:48,933] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:48,933] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:48,934] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:48,934] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:48,934] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:48,934] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:48,935] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:48,935] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:48,935] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:48,935] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:48,935] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:48,936] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:48,936] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:48,936] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:48,936] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:48,936] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:48,936] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:48,937] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:48,937] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:48,937] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:48,937] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:48,937] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:48,938] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:48,938] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:48,938] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:48,938] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:48,938] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:48,938] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:48,939] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:26:48,939] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:26:48,943] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:40:00+00:00 [scheduled]>
[2020-11-11 16:26:48,950] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:40:00+00:00 [queued]>
[2020-11-11 16:26:48,951] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 3, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:26:48,951] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T03:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:26:49,032] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 03:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:00,926] {scheduler_job.py:961} INFO - 38 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:40:00+00:00 [scheduled]>
[2020-11-11 16:27:00,936] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 38 task instances ready to be queued
[2020-11-11 16:27:00,936] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:27:00,937] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:27:00,937] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:27:00,938] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:27:00,938] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:27:00,938] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:27:00,938] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:27:00,939] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:27:00,939] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:27:00,939] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:27:00,939] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:27:00,939] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:27:00,940] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:27:00,940] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:27:00,940] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:27:00,940] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:27:00,941] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:00,941] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:00,941] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:00,941] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:00,942] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:00,942] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:00,942] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:00,942] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:00,942] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:00,943] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:00,943] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:00,943] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:00,943] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:00,943] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:00,944] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:00,944] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:00,944] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:00,944] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:00,944] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:00,945] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:00,945] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:00,945] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:00,945] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:00,945] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:00,945] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:00,946] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:00,946] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:00,946] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:00,946] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:00,946] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:00,946] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:00,947] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:00,947] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:00,947] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:00,947] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:00,947] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:00,947] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:00,948] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:00,948] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:00,948] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:00,948] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:00,948] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:00,948] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:00,949] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:00,952] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:35:00+00:00 [scheduled]>
[2020-11-11 16:27:00,969] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:30:00+00:00 [queued]>
[2020-11-11 16:27:00,970] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 3, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:27:00,971] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T03:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:00,971] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 3, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:00,972] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T03:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:00,972] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 3, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:00,973] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T03:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:00,973] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 3, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:00,974] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T03:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:00,974] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 3, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:00,974] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T03:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:00,975] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 3, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:00,975] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T03:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:00,976] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 3, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:00,976] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T03:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:00,977] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 3, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:00,977] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T03:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:00,978] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 3, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:00,978] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T03:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:00,978] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 3, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:00,979] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T03:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:00,979] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 3, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:00,980] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T03:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:00,980] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 3, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:00,981] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T03:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:00,981] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 3, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:00,982] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T03:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:00,982] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 3, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:00,982] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T03:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:00,983] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 3, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:00,983] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T03:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:00,984] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 3, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:00,984] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T03:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:01,181] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 03:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:01,184] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 03:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:01,186] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 03:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:01,188] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 03:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:01,190] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 03:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:01,192] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 03:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:01,197] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 03:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:01,199] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 03:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:01,202] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 03:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:01,217] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 03:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:01,219] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 03:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:01,229] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 03:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:01,231] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 03:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:01,234] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 03:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:01,237] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 03:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:01,239] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 03:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:12,911] {scheduler_job.py:961} INFO - 33 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:45:00+00:00 [scheduled]>
[2020-11-11 16:27:12,915] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 33 task instances ready to be queued
[2020-11-11 16:27:12,915] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:27:12,916] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:12,916] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:12,916] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:12,916] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:12,916] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:12,917] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:12,917] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:12,917] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:12,917] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:12,917] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:12,917] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:12,917] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:12,917] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:12,917] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:12,918] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:12,918] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:12,918] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:12,918] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:12,918] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:12,918] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:12,918] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:12,918] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:12,918] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:12,919] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:12,919] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:12,919] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:12,919] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:12,919] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:12,919] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:12,919] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:12,919] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:12,919] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:12,919] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:12,919] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:12,919] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:12,920] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:12,920] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:12,920] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:12,920] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:12,920] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:12,920] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:12,920] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:12,920] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:12,920] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:12,920] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:12,920] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:12,921] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:12,921] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:12,921] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:12,921] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:12,921] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:12,921] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:12,921] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:12,921] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:12,921] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:12,921] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:12,921] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:12,921] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:12,922] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:12,922] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:12,922] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:12,922] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:12,922] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:12,922] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:12,925] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:50:00+00:00 [scheduled]>
[2020-11-11 16:27:12,934] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:50:00+00:00 [queued]>
[2020-11-11 16:27:12,935] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 3, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:27:12,935] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T03:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:12,992] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 03:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:24,924] {scheduler_job.py:961} INFO - 45 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:50:00+00:00 [scheduled]>
[2020-11-11 16:27:24,926] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 45 task instances ready to be queued
[2020-11-11 16:27:24,927] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:27:24,927] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:27:24,927] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:27:24,927] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:27:24,927] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:27:24,927] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:27:24,927] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:27:24,927] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:27:24,927] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:27:24,927] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:27:24,928] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:27:24,928] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:27:24,928] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:27:24,928] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:27:24,928] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:27:24,928] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:27:24,928] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:24,928] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:24,928] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:24,928] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:24,928] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:24,929] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:24,929] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:24,929] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:24,929] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:24,929] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:24,929] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:24,929] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:24,929] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:24,929] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:24,929] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:24,930] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:24,930] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:24,930] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:24,930] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:24,930] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:24,930] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:24,930] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:24,930] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:24,930] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:24,930] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:24,930] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:24,931] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:24,931] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:24,931] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:24,931] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:24,931] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:24,931] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:24,931] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:24,931] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:24,931] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:24,931] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:24,931] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:24,932] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:24,932] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:24,932] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:24,932] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:24,932] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:24,932] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:24,932] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:24,932] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:24,932] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:24,932] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:24,932] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:24,933] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:24,933] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:24,933] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:24,933] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:24,933] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:24,933] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:24,933] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:24,933] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:24,933] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:24,933] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:24,935] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:40:00+00:00 [scheduled]>
[2020-11-11 16:27:24,953] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 03:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:35:00+00:00 [queued]>
[2020-11-11 16:27:24,954] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 3, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:27:24,955] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T03:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:24,955] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 3, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:24,956] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T03:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:24,957] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 3, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:24,957] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T03:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:24,957] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 3, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:24,958] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T03:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:24,958] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 3, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:24,959] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T03:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:24,959] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 3, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:24,960] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T03:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:24,960] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 3, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:24,961] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T03:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:24,961] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 3, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:24,962] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T03:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:24,962] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 3, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:24,962] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T03:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:24,963] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 3, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:24,963] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T03:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:24,964] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 3, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:24,964] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T03:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:24,965] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 3, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:24,965] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T03:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:24,966] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 3, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:24,966] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T03:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:24,966] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 3, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:24,967] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T03:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:24,967] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 3, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:24,968] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T03:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:24,968] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 3, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:24,969] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T03:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:25,178] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 03:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:25,181] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 03:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:25,183] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 03:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:25,185] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 03:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:25,187] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 03:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:25,189] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 03:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:25,198] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 03:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:25,201] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 03:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:25,203] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 03:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:25,205] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 03:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:25,219] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 03:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:25,221] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 03:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:25,224] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 03:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:25,226] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 03:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:25,228] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 03:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:25,230] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 03:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:36,960] {scheduler_job.py:961} INFO - 40 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:55:00+00:00 [scheduled]>
[2020-11-11 16:27:36,970] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 40 task instances ready to be queued
[2020-11-11 16:27:36,970] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:27:36,971] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,971] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,971] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,972] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,972] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,972] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,972] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,973] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,973] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,973] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,974] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,974] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,974] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,974] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,975] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,975] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,975] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,975] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,975] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,975] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,976] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,976] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,977] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,977] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,977] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,977] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,977] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,978] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,978] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,978] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,978] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,978] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,978] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,979] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,979] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,979] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,979] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,980] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,980] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,980] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,980] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,980] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,981] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,981] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,981] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,981] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,981] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,981] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,982] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,982] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,982] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,982] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,982] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,983] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,983] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,983] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,983] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,983] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,983] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,984] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,984] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,984] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,984] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,984] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,984] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,985] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,985] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,985] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,985] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,985] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,986] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,986] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,986] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,986] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,986] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,986] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,987] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:36,987] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:36,991] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:00:00+00:00 [scheduled]>
[2020-11-11 16:27:36,999] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:00:00+00:00 [queued]>
[2020-11-11 16:27:36,999] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 4, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:27:36,999] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T04:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:37,070] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 03:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:48,941] {scheduler_job.py:961} INFO - 51 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:00:00+00:00 [scheduled]>
[2020-11-11 16:27:48,944] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 51 task instances ready to be queued
[2020-11-11 16:27:48,944] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:27:48,944] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:27:48,944] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:27:48,944] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:27:48,944] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:27:48,944] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:27:48,944] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:27:48,945] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:27:48,945] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:27:48,945] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:27:48,945] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:27:48,945] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:27:48,945] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:27:48,945] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:27:48,945] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:27:48,945] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:27:48,945] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,945] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,946] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,946] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,946] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,946] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,946] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,946] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,946] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,946] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,946] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,946] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,946] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,947] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,947] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,947] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,947] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,947] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,947] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,947] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,947] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,947] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,947] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,947] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,948] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,948] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,948] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,948] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,948] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,948] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,948] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,948] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,948] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,948] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,948] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,948] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,949] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,949] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,949] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,949] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,949] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,949] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,949] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,949] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,949] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,949] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,949] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,950] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,950] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,950] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,950] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,950] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,950] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,950] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,950] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,950] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,950] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,950] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,950] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,951] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,951] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,951] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,951] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,951] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,951] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,951] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,951] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,951] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,951] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:27:48,951] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:27:48,954] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:50:00+00:00 [scheduled]>
[2020-11-11 16:27:48,971] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:45:00+00:00 [queued]>
[2020-11-11 16:27:48,971] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 4, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:27:48,972] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T04:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:48,972] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 3, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:48,972] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T03:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:48,972] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 3, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:48,972] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T03:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:48,972] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 3, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:48,972] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T03:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:48,972] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 3, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:48,973] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T03:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:48,973] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 3, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:48,973] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T03:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:48,973] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 3, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:48,973] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T03:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:48,973] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 3, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:48,973] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T03:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:48,973] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 3, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:48,973] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T03:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:48,973] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 3, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:48,973] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T03:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:48,974] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 3, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:48,974] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T03:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:48,974] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 3, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:48,974] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T03:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:48,974] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 3, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:48,974] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T03:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:48,974] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 3, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:48,974] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T03:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:48,974] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 3, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:48,974] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T03:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:48,975] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 3, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:27:48,975] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T03:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:27:49,161] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 03:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:49,164] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 03:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:49,165] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 03:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:49,167] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 03:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:49,168] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 03:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:49,170] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 03:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:49,172] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 03:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:49,181] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 03:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:49,189] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 03:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:49,191] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 03:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:49,192] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 03:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:49,200] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 03:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:49,208] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 03:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:49,221] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 03:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:49,223] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 03:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:27:49,230] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 04:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:00,983] {scheduler_job.py:961} INFO - 46 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:05:00+00:00 [scheduled]>
[2020-11-11 16:28:00,991] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 46 task instances ready to be queued
[2020-11-11 16:28:00,992] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:28:00,992] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:00,992] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:00,992] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:00,993] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:00,993] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:00,993] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:00,993] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:00,994] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:00,994] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:00,994] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:00,994] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:00,994] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:00,995] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:00,995] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:00,995] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:00,995] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:00,995] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:00,996] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:00,996] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:00,996] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:00,996] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:00,996] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:00,997] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:00,997] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:00,997] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:00,997] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:00,997] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:00,997] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:00,998] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:00,998] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:00,998] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:00,998] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:00,998] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:00,998] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:00,999] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:00,999] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:00,999] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:00,999] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:00,999] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:00,999] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:01,000] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:01,000] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:01,000] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:01,000] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:01,000] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:01,000] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:01,001] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:01,001] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:01,001] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:01,001] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:01,001] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:01,001] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:01,001] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:01,001] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:01,002] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:01,002] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:01,002] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:01,002] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:01,002] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:01,002] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:01,003] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:01,003] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:01,003] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:01,003] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:01,003] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:01,003] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:01,003] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:01,003] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:01,004] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:01,004] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:01,004] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:01,004] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:01,004] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:01,004] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:01,004] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:01,005] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:01,005] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:01,005] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:01,005] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:01,005] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:01,005] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:01,005] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:01,006] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:01,006] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:01,006] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:01,006] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:01,006] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:01,006] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:01,006] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:01,006] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:01,009] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:10:00+00:00 [scheduled]>
[2020-11-11 16:28:01,022] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:10:00+00:00 [queued]>
[2020-11-11 16:28:01,023] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 4, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:28:01,023] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T04:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:01,106] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 04:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:12,963] {scheduler_job.py:961} INFO - 57 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:10:00+00:00 [scheduled]>
[2020-11-11 16:28:12,965] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 57 task instances ready to be queued
[2020-11-11 16:28:12,966] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:28:12,966] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:28:12,966] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:28:12,966] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:28:12,966] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:28:12,966] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:28:12,966] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:28:12,967] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:28:12,967] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:28:12,967] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:28:12,967] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:28:12,967] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:28:12,967] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:28:12,967] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:28:12,967] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:28:12,967] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:28:12,968] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,968] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,968] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,968] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,968] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,968] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,968] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,968] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,968] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,968] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,968] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,969] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,969] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,969] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,969] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,969] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,969] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,969] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,969] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,969] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,969] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,969] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,970] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,970] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,970] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,970] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,970] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,970] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,970] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,970] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,970] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,970] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,970] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,971] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,971] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,971] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,971] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,971] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,971] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,971] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,971] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,971] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,971] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,971] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,972] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,972] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,972] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,972] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,972] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,972] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,972] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,972] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,972] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,972] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,972] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,973] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,973] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,973] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,973] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,973] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,973] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,973] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,973] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,973] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,973] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,973] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,974] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,974] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,974] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,974] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,974] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,974] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,974] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,974] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,974] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,974] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,974] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,974] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,975] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,975] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,975] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:12,975] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:12,977] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:55:00+00:00 [scheduled]>
[2020-11-11 16:28:12,991] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 03:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 03:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 03:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 03:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 03:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 03:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 03:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 03:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 03:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 03:55:00+00:00 [queued]>
[2020-11-11 16:28:12,991] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 3, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:12,991] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T03:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:12,991] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 3, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:12,991] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T03:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:12,992] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 3, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:12,992] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T03:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:12,992] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 3, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:12,992] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T03:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:12,992] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 3, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:12,992] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T03:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:12,992] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 3, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:12,992] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T03:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:12,992] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 3, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:12,993] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T03:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:12,993] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 3, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:12,993] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T03:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:12,993] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 3, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:12,993] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T03:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:12,993] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 3, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:12,993] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T03:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:12,993] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 3, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:12,993] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T03:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:12,993] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 3, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:12,994] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T03:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:12,994] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 3, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:12,994] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T03:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:12,994] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 3, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:12,994] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T03:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:12,994] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 3, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:12,994] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T03:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:12,994] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 3, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:12,994] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T03:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:13,198] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 03:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:13,201] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 03:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:13,204] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 03:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:13,206] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 03:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:13,208] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 03:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:13,210] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 03:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:13,212] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 03:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:13,215] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 03:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:13,217] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 03:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:13,234] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 03:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:13,237] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 03:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:13,245] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 03:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:13,248] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 03:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:13,250] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 03:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:13,252] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 03:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:13,258] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 04:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:25,003] {scheduler_job.py:961} INFO - 41 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:10:00+00:00 [scheduled]>
[2020-11-11 16:28:25,013] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 41 task instances ready to be queued
[2020-11-11 16:28:25,013] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:28:25,013] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,014] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,014] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,014] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,014] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,015] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,015] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,015] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,015] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,016] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,016] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,016] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,016] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,016] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,017] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,017] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,017] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,017] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,018] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,018] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,018] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,018] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,018] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,018] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,019] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,019] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,019] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,019] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,019] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,020] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,020] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,020] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,020] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,020] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,020] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,021] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,021] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,021] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,021] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,021] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,021] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,022] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,022] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,022] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,022] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,022] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,022] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,023] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,023] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,023] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,023] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,023] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,023] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,024] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,024] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,024] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,024] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,024] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,024] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,024] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,025] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,025] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,025] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,025] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,025] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,025] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,025] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,026] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,026] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,026] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,026] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,026] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,026] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,026] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,027] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,027] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,027] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,027] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,027] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:25,027] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:25,030] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:00:00+00:00 [scheduled]>
[2020-11-11 16:28:25,038] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:00:00+00:00 [queued]>
[2020-11-11 16:28:25,038] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 4, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:25,038] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T04:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:36,985] {scheduler_job.py:961} INFO - 42 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:10:00+00:00 [scheduled]>
[2020-11-11 16:28:36,987] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 42 task instances ready to be queued
[2020-11-11 16:28:36,987] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:28:36,987] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:28:36,988] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:28:36,988] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:28:36,988] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:28:36,988] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:28:36,988] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:28:36,988] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:28:36,988] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:28:36,988] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:28:36,988] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:28:36,988] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:28:36,988] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:28:36,989] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:28:36,989] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:28:36,989] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:28:36,989] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:36,989] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:36,989] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:36,989] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:36,989] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:36,989] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:36,989] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:36,989] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:36,990] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:36,990] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:36,990] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:36,990] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:36,990] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:36,990] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:36,990] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:36,990] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:36,990] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:36,990] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:36,990] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:36,991] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:36,991] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:36,991] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:36,991] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:36,991] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:36,991] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:36,991] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:36,991] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:36,991] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:36,991] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:36,991] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:36,991] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:36,992] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:36,992] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:36,992] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:36,992] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:36,992] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:36,992] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:36,992] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:36,992] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:36,992] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:36,992] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:36,992] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:36,993] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:36,993] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:36,993] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:36,993] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:36,993] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:36,993] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:36,993] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:36,993] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:36,993] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:36,993] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:36,996] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:05:00+00:00 [scheduled]>
[2020-11-11 16:28:37,010] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:00:00+00:00 [queued]>
[2020-11-11 16:28:37,010] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 4, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:37,010] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T04:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:37,010] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 4, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:37,011] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T04:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:37,011] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 4, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:37,011] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T04:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:37,011] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 4, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:37,011] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T04:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:37,011] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 4, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:37,011] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T04:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:37,011] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 4, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:37,011] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T04:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:37,011] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 4, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:37,012] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T04:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:37,012] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 4, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:37,012] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T04:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:37,012] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 4, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:37,012] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T04:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:37,012] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 4, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:37,012] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T04:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:37,012] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 4, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:37,012] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T04:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:37,012] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 4, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:37,013] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T04:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:37,013] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 4, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:37,013] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T04:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:37,013] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 4, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:37,013] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T04:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:37,013] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 4, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:37,013] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T04:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:37,013] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 4, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:37,013] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T04:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:37,251] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 03:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:37,255] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 03:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:37,258] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 03:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:37,261] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 03:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:37,264] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 03:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:37,270] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 03:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:37,276] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 03:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:37,279] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 03:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:37,289] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 03:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:37,295] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 03:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:37,299] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 03:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:37,321] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 03:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:37,328] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 03:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:37,334] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 03:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:37,345] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 03:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:37,350] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 03:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:28:51,000] {scheduler_job.py:961} INFO - 26 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:10:00+00:00 [scheduled]>
[2020-11-11 16:28:51,003] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 26 task instances ready to be queued
[2020-11-11 16:28:51,003] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:28:51,003] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:28:51,003] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:28:51,003] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:28:51,003] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:28:51,004] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:28:51,004] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:28:51,004] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:28:51,004] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:28:51,004] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:28:51,004] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:28:51,004] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:28:51,004] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:28:51,004] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:28:51,004] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:28:51,004] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:28:51,005] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:51,005] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:51,005] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:51,005] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:51,005] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:51,005] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:51,005] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:51,005] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:51,005] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:51,005] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:51,006] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:51,006] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:51,006] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:51,006] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:51,006] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:51,006] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:51,006] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:51,006] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:51,006] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:28:51,006] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:28:51,008] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:05:00+00:00 [scheduled]>
[2020-11-11 16:28:51,023] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 02:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:10:00+00:00 [queued]>
[2020-11-11 16:28:51,023] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 2, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:28:51,023] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T02:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:51,024] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 3, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:28:51,024] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T03:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:51,024] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 3, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:28:51,024] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T03:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:51,024] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 4, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:51,024] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T04:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:51,024] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 4, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:51,024] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T04:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:51,025] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 4, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:51,025] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T04:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:51,025] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 4, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:51,025] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T04:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:51,025] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 4, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:51,025] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T04:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:51,025] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 4, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:51,025] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T04:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:51,025] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 4, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:51,025] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T04:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:51,026] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 4, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:51,026] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T04:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:51,026] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 4, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:51,026] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T04:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:51,026] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 4, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:51,026] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T04:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:51,026] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 4, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:51,026] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T04:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:51,026] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 4, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:51,026] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T04:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:51,026] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 4, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:28:51,027] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T04:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:28:51,230] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 04:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:03,030] {scheduler_job.py:961} INFO - 11 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:00:00+00:00 [scheduled]>
[2020-11-11 16:29:03,042] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 117 open slots and 11 task instances ready to be queued
[2020-11-11 16:29:03,043] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:29:03,043] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:29:03,044] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:29:03,045] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:29:03,045] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:29:03,046] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:29:03,046] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:29:03,047] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:29:03,047] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:29:03,047] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:29:03,048] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:29:03,048] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:29:03,049] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:29:03,049] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:29:03,050] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:29:03,050] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:29:03,051] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:29:03,060] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:30:00+00:00 [scheduled]>
[2020-11-11 16:29:03,078] {scheduler_job.py:1158} INFO - Setting the following 5 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:30:00+00:00 [queued]>
[2020-11-11 16:29:03,078] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 3, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:29:03,078] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T03:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:03,078] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 3, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:29:03,079] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T03:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:03,079] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 3, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:29:03,080] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T03:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:03,080] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 3, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:29:03,080] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T03:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:03,080] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 3, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:29:03,080] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T03:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:03,222] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 04:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:03,225] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 04:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:03,227] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 04:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:03,230] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 04:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:03,232] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 04:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:03,234] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 04:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:03,237] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 04:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:03,239] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 04:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:03,241] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 04:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:03,243] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 04:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:03,245] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 04:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:03,248] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 04:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:03,250] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 04:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:03,252] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 04:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:03,254] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 04:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:03,261] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 04:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:03,263] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 02:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:03,270] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 03:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:03,276] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 03:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:15,021] {scheduler_job.py:961} INFO - 9 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:10:00+00:00 [scheduled]>
[2020-11-11 16:29:15,024] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 9 task instances ready to be queued
[2020-11-11 16:29:15,024] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:29:15,024] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:29:15,024] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:29:15,024] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:29:15,024] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:29:15,024] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:29:15,025] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:29:15,025] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:29:15,025] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:29:15,027] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:10:00+00:00 [scheduled]>
[2020-11-11 16:29:15,039] {scheduler_job.py:1158} INFO - Setting the following 9 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 03:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:10:00+00:00 [queued]>
[2020-11-11 16:29:15,039] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 4, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:29:15,039] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T04:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:15,039] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 3, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:29:15,039] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T03:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:15,039] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 3, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:29:15,040] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T03:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:15,040] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 3, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:29:15,040] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T03:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:15,040] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 3, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:29:15,040] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T03:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:15,040] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 3, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:29:15,040] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T03:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:15,040] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 4, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:29:15,040] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T04:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:15,041] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 4, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:29:15,041] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T04:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:15,041] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 4, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:29:15,041] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T04:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:15,188] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 04:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:15,191] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 04:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:15,193] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 04:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:15,194] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 04:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:15,196] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 04:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:15,198] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 04:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:15,201] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 04:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:15,203] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 04:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:15,213] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 04:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:15,215] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 04:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:15,218] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 04:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:15,220] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 04:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:15,222] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 04:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:15,227] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 03:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:15,234] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 03:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:15,236] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 03:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:15,238] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 03:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:15,250] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 03:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:27,046] {scheduler_job.py:961} INFO - 11 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:15:00+00:00 [scheduled]>
[2020-11-11 16:29:27,052] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 11 task instances ready to be queued
[2020-11-11 16:29:27,053] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:29:27,053] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:29:27,053] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:29:27,054] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:29:27,054] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:29:27,054] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:29:27,054] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:29:27,054] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:29:27,055] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:29:27,055] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:29:27,055] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:29:27,059] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:15:00+00:00 [scheduled]>
[2020-11-11 16:29:27,076] {scheduler_job.py:1158} INFO - Setting the following 11 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:15:00+00:00 [queued]>
[2020-11-11 16:29:27,077] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 4, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:29:27,077] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T04:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:27,077] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 4, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:29:27,077] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T04:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:27,077] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 4, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:29:27,077] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T04:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:27,078] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 4, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:29:27,078] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T04:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:27,078] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 4, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:29:27,078] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T04:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:27,078] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 4, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:29:27,078] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T04:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:27,078] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 4, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:29:27,078] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T04:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:27,078] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 4, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:29:27,078] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T04:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:27,079] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 4, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:29:27,079] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T04:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:27,079] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 4, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:29:27,079] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T04:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:27,079] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 4, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:29:27,079] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T04:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:27,275] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 04:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:27,278] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 03:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:27,280] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 03:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:27,282] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 03:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:27,285] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 03:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:27,289] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 03:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:27,291] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 04:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:27,293] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 04:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:27,305] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 04:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:39,066] {scheduler_job.py:961} INFO - 11 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:20:00+00:00 [scheduled]>
[2020-11-11 16:29:39,077] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 120 open slots and 11 task instances ready to be queued
[2020-11-11 16:29:39,078] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:29:39,078] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:29:39,079] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:29:39,079] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:29:39,080] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:29:39,080] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:29:39,081] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:29:39,081] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:29:39,081] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:29:39,082] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:29:39,082] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:29:39,083] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:29:39,083] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:29:39,083] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:29:39,090] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:20:00+00:00 [scheduled]>
[2020-11-11 16:29:39,107] {scheduler_job.py:1158} INFO - Setting the following 8 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:20:00+00:00 [queued]>
[2020-11-11 16:29:39,108] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 4, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:29:39,108] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T04:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:39,108] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 4, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:29:39,108] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T04:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:39,109] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 4, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:29:39,109] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T04:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:39,109] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 4, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:29:39,110] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T04:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:39,110] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 4, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:29:39,110] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T04:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:39,110] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 4, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:29:39,110] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T04:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:39,110] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 4, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:29:39,111] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T04:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:39,111] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 4, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:29:39,111] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T04:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:39,253] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 04:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:51,078] {scheduler_job.py:961} INFO - 15 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:25:00+00:00 [scheduled]>
[2020-11-11 16:29:51,089] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 15 task instances ready to be queued
[2020-11-11 16:29:51,090] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:29:51,090] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:29:51,091] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:29:51,091] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:29:51,092] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:29:51,092] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:29:51,093] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:29:51,093] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:29:51,094] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:29:51,094] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:29:51,094] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:29:51,095] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:29:51,095] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:29:51,096] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:29:51,096] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:29:51,103] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:15:00+00:00 [scheduled]>
[2020-11-11 16:29:51,136] {scheduler_job.py:1158} INFO - Setting the following 15 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:25:00+00:00 [queued]>
[2020-11-11 16:29:51,136] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 4, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:29:51,137] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T04:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:51,137] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 4, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:29:51,138] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T04:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:51,138] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 4, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:29:51,139] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T04:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:51,139] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 4, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:29:51,139] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T04:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:51,140] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 4, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:29:51,140] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T04:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:51,140] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 4, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:29:51,141] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T04:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:51,141] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 4, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:29:51,141] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T04:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:51,141] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 4, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:29:51,142] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T04:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:51,142] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 4, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:29:51,142] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T04:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:51,143] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 4, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:29:51,143] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T04:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:51,143] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 4, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:29:51,144] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T04:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:51,144] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 4, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:29:51,144] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T04:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:51,145] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 4, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:29:51,145] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T04:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:51,145] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 4, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:29:51,146] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T04:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:51,146] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 4, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:29:51,146] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T04:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:29:51,330] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 04:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:51,333] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 04:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:51,335] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 04:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:51,337] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 04:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:51,340] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 04:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:51,342] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 04:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:51,351] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 04:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:51,362] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 04:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:51,365] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 04:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:51,367] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 04:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:29:51,377] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 04:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:03,065] {scheduler_job.py:961} INFO - 11 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:30:00+00:00 [scheduled]>
[2020-11-11 16:30:03,068] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 115 open slots and 11 task instances ready to be queued
[2020-11-11 16:30:03,068] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:30:03,068] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:30:03,068] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:30:03,068] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:03,069] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:03,069] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:03,069] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:03,069] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:03,069] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:03,069] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:03,069] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:03,070] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:03,070] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:03,070] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:03,070] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:03,070] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:03,070] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:03,070] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:03,070] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:03,073] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:30:00+00:00 [scheduled]>
[2020-11-11 16:30:03,080] {scheduler_job.py:1158} INFO - Setting the following 3 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:30:00+00:00 [queued]>
[2020-11-11 16:30:03,080] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 4, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:30:03,080] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T04:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:03,080] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 4, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:03,080] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T04:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:03,081] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 4, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:03,081] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T04:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:03,192] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 04:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:03,195] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 04:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:03,197] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 04:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:03,199] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 04:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:03,201] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 04:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:03,203] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 04:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:03,205] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 04:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:03,207] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 04:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:03,209] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 04:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:15,096] {scheduler_job.py:961} INFO - 21 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:35:00+00:00 [scheduled]>
[2020-11-11 16:30:15,107] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 21 task instances ready to be queued
[2020-11-11 16:30:15,107] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:30:15,107] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:30:15,108] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:30:15,108] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:30:15,108] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:30:15,109] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:30:15,109] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:30:15,109] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:30:15,110] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:30:15,110] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:30:15,110] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:30:15,111] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:30:15,111] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:30:15,111] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:30:15,111] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:30:15,111] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:30:15,112] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:15,112] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:15,112] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:15,112] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:15,113] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:15,113] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:15,113] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:15,113] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:15,114] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:15,114] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:15,118] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:35:00+00:00 [scheduled]>
[2020-11-11 16:30:15,147] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:30:00+00:00 [queued]>
[2020-11-11 16:30:15,147] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 4, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:30:15,147] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T04:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:15,147] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 4, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:15,147] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T04:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:15,148] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 4, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:15,148] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T04:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:15,148] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 4, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:15,148] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T04:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:15,148] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 4, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:15,148] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T04:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:15,148] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 4, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:15,148] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T04:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:15,148] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 4, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:15,149] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T04:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:15,149] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 4, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:15,149] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T04:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:15,149] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 4, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:15,149] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T04:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:15,149] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 4, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:15,149] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T04:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:15,149] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 4, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:15,149] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T04:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:15,150] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 4, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:15,150] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T04:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:15,150] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 4, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:15,150] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T04:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:15,150] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 4, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:15,150] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T04:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:15,150] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 4, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:15,150] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T04:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:15,150] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 4, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:15,150] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T04:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:15,384] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 04:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:15,389] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 04:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:15,391] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 04:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:15,393] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 04:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:15,404] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 04:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:15,406] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 04:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:15,408] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 04:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:15,414] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 04:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:15,420] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 04:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:15,430] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 04:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:15,432] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 04:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:15,440] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 04:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:15,445] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 04:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:15,455] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 04:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:27,108] {scheduler_job.py:961} INFO - 16 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:40:00+00:00 [scheduled]>
[2020-11-11 16:30:27,119] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 114 open slots and 16 task instances ready to be queued
[2020-11-11 16:30:27,120] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:30:27,120] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:30:27,121] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:27,121] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:27,122] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:27,122] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:27,123] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:27,123] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:27,124] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:27,124] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:27,125] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:27,125] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:27,125] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:27,126] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:27,126] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:27,127] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:27,127] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:27,128] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:27,128] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:27,128] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:27,129] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:27,129] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:27,130] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:27,130] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:27,131] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:27,131] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:27,131] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:27,132] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:27,132] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:27,133] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:27,144] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:35:00+00:00 [scheduled]>
[2020-11-11 16:30:27,161] {scheduler_job.py:1158} INFO - Setting the following 2 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:35:00+00:00 [queued]>
[2020-11-11 16:30:27,162] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 4, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:30:27,162] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T04:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:27,163] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 4, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:27,163] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T04:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:27,265] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 04:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:27,267] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 04:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:27,269] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 04:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:39,124] {scheduler_job.py:961} INFO - 26 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:45:00+00:00 [scheduled]>
[2020-11-11 16:30:39,133] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 26 task instances ready to be queued
[2020-11-11 16:30:39,133] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:30:39,134] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:30:39,134] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:30:39,134] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:30:39,134] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:30:39,135] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:30:39,135] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:30:39,135] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:30:39,135] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:30:39,136] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:30:39,136] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:30:39,136] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:30:39,136] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:30:39,137] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:30:39,137] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:30:39,137] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:30:39,137] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:39,137] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:39,138] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:39,138] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:39,138] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:39,138] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:39,139] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:39,139] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:39,139] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:39,139] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:39,139] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:39,139] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:39,140] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:39,140] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:39,140] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:39,140] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:39,140] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:39,141] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:39,141] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:39,141] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:39,145] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:45:00+00:00 [scheduled]>
[2020-11-11 16:30:39,169] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:40:00+00:00 [queued]>
[2020-11-11 16:30:39,169] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 4, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:30:39,169] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T04:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:39,170] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 4, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:39,170] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T04:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:39,170] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 4, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:39,170] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T04:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:39,170] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 4, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:39,170] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T04:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:39,170] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 4, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:39,171] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T04:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:39,171] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 4, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:39,171] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T04:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:39,171] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 4, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:39,171] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T04:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:39,171] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 4, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:39,171] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T04:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:39,171] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 4, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:39,171] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T04:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:39,172] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 4, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:39,172] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T04:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:39,172] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 4, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:39,172] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T04:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:39,172] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 4, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:39,172] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T04:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:39,172] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 4, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:39,172] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T04:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:39,172] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 4, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:39,172] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T04:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:39,173] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 4, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:39,173] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T04:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:39,173] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 4, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:39,173] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T04:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:39,400] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 04:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:39,404] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 04:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:39,405] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 04:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:39,407] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 04:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:39,408] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 04:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:39,410] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 04:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:39,417] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 04:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:39,425] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 04:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:39,433] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 04:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:39,441] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 04:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:39,442] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 04:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:39,446] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 04:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:39,459] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 04:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:39,461] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 04:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:39,465] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 04:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:39,467] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 04:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:51,131] {scheduler_job.py:961} INFO - 21 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:50:00+00:00 [scheduled]>
[2020-11-11 16:30:51,143] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 114 open slots and 21 task instances ready to be queued
[2020-11-11 16:30:51,144] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:30:51,144] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:30:51,144] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:51,145] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:51,145] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:51,146] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:51,146] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:51,146] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:51,147] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:51,147] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:51,147] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:51,148] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:51,148] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:51,148] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:51,148] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:51,149] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:51,149] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:51,149] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:51,149] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:51,150] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:51,150] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:51,150] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:51,150] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:51,150] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:51,151] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:51,151] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:51,151] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:51,151] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:51,152] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:51,152] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:51,152] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:51,152] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:51,153] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:51,153] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:51,153] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:51,153] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:51,153] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:51,154] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:51,154] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:30:51,154] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:30:51,158] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:45:00+00:00 [scheduled]>
[2020-11-11 16:30:51,168] {scheduler_job.py:1158} INFO - Setting the following 2 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 04:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:45:00+00:00 [queued]>
[2020-11-11 16:30:51,168] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 4, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:30:51,168] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T04:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:51,168] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 4, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:30:51,169] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T04:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:30:51,249] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 04:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:30:51,252] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 04:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:03,146] {scheduler_job.py:961} INFO - 32 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:55:00+00:00 [scheduled]>
[2020-11-11 16:31:03,155] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 32 task instances ready to be queued
[2020-11-11 16:31:03,155] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:31:03,155] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:31:03,156] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:31:03,156] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:31:03,156] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:31:03,156] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:31:03,157] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:31:03,157] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:31:03,157] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:31:03,157] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:31:03,158] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:31:03,158] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:31:03,158] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:31:03,158] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:31:03,158] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:31:03,159] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:31:03,159] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:03,159] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:03,159] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:03,159] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:03,160] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:03,160] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:03,160] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:03,160] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:03,161] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:03,161] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:03,161] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:03,161] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:03,161] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:03,161] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:03,162] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:03,162] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:03,162] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:03,162] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:03,162] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:03,163] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:03,163] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:03,163] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:03,163] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:03,163] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:03,163] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:03,164] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:03,164] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:03,164] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:03,164] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:03,164] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:03,164] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:03,165] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:03,168] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:50:00+00:00 [scheduled]>
[2020-11-11 16:31:03,186] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:45:00+00:00 [queued]>
[2020-11-11 16:31:03,187] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 5, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:31:03,188] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T05:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:03,189] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 4, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:03,189] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T04:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:03,189] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 4, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:03,190] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T04:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:03,190] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 4, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:03,191] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T04:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:03,191] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 4, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:03,192] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T04:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:03,192] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 4, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:03,193] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T04:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:03,193] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 4, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:03,194] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T04:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:03,194] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 4, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:03,194] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T04:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:03,195] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 4, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:03,195] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T04:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:03,196] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 4, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:03,196] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T04:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:03,197] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 4, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:03,197] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T04:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:03,198] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 4, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:03,198] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T04:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:03,198] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 4, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:03,199] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T04:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:03,199] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 4, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:03,200] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T04:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:03,200] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 4, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:03,201] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T04:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:03,201] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 4, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:03,201] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T04:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:03,386] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 04:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:03,389] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 04:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:03,391] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 04:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:03,393] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 04:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:03,395] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 04:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:03,399] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 04:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:03,405] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 04:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:03,409] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 04:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:03,413] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 04:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:03,417] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 04:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:03,421] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 04:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:03,437] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 04:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:03,439] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 04:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:03,444] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 04:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:03,446] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 04:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:03,448] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 04:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:15,128] {scheduler_job.py:961} INFO - 27 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:00:00+00:00 [scheduled]>
[2020-11-11 16:31:15,130] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 27 task instances ready to be queued
[2020-11-11 16:31:15,130] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:31:15,130] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:15,131] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:15,131] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:15,131] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:15,131] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:15,131] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:15,131] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:15,131] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:15,131] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:15,131] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:15,131] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:15,132] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:15,132] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:15,132] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:15,132] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:15,132] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:15,132] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:15,132] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:15,132] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:15,132] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:15,132] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:15,132] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:15,133] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:15,133] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:15,133] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:15,133] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:15,133] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:15,133] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:15,133] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:15,133] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:15,133] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:15,133] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:15,133] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:15,134] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:15,134] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:15,134] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:15,134] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:15,134] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:15,134] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:15,134] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:15,134] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:15,134] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:15,134] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:15,134] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:15,135] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:15,135] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:15,135] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:15,135] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:15,135] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:15,135] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:15,135] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:15,135] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:15,150] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:05:00+00:00 [scheduled]>
[2020-11-11 16:31:15,157] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:05:00+00:00 [queued]>
[2020-11-11 16:31:15,157] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 5, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:31:15,157] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T05:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:15,229] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 04:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:15,232] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 05:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:29,143] {scheduler_job.py:961} INFO - 38 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:05:00+00:00 [scheduled]>
[2020-11-11 16:31:29,146] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 38 task instances ready to be queued
[2020-11-11 16:31:29,146] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:31:29,146] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:31:29,146] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:31:29,146] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:31:29,146] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:31:29,146] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:31:29,147] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:31:29,147] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:31:29,147] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:31:29,147] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:31:29,147] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:31:29,147] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:31:29,147] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:31:29,147] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:31:29,147] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:31:29,147] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:31:29,148] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:29,148] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:29,148] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:29,148] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:29,148] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:29,148] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:29,148] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:29,148] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:29,148] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:29,149] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:29,149] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:29,149] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:29,149] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:29,149] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:29,149] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:29,149] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:29,149] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:29,149] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:29,149] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:29,149] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:29,150] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:29,150] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:29,150] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:29,150] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:29,150] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:29,150] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:29,150] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:29,150] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:29,150] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:29,150] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:29,151] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:29,151] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:29,151] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:29,151] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:29,151] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:29,151] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:29,151] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:29,151] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:29,151] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:29,151] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:29,152] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:29,152] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:29,152] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:29,152] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:29,154] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:00:00+00:00 [scheduled]>
[2020-11-11 16:31:29,170] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 04:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 04:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 04:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 04:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 04:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 04:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 04:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 04:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 04:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 04:55:00+00:00 [queued]>
[2020-11-11 16:31:29,170] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 5, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:31:29,170] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T05:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:29,170] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 4, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:29,170] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T04:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:29,171] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 5, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:29,171] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T05:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:29,171] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 4, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:29,171] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T04:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:29,171] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 5, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:29,171] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T05:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:29,171] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 4, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:29,172] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T04:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:29,172] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 5, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:29,172] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T05:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:29,172] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 4, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:29,172] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T04:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:29,172] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 5, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:29,172] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T05:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:29,172] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 4, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:29,172] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T04:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:29,172] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 4, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:29,173] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T04:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:29,173] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 4, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:29,173] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T04:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:29,173] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 4, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:29,173] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T04:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:29,173] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 4, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:29,173] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T04:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:29,173] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 4, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:29,173] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T04:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:29,173] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 4, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:29,173] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T04:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:29,360] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 04:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:29,370] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 04:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:29,372] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 04:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:29,374] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 04:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:29,376] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 04:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:29,377] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 04:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:29,389] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 04:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:29,394] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 04:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:29,400] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 04:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:29,408] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 04:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:29,411] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 04:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:29,413] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 04:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:29,421] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 04:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:29,426] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 04:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:29,431] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 04:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:29,440] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 05:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:41,150] {scheduler_job.py:961} INFO - 33 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:10:00+00:00 [scheduled]>
[2020-11-11 16:31:41,154] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 33 task instances ready to be queued
[2020-11-11 16:31:41,155] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:31:41,155] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:41,155] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:41,155] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:41,155] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:41,155] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:41,156] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:41,156] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:41,156] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:41,156] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:41,156] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:41,156] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:41,156] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:41,156] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:41,156] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:41,156] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:41,156] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:41,157] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:41,157] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:41,157] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:41,157] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:41,157] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:41,157] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:41,157] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:41,157] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:41,157] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:41,158] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:41,158] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:41,158] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:41,158] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:41,158] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:41,158] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:41,158] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:41,158] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:41,158] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:41,158] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:41,158] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:41,159] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:41,159] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:41,159] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:41,159] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:41,159] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:41,159] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:41,159] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:41,159] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:41,159] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:41,159] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:41,160] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:41,160] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:41,160] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:41,160] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:41,161] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:41,161] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:41,161] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:41,161] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:41,161] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:41,161] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:41,161] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:41,161] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:41,161] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:41,162] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:41,162] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:41,162] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:41,162] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:41,162] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:41,166] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:15:00+00:00 [scheduled]>
[2020-11-11 16:31:41,174] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:15:00+00:00 [queued]>
[2020-11-11 16:31:41,174] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 5, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:31:41,174] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T05:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:41,260] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 05:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:53,196] {scheduler_job.py:961} INFO - 45 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:15:00+00:00 [scheduled]>
[2020-11-11 16:31:53,204] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 45 task instances ready to be queued
[2020-11-11 16:31:53,204] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:31:53,205] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:31:53,205] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:31:53,205] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:31:53,205] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:31:53,206] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:31:53,206] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:31:53,206] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:31:53,206] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:31:53,206] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:31:53,207] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:31:53,207] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:31:53,207] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:31:53,207] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:31:53,207] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:31:53,207] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:31:53,208] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:53,208] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:53,208] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:53,208] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:53,208] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:53,209] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:53,209] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:53,209] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:53,209] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:53,209] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:53,209] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:53,210] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:53,210] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:53,210] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:53,210] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:53,210] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:53,211] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:53,211] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:53,211] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:53,211] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:53,211] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:53,211] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:53,211] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:53,212] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:53,212] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:53,212] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:53,212] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:53,212] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:53,212] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:53,212] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:53,213] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:53,213] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:53,213] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:53,213] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:53,213] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:53,213] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:53,214] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:53,214] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:53,214] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:53,214] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:53,214] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:53,214] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:53,214] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:53,215] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:53,215] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:53,215] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:53,215] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:53,215] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:53,215] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:53,215] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:53,216] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:53,216] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:53,216] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:53,216] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:53,216] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:53,216] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:53,216] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:31:53,216] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:31:53,220] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:05:00+00:00 [scheduled]>
[2020-11-11 16:31:53,239] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:00:00+00:00 [queued]>
[2020-11-11 16:31:53,240] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 5, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:31:53,240] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T05:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:53,240] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 5, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:53,240] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T05:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:53,240] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 5, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:53,240] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T05:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:53,240] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 5, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:53,240] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T05:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:53,241] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 5, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:53,241] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T05:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:53,241] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 5, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:53,242] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T05:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:53,242] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 5, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:53,242] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T05:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:53,242] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 5, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:53,242] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T05:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:53,242] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 5, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:53,242] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T05:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:53,242] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 5, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:53,242] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T05:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:53,243] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 5, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:53,243] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T05:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:53,243] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 5, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:53,243] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T05:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:53,243] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 5, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:53,243] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T05:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:53,243] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 5, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:53,243] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T05:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:53,243] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 5, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:53,243] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T05:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:53,244] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 5, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:31:53,244] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T05:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:31:53,444] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 04:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:53,447] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 05:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:53,449] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 04:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:53,452] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 05:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:53,454] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 04:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:53,456] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 04:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:53,465] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 05:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:53,470] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 04:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:53,474] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 04:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:53,479] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 04:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:53,486] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 05:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:53,488] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 04:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:53,491] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 04:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:53,495] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 04:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:53,497] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 04:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:31:53,499] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 05:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:05,206] {scheduler_job.py:961} INFO - 40 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:20:00+00:00 [scheduled]>
[2020-11-11 16:32:05,216] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 114 open slots and 40 task instances ready to be queued
[2020-11-11 16:32:05,216] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:32:05,217] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:32:05,217] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,217] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,217] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,218] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,218] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,218] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,218] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,219] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,219] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,219] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,219] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,220] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,220] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,220] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,220] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,221] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,221] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,221] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,221] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,222] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,222] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,222] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,222] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,222] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,223] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,223] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,223] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,223] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,224] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,224] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,225] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,225] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,225] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,225] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,225] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,226] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,226] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,226] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,226] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,226] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,227] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,227] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,227] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,227] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,228] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,228] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,228] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,228] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,228] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,229] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,229] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,229] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,229] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,230] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,230] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,230] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,230] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,230] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,231] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,231] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,231] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,231] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,232] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,232] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,232] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,232] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,232] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,233] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,233] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,233] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,233] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,233] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,234] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,234] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,234] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:05,234] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:05,239] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:05:00+00:00 [scheduled]>
[2020-11-11 16:32:05,250] {scheduler_job.py:1158} INFO - Setting the following 2 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:05:00+00:00 [queued]>
[2020-11-11 16:32:05,250] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 5, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:32:05,251] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T05:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:05,251] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 5, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:05,251] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T05:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:05,350] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 05:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:17,219] {scheduler_job.py:961} INFO - 50 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:25:00+00:00 [scheduled]>
[2020-11-11 16:32:17,228] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 50 task instances ready to be queued
[2020-11-11 16:32:17,229] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:32:17,229] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:32:17,229] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:32:17,229] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:32:17,230] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:32:17,230] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:32:17,230] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:32:17,230] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:32:17,230] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:32:17,231] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:32:17,231] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:32:17,231] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:32:17,231] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:32:17,232] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:32:17,232] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:32:17,232] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:32:17,232] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,232] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,233] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,233] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,233] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,233] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,234] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,234] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,234] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,234] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,234] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,234] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,235] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,235] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,235] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,235] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,235] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,235] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,236] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,236] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,236] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,236] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,236] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,236] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,237] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,237] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,237] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,237] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,237] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,238] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,238] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,238] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,238] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,238] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,238] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,239] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,239] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,239] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,239] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,239] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,239] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,239] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,240] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,240] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,240] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,240] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,240] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,240] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,240] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,241] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,241] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,241] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,241] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,241] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,241] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,241] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,242] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,242] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,242] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,242] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,242] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,242] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,242] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,243] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,243] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,243] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,243] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:17,243] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:17,246] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:15:00+00:00 [scheduled]>
[2020-11-11 16:32:17,262] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:10:00+00:00 [queued]>
[2020-11-11 16:32:17,262] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 5, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:32:17,262] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T05:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:17,262] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 5, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:17,262] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T05:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:17,263] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 5, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:17,263] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T05:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:17,263] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 5, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:17,263] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T05:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:17,263] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 5, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:17,263] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T05:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:17,263] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 5, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:17,263] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T05:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:17,263] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 5, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:17,263] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T05:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:17,264] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 5, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:17,264] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T05:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:17,264] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 5, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:17,264] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T05:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:17,264] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 5, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:17,264] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T05:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:17,264] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 5, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:17,264] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T05:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:17,264] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 5, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:17,264] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T05:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:17,265] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 5, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:17,265] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T05:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:17,265] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 5, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:17,265] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T05:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:17,265] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 5, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:17,265] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T05:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:17,265] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 5, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:17,265] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T05:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:17,443] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 05:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:17,446] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 05:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:17,448] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 05:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:17,450] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 05:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:17,451] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 05:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:17,453] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 05:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:17,459] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 05:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:17,460] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 05:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:17,466] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 05:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:17,475] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 05:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:17,483] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 05:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:17,487] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 05:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:17,491] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 05:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:17,502] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 05:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:17,504] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 05:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:17,509] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 05:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:29,229] {scheduler_job.py:961} INFO - 46 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:30:00+00:00 [scheduled]>
[2020-11-11 16:32:29,237] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 116 open slots and 46 task instances ready to be queued
[2020-11-11 16:32:29,237] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:32:29,237] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:32:29,238] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:32:29,238] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:32:29,238] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,238] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,239] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,239] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,239] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,239] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,240] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,240] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,240] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,240] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,240] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,241] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,241] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,241] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,241] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,241] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,241] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,242] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,242] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,242] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,242] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,242] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,243] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,243] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,243] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,243] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,243] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,243] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,244] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,244] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,244] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,244] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,244] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,244] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,245] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,245] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,245] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,245] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,245] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,245] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,246] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,246] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,246] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,246] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,246] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,246] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,246] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,247] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,247] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,247] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,247] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,247] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,247] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,247] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,248] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,248] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,248] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,248] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,248] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,248] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,248] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,249] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,249] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,249] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,249] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,249] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,249] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,249] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,250] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,250] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,250] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,250] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,250] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,250] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,250] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,251] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,251] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,251] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,251] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,251] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,251] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,251] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,251] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:29,252] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:29,254] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:15:00+00:00 [scheduled]>
[2020-11-11 16:32:29,263] {scheduler_job.py:1158} INFO - Setting the following 4 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:15:00+00:00 [queued]>
[2020-11-11 16:32:29,263] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 5, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:32:29,263] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T05:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:29,263] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 5, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:29,264] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T05:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:29,264] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 5, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:29,264] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T05:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:29,264] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 5, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:29,264] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T05:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:29,365] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 05:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:29,368] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 05:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:41,240] {scheduler_job.py:961} INFO - 53 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:35:00+00:00 [scheduled]>
[2020-11-11 16:32:41,246] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 53 task instances ready to be queued
[2020-11-11 16:32:41,247] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:32:41,247] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:32:41,247] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:32:41,247] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:32:41,247] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:32:41,248] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:32:41,248] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:32:41,248] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:32:41,248] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:32:41,248] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:32:41,248] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:32:41,249] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:32:41,249] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:32:41,249] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:32:41,249] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:32:41,249] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:32:41,250] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,250] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,250] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,250] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,250] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,250] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,251] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,251] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,251] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,251] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,251] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,251] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,252] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,252] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,252] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,252] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,252] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,252] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,252] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,253] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,253] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,253] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,253] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,253] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,253] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,253] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,254] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,254] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,254] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,254] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,254] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,254] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,254] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,255] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,255] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,255] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,255] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,255] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,255] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,255] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,255] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,256] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,256] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,256] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,256] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,256] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,256] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,256] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,256] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,257] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,257] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,257] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,257] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,257] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,257] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,257] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,257] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,258] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,258] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,258] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,258] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,258] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,258] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,258] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,258] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,259] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,259] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,259] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,259] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,259] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,259] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,259] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,259] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:41,259] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:41,262] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:25:00+00:00 [scheduled]>
[2020-11-11 16:32:41,278] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:20:00+00:00 [queued]>
[2020-11-11 16:32:41,278] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 5, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:41,279] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T05:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:41,279] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 5, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:41,279] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T05:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:41,279] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 5, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:41,280] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T05:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:41,280] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 5, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:41,280] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T05:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:41,280] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 5, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:41,280] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T05:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:41,280] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 5, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:41,280] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T05:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:41,280] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 5, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:41,281] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T05:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:41,281] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 5, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:41,281] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T05:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:41,281] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 5, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:41,281] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T05:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:41,281] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 5, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:41,281] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T05:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:41,281] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 5, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:41,281] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T05:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:41,282] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 5, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:41,282] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T05:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:41,282] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 5, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:41,282] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T05:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:41,282] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 5, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:41,282] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T05:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:41,282] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 5, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:41,282] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T05:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:41,282] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 5, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:41,283] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T05:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:41,461] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 05:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:41,464] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 05:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:41,466] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 05:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:41,467] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 05:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:41,473] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 05:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:41,474] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 05:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:41,481] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 05:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:41,489] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 05:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:41,491] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 05:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:41,492] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 05:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:41,494] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 05:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:41,496] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 05:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:41,505] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 05:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:41,507] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 05:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:41,510] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 05:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:41,513] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 05:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:53,247] {scheduler_job.py:961} INFO - 37 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:35:00+00:00 [scheduled]>
[2020-11-11 16:32:53,256] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 37 task instances ready to be queued
[2020-11-11 16:32:53,256] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:32:53,257] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,257] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,257] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,257] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,258] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,258] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,258] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,258] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,258] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,259] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,259] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,259] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,259] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,260] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,260] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,260] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,260] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,260] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,261] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,261] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,261] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,261] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,261] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,261] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,262] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,262] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,262] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,262] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,262] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,263] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,263] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,263] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,263] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,263] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,263] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,264] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,264] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,264] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,264] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,264] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,264] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,265] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,265] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,265] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,265] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,265] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,265] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,266] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,266] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,266] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,266] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,266] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,266] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,266] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,267] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,267] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,267] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,267] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,267] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,267] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,268] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,268] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,268] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,268] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,268] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,268] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,268] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,269] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,269] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,269] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,269] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:32:53,269] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:32:53,272] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:25:00+00:00 [scheduled]>
[2020-11-11 16:32:53,279] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:25:00+00:00 [queued]>
[2020-11-11 16:32:53,279] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 5, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:32:53,279] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T05:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:32:53,338] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 05:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:53,340] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 05:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:32:53,342] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 05:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:05,258] {scheduler_job.py:961} INFO - 38 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:35:00+00:00 [scheduled]>
[2020-11-11 16:33:05,268] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 38 task instances ready to be queued
[2020-11-11 16:33:05,268] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:33:05,269] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:33:05,269] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:33:05,269] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:33:05,270] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:33:05,270] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:33:05,270] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:33:05,271] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:33:05,271] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:33:05,271] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:33:05,271] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:33:05,272] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:33:05,272] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:33:05,272] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:33:05,272] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:33:05,273] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:33:05,273] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:05,273] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:05,273] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:05,273] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:05,274] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:05,274] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:05,274] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:05,274] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:05,275] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:05,275] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:05,275] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:05,275] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:05,276] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:05,276] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:05,276] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:05,276] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:05,276] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:05,277] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:05,277] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:05,277] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:05,277] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:05,277] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:05,277] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:05,278] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:05,278] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:05,278] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:05,278] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:05,278] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:05,278] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:05,279] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:05,279] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:05,279] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:05,279] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:05,279] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:05,280] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:05,280] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:05,281] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:05,281] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:05,281] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:05,281] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:05,281] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:05,282] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:05,282] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:05,282] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:05,285] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:35:00+00:00 [scheduled]>
[2020-11-11 16:33:05,302] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:30:00+00:00 [queued]>
[2020-11-11 16:33:05,302] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 5, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:33:05,303] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T05:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:05,303] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 5, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:33:05,303] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T05:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:05,303] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 5, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:33:05,303] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T05:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:05,303] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 5, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:33:05,304] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T05:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:05,304] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 5, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:33:05,304] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T05:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:05,304] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 5, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:33:05,304] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T05:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:05,304] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 5, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:33:05,304] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T05:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:05,305] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 5, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:33:05,305] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T05:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:05,305] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 5, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:33:05,305] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T05:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:05,305] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 5, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:33:05,305] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T05:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:05,306] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 5, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:33:05,306] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T05:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:05,306] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 5, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:33:05,306] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T05:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:05,306] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 5, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:33:05,306] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T05:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:05,306] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 5, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:33:05,307] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T05:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:05,307] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 5, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:33:05,307] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T05:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:05,307] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 5, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:33:05,307] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T05:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:05,552] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 05:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:05,556] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 05:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:05,560] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 05:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:05,563] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 05:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:05,567] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 05:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:05,577] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 05:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:05,590] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 05:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:05,605] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 05:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:05,618] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 05:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:05,622] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 05:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:05,629] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 05:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:05,641] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 05:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:05,657] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 05:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:05,662] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 05:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:05,667] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 05:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:05,672] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 05:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:17,263] {scheduler_job.py:961} INFO - 22 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:35:00+00:00 [scheduled]>
[2020-11-11 16:33:17,272] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 22 task instances ready to be queued
[2020-11-11 16:33:17,272] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:33:17,273] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:17,273] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:17,273] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:17,273] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:17,274] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:17,274] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:17,274] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:17,274] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:17,275] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:17,275] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:17,275] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:17,275] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:17,276] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:17,276] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:17,276] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:17,276] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:17,276] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:17,277] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:17,277] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:17,277] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:17,277] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:17,277] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:17,278] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:17,278] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:35:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:17,278] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:17,278] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:17,278] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:17,278] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:45:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:17,279] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:17,279] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:17,279] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:17,279] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:55:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:17,279] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:17,279] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:17,280] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:17,280] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:17,280] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:17,280] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:17,280] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:17,281] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:17,281] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:17,281] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:17,284] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:35:00+00:00 [scheduled]>
[2020-11-11 16:33:17,292] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:35:00+00:00 [queued]>
[2020-11-11 16:33:17,292] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 5, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:33:17,292] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T05:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:17,360] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 05:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:29,273] {scheduler_job.py:961} INFO - 23 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:35:00+00:00 [scheduled]>
[2020-11-11 16:33:29,283] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 23 task instances ready to be queued
[2020-11-11 16:33:29,284] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:33:29,284] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:33:29,285] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:33:29,285] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:33:29,286] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:33:29,286] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:33:29,287] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:33:29,287] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:33:29,287] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:33:29,288] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:33:29,288] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:33:29,289] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:33:29,289] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:33:29,290] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:33:29,290] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:33:29,290] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:33:29,291] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:29,291] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:00:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:29,292] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:29,292] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:05:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:29,293] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:29,293] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:29,293] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:29,294] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:15:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:29,294] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:29,295] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:20:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:29,295] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:29,295] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:25:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:29,296] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:33:29,296] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:30:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:33:29,306] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:30:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:35:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:55:00+00:00 [scheduled]>
[2020-11-11 16:33:29,356] {scheduler_job.py:1158} INFO - Setting the following 16 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:30:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 04:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:35:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:35:00+00:00 [queued]>
[2020-11-11 16:33:29,357] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 4, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:33:29,358] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T04:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:29,358] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 4, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:33:29,359] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T04:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:29,359] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 4, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:33:29,360] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T04:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:29,360] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 4, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:33:29,361] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T04:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:29,361] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 4, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:33:29,362] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T04:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:29,362] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 4, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:33:29,363] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T04:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:29,363] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 4, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:33:29,363] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T04:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:29,364] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 4, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:33:29,364] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T04:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:29,365] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 5, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:33:29,365] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T05:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:29,366] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 5, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:33:29,366] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T05:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:29,366] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 5, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:33:29,367] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T05:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:29,367] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 5, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:33:29,368] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T05:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:29,368] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 5, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:33:29,369] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T05:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:29,369] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 5, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:33:29,370] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T05:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:29,370] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 5, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:33:29,370] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T05:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:29,371] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 5, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:33:29,371] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T05:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:29,548] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 05:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:29,551] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 05:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:29,553] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 05:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:29,555] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 05:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:29,557] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 05:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:29,560] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 05:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:29,570] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 05:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:29,573] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 05:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:29,575] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 05:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:29,577] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 05:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:29,589] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 05:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:29,597] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 05:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:29,599] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 05:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:29,601] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 05:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:29,610] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 05:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:29,612] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 05:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:41,279] {scheduler_job.py:961} INFO - 7 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:30:00+00:00 [scheduled]>
[2020-11-11 16:33:41,290] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 120 open slots and 7 task instances ready to be queued
[2020-11-11 16:33:41,291] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:33:41,291] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:33:41,291] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:33:41,292] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:33:41,292] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:33:41,292] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:33:41,293] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:33:41,298] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:05:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:10:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:15:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:20:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:25:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:30:00+00:00 [scheduled]>
[2020-11-11 16:33:41,313] {scheduler_job.py:1158} INFO - Setting the following 7 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:05:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:10:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:15:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:20:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:25:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:30:00+00:00 [queued]>
[2020-11-11 16:33:41,313] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 5, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:33:41,313] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T05:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:41,314] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 5, 5, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:33:41,314] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T05:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:41,314] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 5, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:33:41,315] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T05:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:41,315] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 5, 15, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:33:41,315] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T05:15:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:41,315] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 5, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:33:41,315] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T05:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:41,315] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 5, 25, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:33:41,316] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T05:25:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:41,316] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 5, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:33:41,316] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T05:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:41,462] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 05:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:41,465] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 04:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:41,468] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 04:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:41,470] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 04:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:41,472] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 04:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:41,474] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 04:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:41,475] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 04:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:41,477] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 04:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:41,478] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 04:55:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:53,290] {scheduler_job.py:961} INFO - 2 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:35:00+00:00 [scheduled]>
[2020-11-11 16:33:53,299] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 2 task instances ready to be queued
[2020-11-11 16:33:53,300] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:33:53,301] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:33:53,309] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:35:00+00:00 [scheduled]>
[2020-11-11 16:33:53,327] {scheduler_job.py:1158} INFO - Setting the following 2 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:35:00+00:00 [queued]>
[2020-11-11 16:33:53,327] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 5, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:33:53,328] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T05:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:53,328] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 5, 35, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:33:53,329] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T05:35:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:33:53,420] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 05:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:53,423] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 05:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:53,424] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 05:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:53,425] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 05:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:53,427] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 05:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:53,428] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 05:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:53,429] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 05:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:53,431] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 05:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:53,432] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 05:00:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:53,433] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 05:05:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:53,434] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 05:10:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:53,436] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 05:15:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:53,437] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 05:20:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:53,438] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 05:25:00+00:00 exited with status success for try_number 1
[2020-11-11 16:33:53,439] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 05:30:00+00:00 exited with status success for try_number 1
[2020-11-11 16:34:07,295] {scheduler_job.py:961} INFO - 11 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:40:00+00:00 [scheduled]>
[2020-11-11 16:34:07,297] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 11 task instances ready to be queued
[2020-11-11 16:34:07,297] {scheduler_job.py:1023} INFO - DAG sleep_task has 0/16 running and queued tasks
[2020-11-11 16:34:07,297] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:34:07,298] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:34:07,298] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:34:07,298] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:34:07,298] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:34:07,298] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:34:07,298] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:34:07,298] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:34:07,298] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:34:07,298] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:34:07,300] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:40:00+00:00 [scheduled]>
[2020-11-11 16:34:07,314] {scheduler_job.py:1158} INFO - Setting the following 11 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:40:00+00:00 [queued]>
[2020-11-11 16:34:07,314] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 5, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:34:07,314] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T05:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:07,314] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 5, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:07,315] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T05:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:07,315] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 5, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:07,315] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T05:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:07,315] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 5, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:07,315] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T05:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:07,315] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 5, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:07,315] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T05:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:07,315] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 5, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:07,315] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T05:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:07,316] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 5, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:07,316] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T05:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:07,316] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 5, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:07,316] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T05:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:07,316] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 5, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:07,316] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T05:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:07,316] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 5, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:07,316] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T05:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:07,316] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 5, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:07,316] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T05:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:07,468] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 05:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:34:07,471] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_last execution_date=2020-11-01 05:35:00+00:00 exited with status success for try_number 1
[2020-11-11 16:34:19,312] {scheduler_job.py:961} INFO - 11 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:45:00+00:00 [scheduled]>
[2020-11-11 16:34:19,321] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 126 open slots and 11 task instances ready to be queued
[2020-11-11 16:34:19,321] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:34:19,322] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:34:19,322] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:34:19,323] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:34:19,323] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:34:19,323] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:34:19,323] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:34:19,323] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:34:19,324] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:34:19,324] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:34:19,324] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:34:19,329] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:45:00+00:00 [scheduled]>
[2020-11-11 16:34:19,348] {scheduler_job.py:1158} INFO - Setting the following 11 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:45:00+00:00 [queued]>
[2020-11-11 16:34:19,348] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 5, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:34:19,348] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T05:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:19,349] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 5, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:19,349] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T05:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:19,350] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 5, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:19,350] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T05:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:19,350] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 5, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:19,350] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T05:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:19,350] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 5, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:19,350] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T05:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:19,351] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 5, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:19,351] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T05:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:19,351] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 5, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:19,351] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T05:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:19,351] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 5, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:19,351] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T05:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:19,351] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 5, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:19,352] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T05:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:19,352] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 5, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:19,352] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T05:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:19,352] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 5, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:19,352] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T05:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:19,528] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 05:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:34:31,333] {scheduler_job.py:961} INFO - 12 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:50:00+00:00 [scheduled]>
[2020-11-11 16:34:31,341] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 122 open slots and 12 task instances ready to be queued
[2020-11-11 16:34:31,342] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:34:31,342] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:34:31,342] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:34:31,343] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:34:31,343] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:34:31,343] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:34:31,343] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:34:31,344] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:34:31,344] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:34:31,344] {scheduler_job.py:1023} INFO - DAG sleep_task has 15/16 running and queued tasks
[2020-11-11 16:34:31,344] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:34:31,345] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:50:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:34:31,345] {scheduler_job.py:1023} INFO - DAG sleep_task has 16/16 running and queued tasks
[2020-11-11 16:34:31,345] {scheduler_job.py:1028} INFO - Not executing <TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:40:00+00:00 [scheduled]> since the number of tasks running or queued from DAG sleep_task is >= to the DAG's task concurrency limit of 16
[2020-11-11 16:34:31,350] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:50:00+00:00 [scheduled]>
[2020-11-11 16:34:31,366] {scheduler_job.py:1158} INFO - Setting the following 10 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 05:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:50:00+00:00 [queued]>
[2020-11-11 16:34:31,366] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 5, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:34:31,367] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T05:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:31,367] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 5, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:31,368] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T05:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:31,368] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 5, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:31,368] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T05:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:31,368] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 5, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:31,368] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T05:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:31,368] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 5, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:31,369] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T05:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:31,369] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 5, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:31,369] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T05:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:31,369] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 5, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:31,369] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T05:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:31,369] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 5, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:31,370] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T05:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:31,370] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 5, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:31,370] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T05:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:31,371] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 5, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:31,371] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T05:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:31,583] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 05:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:34:31,590] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 05:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:34:31,592] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 05:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:34:31,595] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 05:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:34:31,597] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 05:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:34:31,603] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 05:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:34:31,606] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 05:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:34:31,609] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 05:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:34:31,615] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 05:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:34:31,619] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 05:40:00+00:00 exited with status success for try_number 1
[2020-11-11 16:34:31,622] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 05:50:00+00:00 exited with status success for try_number 1
[2020-11-11 16:34:43,336] {scheduler_job.py:961} INFO - 14 tasks up for execution:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 06:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:45:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:55:00+00:00 [scheduled]>
[2020-11-11 16:34:43,342] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 127 open slots and 14 task instances ready to be queued
[2020-11-11 16:34:43,342] {scheduler_job.py:1023} INFO - DAG sleep_task has 1/16 running and queued tasks
[2020-11-11 16:34:43,342] {scheduler_job.py:1023} INFO - DAG sleep_task has 2/16 running and queued tasks
[2020-11-11 16:34:43,342] {scheduler_job.py:1023} INFO - DAG sleep_task has 3/16 running and queued tasks
[2020-11-11 16:34:43,343] {scheduler_job.py:1023} INFO - DAG sleep_task has 4/16 running and queued tasks
[2020-11-11 16:34:43,343] {scheduler_job.py:1023} INFO - DAG sleep_task has 5/16 running and queued tasks
[2020-11-11 16:34:43,343] {scheduler_job.py:1023} INFO - DAG sleep_task has 6/16 running and queued tasks
[2020-11-11 16:34:43,343] {scheduler_job.py:1023} INFO - DAG sleep_task has 7/16 running and queued tasks
[2020-11-11 16:34:43,343] {scheduler_job.py:1023} INFO - DAG sleep_task has 8/16 running and queued tasks
[2020-11-11 16:34:43,344] {scheduler_job.py:1023} INFO - DAG sleep_task has 9/16 running and queued tasks
[2020-11-11 16:34:43,344] {scheduler_job.py:1023} INFO - DAG sleep_task has 10/16 running and queued tasks
[2020-11-11 16:34:43,344] {scheduler_job.py:1023} INFO - DAG sleep_task has 11/16 running and queued tasks
[2020-11-11 16:34:43,344] {scheduler_job.py:1023} INFO - DAG sleep_task has 12/16 running and queued tasks
[2020-11-11 16:34:43,344] {scheduler_job.py:1023} INFO - DAG sleep_task has 13/16 running and queued tasks
[2020-11-11 16:34:43,344] {scheduler_job.py:1023} INFO - DAG sleep_task has 14/16 running and queued tasks
[2020-11-11 16:34:43,348] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 06:00:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:50:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:55:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:40:00+00:00 [scheduled]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:45:00+00:00 [scheduled]>
[2020-11-11 16:34:43,364] {scheduler_job.py:1158} INFO - Setting the following 14 tasks to queued state:
	<TaskInstance: sleep_task.run_this_bash_first 2020-11-01 06:00:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:40:00+00:00 [queued]>
	<TaskInstance: sleep_task.run_this_bash_last 2020-11-01 05:45:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_0 2020-11-01 05:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_1 2020-11-01 05:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_2 2020-11-01 05:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_3 2020-11-01 05:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_4 2020-11-01 05:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_5 2020-11-01 05:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_6 2020-11-01 05:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_7 2020-11-01 05:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_8 2020-11-01 05:55:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:50:00+00:00 [queued]>
	<TaskInstance: sleep_task.sleep_task_9 2020-11-01 05:55:00+00:00 [queued]>
[2020-11-11 16:34:43,364] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_first', datetime.datetime(2020, 11, 1, 6, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 12 and queue test_airflow_queue
[2020-11-11 16:34:43,364] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_first', '2020-11-01T06:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:43,364] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 5, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:34:43,364] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T05:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:43,364] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'run_this_bash_last', datetime.datetime(2020, 11, 1, 5, 45, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-11 16:34:43,364] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'run_this_bash_last', '2020-11-01T05:45:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:43,365] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_0', datetime.datetime(2020, 11, 1, 5, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:43,365] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_0', '2020-11-01T05:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:43,365] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_1', datetime.datetime(2020, 11, 1, 5, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:43,365] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_1', '2020-11-01T05:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:43,365] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_2', datetime.datetime(2020, 11, 1, 5, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:43,365] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_2', '2020-11-01T05:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:43,365] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_3', datetime.datetime(2020, 11, 1, 5, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:43,365] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_3', '2020-11-01T05:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:43,365] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_4', datetime.datetime(2020, 11, 1, 5, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:43,366] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_4', '2020-11-01T05:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:43,366] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_5', datetime.datetime(2020, 11, 1, 5, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:43,366] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_5', '2020-11-01T05:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:43,366] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_6', datetime.datetime(2020, 11, 1, 5, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:43,366] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_6', '2020-11-01T05:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:43,366] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_7', datetime.datetime(2020, 11, 1, 5, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:43,366] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_7', '2020-11-01T05:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:43,366] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_8', datetime.datetime(2020, 11, 1, 5, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:43,366] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_8', '2020-11-01T05:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:43,366] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 5, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:43,366] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T05:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:43,367] {scheduler_job.py:1193} INFO - Sending ('sleep_task', 'sleep_task_9', datetime.datetime(2020, 11, 1, 5, 55, tzinfo=<Timezone [UTC]>), 1) to executor with priority 2 and queue test_airflow_queue
[2020-11-11 16:34:43,367] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'sleep_task', 'sleep_task_9', '2020-11-01T05:55:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/sleep_task.py']
[2020-11-11 16:34:43,604] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_0 execution_date=2020-11-01 05:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:34:43,607] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_1 execution_date=2020-11-01 05:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:34:43,609] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_2 execution_date=2020-11-01 05:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:34:43,614] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_3 execution_date=2020-11-01 05:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:34:43,621] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_4 execution_date=2020-11-01 05:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:34:43,633] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_5 execution_date=2020-11-01 05:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:34:43,642] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_6 execution_date=2020-11-01 05:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:34:43,649] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_7 execution_date=2020-11-01 05:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:34:43,656] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_8 execution_date=2020-11-01 05:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:34:43,658] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.sleep_task_9 execution_date=2020-11-01 05:45:00+00:00 exited with status success for try_number 1
[2020-11-11 16:34:43,669] {scheduler_job.py:1331} INFO - Executor reports execution of sleep_task.run_this_bash_first execution_date=2020-11-01 05:55:00+00:00 exited with status success for try_number 1
[2020-11-11 18:15:29,596] {helpers.py:325} INFO - Sending Signals.SIGTERM to GPID 12815
[2020-11-11 18:15:29,596] {helpers.py:291} INFO - Process psutil.Process(pid=12815, status='terminated', exitcode=0, started='15:55:12') (12815) terminated with exit code 0
[2020-11-11 18:15:29,596] {scheduler_job.py:1404} INFO - Exited execute loop
Traceback (most recent call last):
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1276, in _execute_context
    self.dialect.do_execute(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/cursors.py", line 255, in execute
    self.errorhandler(self, exc, value)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/connections.py", line 50, in defaulterrorhandler
    raise errorvalue
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/cursors.py", line 252, in execute
    res = self._query(query)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/cursors.py", line 378, in _query
    db.query(q)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/connections.py", line 280, in query
    _mysql.connection.query(self, query)
_mysql_exceptions.OperationalError: (2006, 'MySQL server has gone away')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/bin/airflow", line 37, in <module>
    args.func(args)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/utils/cli.py", line 76, in wrapper
    return f(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/bin/cli.py", line 1221, in scheduler
    job.run()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/jobs/base_job.py", line 229, in run
    session.merge(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 2162, in merge
    return self._merge(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 2240, in _merge
    merged = self.query(mapper.class_).get(key[1])
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 1018, in get
    return self._get_impl(ident, loading.load_on_pk_identity)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 1135, in _get_impl
    return db_load_fn(self, primary_key_identity)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/loading.py", line 286, in load_on_pk_identity
    return q.one()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3490, in one
    ret = self.one_or_none()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3459, in one_or_none
    ret = list(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3535, in __iter__
    return self._execute_and_instances(context)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3560, in _execute_and_instances
    result = conn.execute(querycontext.statement, self._params)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1124, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1316, in _execute_context
    self._handle_dbapi_exception(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1510, in _handle_dbapi_exception
    util.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1276, in _execute_context
    self.dialect.do_execute(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/cursors.py", line 255, in execute
    self.errorhandler(self, exc, value)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/connections.py", line 50, in defaulterrorhandler
    raise errorvalue
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/cursors.py", line 252, in execute
    res = self._query(query)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/cursors.py", line 378, in _query
    db.query(q)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/connections.py", line 280, in query
    _mysql.connection.query(self, query)
sqlalchemy.exc.OperationalError: (_mysql_exceptions.OperationalError) (2006, 'MySQL server has gone away')
[SQL: SELECT job.id AS job_id, job.dag_id AS job_dag_id, job.state AS job_state, job.job_type AS job_job_type, job.start_date AS job_start_date, job.end_date AS job_end_date, job.latest_heartbeat AS job_latest_heartbeat, job.executor_class AS job_executor_class, job.hostname AS job_hostname, job.unixname AS job_unixname 
FROM job 
WHERE job.id = %s AND job.job_type IN (%s)]
[parameters: (5, 'SchedulerJob')]
(Background on this error at: http://sqlalche.me/e/13/e3q8)
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2020-11-12 11:08:05,380] {__init__.py:50} INFO - Using executor CeleryExecutor
[2020-11-12 11:08:05,395] {scheduler_job.py:1367} INFO - Starting the scheduler
[2020-11-12 11:08:05,395] {scheduler_job.py:1375} INFO - Running execute loop for -1 seconds
[2020-11-12 11:08:05,395] {scheduler_job.py:1376} INFO - Processing each file at most -1 times
[2020-11-12 11:08:05,395] {scheduler_job.py:1379} INFO - Searching for files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-12 11:08:05,430] {scheduler_job.py:1381} INFO - There are 27 files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-12 11:08:05,430] {scheduler_job.py:1438} INFO - Resetting orphaned tasks for active dag runs
[2020-11-12 11:08:05,440] {dag_processing.py:562} INFO - Launched DagFileProcessorManager with pid: 21388
[2020-11-12 11:08:05,442] {settings.py:55} INFO - Configured default timezone <Timezone [UTC]>
[2020-11-12 11:08:21,484] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:06:00+00:00 [scheduled]>
[2020-11-12 11:08:21,497] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:08:21,497] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:08:21,506] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:06:00+00:00 [scheduled]>
[2020-11-12 11:08:21,524] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:06:00+00:00 [queued]>
[2020-11-12 11:08:21,525] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 6, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:08:21,526] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:08:35,480] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:06:00+00:00 exited with status success for try_number 1
[2020-11-12 11:10:07,580] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:08:00+00:00 [scheduled]>
[2020-11-12 11:10:07,591] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:10:07,591] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:10:07,600] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:08:00+00:00 [scheduled]>
[2020-11-12 11:10:07,614] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:08:00+00:00 [queued]>
[2020-11-12 11:10:07,615] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 8, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:10:07,616] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:08:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:10:19,595] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:08:00+00:00 exited with status success for try_number 1
[2020-11-12 11:12:05,675] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:10:00+00:00 [scheduled]>
[2020-11-12 11:12:05,678] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:12:05,678] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:12:05,680] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:10:00+00:00 [scheduled]>
[2020-11-12 11:12:05,687] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:10:00+00:00 [queued]>
[2020-11-12 11:12:05,687] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:12:05,688] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:12:19,704] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:10:00+00:00 exited with status success for try_number 1
[2020-11-12 11:13:23,764] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:06:00+00:00 [scheduled]>
[2020-11-12 11:13:23,774] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:13:23,774] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:13:23,781] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:06:00+00:00 [scheduled]>
[2020-11-12 11:13:23,790] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:06:00+00:00 [queued]>
[2020-11-12 11:13:23,790] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 6, tzinfo=<Timezone [UTC]>), 2) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:13:23,791] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:13:37,780] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:06:00+00:00 exited with status success for try_number 2
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2020-11-12 11:14:14,538] {__init__.py:50} INFO - Using executor CeleryExecutor
[2020-11-12 11:14:14,546] {scheduler_job.py:1367} INFO - Starting the scheduler
[2020-11-12 11:14:14,546] {scheduler_job.py:1375} INFO - Running execute loop for -1 seconds
[2020-11-12 11:14:14,546] {scheduler_job.py:1376} INFO - Processing each file at most -1 times
[2020-11-12 11:14:14,546] {scheduler_job.py:1379} INFO - Searching for files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-12 11:14:14,548] {scheduler_job.py:1381} INFO - There are 27 files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-12 11:14:14,548] {scheduler_job.py:1438} INFO - Resetting orphaned tasks for active dag runs
[2020-11-12 11:14:14,554] {dag_processing.py:562} INFO - Launched DagFileProcessorManager with pid: 23624
[2020-11-12 11:14:14,559] {settings.py:55} INFO - Configured default timezone <Timezone [UTC]>
[2020-11-12 11:14:16,566] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:12:00+00:00 [scheduled]>
[2020-11-12 11:14:16,571] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:14:16,571] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:14:16,580] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:12:00+00:00 [scheduled]>
[2020-11-12 11:14:16,597] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:12:00+00:00 [queued]>
[2020-11-12 11:14:16,597] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 12, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:14:16,598] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:12:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:14:30,595] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:12:00+00:00 exited with status success for try_number 1
Process DagFileProcessor64-Process:
Traceback (most recent call last):
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 493, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/__init__.py", line 85, in Connect
    return Connection(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/connections.py", line 208, in __init__
    super(Connection, self).__init__(*args, **kwargs2)
_mysql_exceptions.OperationalError: (2006, "Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/jobs/scheduler_job.py", line 157, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/jobs/scheduler_job.py", line 1609, in process_file
    dag.sync_to_db()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/models/dag.py", line 1514, in sync_to_db
    orm_dag = session.query(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3429, in first
    ret = list(self[0:1])
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3203, in __getitem__
    return list(res)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3535, in __iter__
    return self._execute_and_instances(context)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3556, in _execute_and_instances
    conn = self._get_bind_args(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3571, in _get_bind_args
    return fn(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3550, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1138, in connection
    return self._connection_for_bind(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1146, in _connection_for_bind
    return self.transaction._connection_for_bind(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 433, in _connection_for_bind
    conn = bind._contextual_connect()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2302, in _contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2339, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1583, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 493, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/__init__.py", line 85, in Connect
    return Connection(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/connections.py", line 208, in __init__
    super(Connection, self).__init__(*args, **kwargs2)
sqlalchemy.exc.OperationalError: (_mysql_exceptions.OperationalError) (2006, "Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)")
(Background on this error at: http://sqlalche.me/e/13/e3q8)
Process DagFileProcessor65-Process:
Traceback (most recent call last):
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 493, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/__init__.py", line 85, in Connect
    return Connection(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/connections.py", line 208, in __init__
    super(Connection, self).__init__(*args, **kwargs2)
_mysql_exceptions.OperationalError: (2006, "Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/jobs/scheduler_job.py", line 157, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/jobs/scheduler_job.py", line 1609, in process_file
    dag.sync_to_db()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/models/dag.py", line 1514, in sync_to_db
    orm_dag = session.query(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3429, in first
    ret = list(self[0:1])
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3203, in __getitem__
    return list(res)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3535, in __iter__
    return self._execute_and_instances(context)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3556, in _execute_and_instances
    conn = self._get_bind_args(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3571, in _get_bind_args
    return fn(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3550, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1138, in connection
    return self._connection_for_bind(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1146, in _connection_for_bind
    return self.transaction._connection_for_bind(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 433, in _connection_for_bind
    conn = bind._contextual_connect()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2302, in _contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2339, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1583, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 493, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/__init__.py", line 85, in Connect
    return Connection(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/connections.py", line 208, in __init__
    super(Connection, self).__init__(*args, **kwargs2)
sqlalchemy.exc.OperationalError: (_mysql_exceptions.OperationalError) (2006, "Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)")
(Background on this error at: http://sqlalche.me/e/13/e3q8)
[2020-11-12 11:14:47,374] {helpers.py:325} INFO - Sending Signals.SIGTERM to GPID 23624
[2020-11-12 11:14:47,400] {helpers.py:291} INFO - Process psutil.Process(pid=23624, status='terminated', exitcode=0, started='11:14:14') (23624) terminated with exit code 0
[2020-11-12 11:14:47,401] {scheduler_job.py:1404} INFO - Exited execute loop
Traceback (most recent call last):
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1276, in _execute_context
    self.dialect.do_execute(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/cursors.py", line 255, in execute
    self.errorhandler(self, exc, value)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/connections.py", line 50, in defaulterrorhandler
    raise errorvalue
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/cursors.py", line 252, in execute
    res = self._query(query)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/cursors.py", line 378, in _query
    db.query(q)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/connections.py", line 280, in query
    _mysql.connection.query(self, query)
_mysql_exceptions.OperationalError: (2006, 'MySQL server has gone away')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/bin/airflow", line 37, in <module>
    args.func(args)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/utils/cli.py", line 76, in wrapper
    return f(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/bin/cli.py", line 1221, in scheduler
    job.run()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/jobs/base_job.py", line 229, in run
    session.merge(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 2162, in merge
    return self._merge(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 2240, in _merge
    merged = self.query(mapper.class_).get(key[1])
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 1018, in get
    return self._get_impl(ident, loading.load_on_pk_identity)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 1135, in _get_impl
    return db_load_fn(self, primary_key_identity)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/loading.py", line 286, in load_on_pk_identity
    return q.one()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3490, in one
    ret = self.one_or_none()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3459, in one_or_none
    ret = list(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3535, in __iter__
    return self._execute_and_instances(context)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3560, in _execute_and_instances
    result = conn.execute(querycontext.statement, self._params)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1124, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1316, in _execute_context
    self._handle_dbapi_exception(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1510, in _handle_dbapi_exception
    util.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1276, in _execute_context
    self.dialect.do_execute(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/cursors.py", line 255, in execute
    self.errorhandler(self, exc, value)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/connections.py", line 50, in defaulterrorhandler
    raise errorvalue
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/cursors.py", line 252, in execute
    res = self._query(query)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/cursors.py", line 378, in _query
    db.query(q)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/connections.py", line 280, in query
    _mysql.connection.query(self, query)
sqlalchemy.exc.OperationalError: (_mysql_exceptions.OperationalError) (2006, 'MySQL server has gone away')
[SQL: SELECT job.id AS job_id, job.dag_id AS job_dag_id, job.state AS job_state, job.job_type AS job_job_type, job.start_date AS job_start_date, job.end_date AS job_end_date, job.latest_heartbeat AS job_latest_heartbeat, job.executor_class AS job_executor_class, job.hostname AS job_hostname, job.unixname AS job_unixname 
FROM job 
WHERE job.id = %s AND job.job_type IN (%s)]
[parameters: (874, 'SchedulerJob')]
(Background on this error at: http://sqlalche.me/e/13/e3q8)
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2020-11-12 11:18:23,086] {__init__.py:50} INFO - Using executor CeleryExecutor
[2020-11-12 11:18:23,102] {scheduler_job.py:1367} INFO - Starting the scheduler
[2020-11-12 11:18:23,102] {scheduler_job.py:1375} INFO - Running execute loop for -1 seconds
[2020-11-12 11:18:23,102] {scheduler_job.py:1376} INFO - Processing each file at most -1 times
[2020-11-12 11:18:23,102] {scheduler_job.py:1379} INFO - Searching for files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-12 11:18:23,174] {scheduler_job.py:1381} INFO - There are 27 files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-12 11:18:23,174] {scheduler_job.py:1438} INFO - Resetting orphaned tasks for active dag runs
[2020-11-12 11:18:23,190] {dag_processing.py:562} INFO - Launched DagFileProcessorManager with pid: 5923
[2020-11-12 11:18:23,192] {settings.py:55} INFO - Configured default timezone <Timezone [UTC]>
[2020-11-12 11:18:29,209] {scheduler_job.py:961} INFO - 3 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:08:00+00:00 [scheduled]>
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:10:00+00:00 [scheduled]>
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:16:00+00:00 [scheduled]>
[2020-11-12 11:18:29,216] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 3 task instances ready to be queued
[2020-11-12 11:18:29,216] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:18:29,216] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 1/16 running and queued tasks
[2020-11-12 11:18:29,216] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 2/16 running and queued tasks
[2020-11-12 11:18:29,220] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:08:00+00:00 [scheduled]>
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:10:00+00:00 [scheduled]>
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:16:00+00:00 [scheduled]>
[2020-11-12 11:18:29,237] {scheduler_job.py:1158} INFO - Setting the following 3 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:08:00+00:00 [queued]>
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:10:00+00:00 [queued]>
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:16:00+00:00 [queued]>
[2020-11-12 11:18:29,237] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 8, tzinfo=<Timezone [UTC]>), 2) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:18:29,237] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:08:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:18:29,237] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 10, tzinfo=<Timezone [UTC]>), 2) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:18:29,238] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:18:29,238] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 16, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:18:29,238] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:16:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:18:41,237] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:08:00+00:00 exited with status success for try_number 2
[2020-11-12 11:18:41,244] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:10:00+00:00 exited with status success for try_number 2
[2020-11-12 11:18:41,248] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:16:00+00:00 exited with status success for try_number 1
[2020-11-12 11:20:13,313] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:18:00+00:00 [scheduled]>
[2020-11-12 11:20:13,323] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:20:13,324] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:20:13,332] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:18:00+00:00 [scheduled]>
[2020-11-12 11:20:13,348] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:18:00+00:00 [queued]>
[2020-11-12 11:20:13,349] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 18, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:20:13,349] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:18:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:20:27,331] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:18:00+00:00 exited with status success for try_number 1
[2020-11-12 11:22:11,428] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:20:00+00:00 [scheduled]>
[2020-11-12 11:22:11,438] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:22:11,439] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:22:11,448] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:20:00+00:00 [scheduled]>
[2020-11-12 11:22:11,464] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:20:00+00:00 [queued]>
[2020-11-12 11:22:11,465] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:22:11,465] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:22:25,441] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:20:00+00:00 exited with status success for try_number 1
[2020-11-12 11:24:11,525] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:22:00+00:00 [scheduled]>
[2020-11-12 11:24:11,527] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:24:11,527] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:24:11,529] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:22:00+00:00 [scheduled]>
[2020-11-12 11:24:11,535] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:22:00+00:00 [queued]>
[2020-11-12 11:24:11,535] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 22, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:24:11,536] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:22:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:24:23,529] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:22:00+00:00 exited with status success for try_number 1
[2020-11-12 11:26:09,643] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:24:00+00:00 [scheduled]>
[2020-11-12 11:26:09,648] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:26:09,648] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:26:09,652] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:24:00+00:00 [scheduled]>
[2020-11-12 11:26:09,660] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:24:00+00:00 [queued]>
[2020-11-12 11:26:09,661] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 24, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:26:09,661] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:24:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:26:23,653] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:24:00+00:00 exited with status success for try_number 1
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2020-11-12 11:28:02,936] {__init__.py:50} INFO - Using executor CeleryExecutor
[2020-11-12 11:28:02,943] {scheduler_job.py:1367} INFO - Starting the scheduler
[2020-11-12 11:28:02,943] {scheduler_job.py:1375} INFO - Running execute loop for -1 seconds
[2020-11-12 11:28:02,943] {scheduler_job.py:1376} INFO - Processing each file at most -1 times
[2020-11-12 11:28:02,943] {scheduler_job.py:1379} INFO - Searching for files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-12 11:28:02,945] {scheduler_job.py:1381} INFO - There are 27 files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-12 11:28:02,946] {scheduler_job.py:1438} INFO - Resetting orphaned tasks for active dag runs
[2020-11-12 11:28:02,952] {dag_processing.py:562} INFO - Launched DagFileProcessorManager with pid: 9780
[2020-11-12 11:28:02,954] {settings.py:55} INFO - Configured default timezone <Timezone [UTC]>
[2020-11-12 11:28:06,986] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:26:00+00:00 [scheduled]>
[2020-11-12 11:28:07,001] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:28:07,002] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:28:07,010] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:26:00+00:00 [scheduled]>
[2020-11-12 11:28:07,026] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:26:00+00:00 [queued]>
[2020-11-12 11:28:07,026] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 26, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:28:07,026] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:26:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:28:20,996] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:26:00+00:00 exited with status success for try_number 1
[2020-11-12 11:30:05,090] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:28:00+00:00 [scheduled]>
[2020-11-12 11:30:05,099] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:30:05,100] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:30:05,108] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:28:00+00:00 [scheduled]>
[2020-11-12 11:30:05,123] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:28:00+00:00 [queued]>
[2020-11-12 11:30:05,124] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 28, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:30:05,125] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:28:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:30:19,106] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:28:00+00:00 exited with status success for try_number 1
[2020-11-12 11:32:03,202] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:30:00+00:00 [scheduled]>
[2020-11-12 11:32:03,211] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:32:03,212] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:32:03,218] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:30:00+00:00 [scheduled]>
[2020-11-12 11:32:03,224] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:30:00+00:00 [queued]>
[2020-11-12 11:32:03,224] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:32:03,224] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:32:17,216] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:30:00+00:00 exited with status success for try_number 1
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2020-11-12 11:33:49,791] {__init__.py:50} INFO - Using executor CeleryExecutor
[2020-11-12 11:33:49,797] {scheduler_job.py:1367} INFO - Starting the scheduler
[2020-11-12 11:33:49,797] {scheduler_job.py:1375} INFO - Running execute loop for -1 seconds
[2020-11-12 11:33:49,797] {scheduler_job.py:1376} INFO - Processing each file at most -1 times
[2020-11-12 11:33:49,798] {scheduler_job.py:1379} INFO - Searching for files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-12 11:33:49,800] {scheduler_job.py:1381} INFO - There are 27 files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-12 11:33:49,800] {scheduler_job.py:1438} INFO - Resetting orphaned tasks for active dag runs
[2020-11-12 11:33:49,807] {dag_processing.py:562} INFO - Launched DagFileProcessorManager with pid: 11681
[2020-11-12 11:33:49,809] {settings.py:55} INFO - Configured default timezone <Timezone [UTC]>
[2020-11-12 11:34:09,839] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:32:00+00:00 [scheduled]>
[2020-11-12 11:34:09,841] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:34:09,841] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:34:09,843] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:32:00+00:00 [scheduled]>
[2020-11-12 11:34:09,850] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:32:00+00:00 [queued]>
[2020-11-12 11:34:09,850] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 32, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:34:09,851] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:32:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:34:21,866] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:32:00+00:00 exited with status success for try_number 1
[2020-11-12 11:36:07,965] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:34:00+00:00 [scheduled]>
[2020-11-12 11:36:07,975] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:36:07,976] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:36:07,984] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:34:00+00:00 [scheduled]>
[2020-11-12 11:36:07,998] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:34:00+00:00 [queued]>
[2020-11-12 11:36:07,999] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 34, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:36:07,999] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:34:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:36:19,980] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:34:00+00:00 exited with status success for try_number 1
[2020-11-12 11:38:06,075] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:36:00+00:00 [scheduled]>
[2020-11-12 11:38:06,087] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:38:06,087] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:38:06,097] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:36:00+00:00 [scheduled]>
[2020-11-12 11:38:06,111] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:36:00+00:00 [queued]>
[2020-11-12 11:38:06,112] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 36, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:38:06,113] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:36:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:38:20,092] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:36:00+00:00 exited with status success for try_number 1
[2020-11-12 11:39:24,151] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:32:00+00:00 [scheduled]>
[2020-11-12 11:39:24,161] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:39:24,161] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:39:24,169] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:32:00+00:00 [scheduled]>
[2020-11-12 11:39:24,178] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:32:00+00:00 [queued]>
[2020-11-12 11:39:24,178] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 32, tzinfo=<Timezone [UTC]>), 2) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:39:24,179] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:32:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:39:38,151] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:32:00+00:00 exited with status success for try_number 2
[2020-11-12 11:40:04,191] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:38:00+00:00 [scheduled]>
[2020-11-12 11:40:04,202] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:40:04,203] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:40:04,212] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:38:00+00:00 [scheduled]>
[2020-11-12 11:40:04,228] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:38:00+00:00 [queued]>
[2020-11-12 11:40:04,229] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 38, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:40:04,230] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:38:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:40:18,205] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:38:00+00:00 exited with status success for try_number 1
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2020-11-12 11:40:57,408] {__init__.py:50} INFO - Using executor CeleryExecutor
[2020-11-12 11:40:57,416] {scheduler_job.py:1367} INFO - Starting the scheduler
[2020-11-12 11:40:57,416] {scheduler_job.py:1375} INFO - Running execute loop for -1 seconds
[2020-11-12 11:40:57,417] {scheduler_job.py:1376} INFO - Processing each file at most -1 times
[2020-11-12 11:40:57,417] {scheduler_job.py:1379} INFO - Searching for files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-12 11:40:57,419] {scheduler_job.py:1381} INFO - There are 27 files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-12 11:40:57,419] {scheduler_job.py:1438} INFO - Resetting orphaned tasks for active dag runs
[2020-11-12 11:40:57,427] {dag_processing.py:562} INFO - Launched DagFileProcessorManager with pid: 15177
[2020-11-12 11:40:57,432] {settings.py:55} INFO - Configured default timezone <Timezone [UTC]>
[2020-11-12 11:41:23,476] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:34:00+00:00 [scheduled]>
[2020-11-12 11:41:23,488] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:41:23,489] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:41:23,498] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:34:00+00:00 [scheduled]>
[2020-11-12 11:41:23,515] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:34:00+00:00 [queued]>
[2020-11-12 11:41:23,516] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 34, tzinfo=<Timezone [UTC]>), 2) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:41:23,517] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:34:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:41:37,487] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:34:00+00:00 exited with status success for try_number 2
[2020-11-12 11:42:03,496] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:40:00+00:00 [scheduled]>
[2020-11-12 11:42:03,498] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:42:03,498] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:42:03,500] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:40:00+00:00 [scheduled]>
[2020-11-12 11:42:03,507] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:40:00+00:00 [queued]>
[2020-11-12 11:42:03,507] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:42:03,507] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:42:15,508] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:40:00+00:00 exited with status success for try_number 1
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2020-11-12 11:43:33,781] {__init__.py:50} INFO - Using executor CeleryExecutor
[2020-11-12 11:43:33,788] {scheduler_job.py:1367} INFO - Starting the scheduler
[2020-11-12 11:43:33,788] {scheduler_job.py:1375} INFO - Running execute loop for -1 seconds
[2020-11-12 11:43:33,788] {scheduler_job.py:1376} INFO - Processing each file at most -1 times
[2020-11-12 11:43:33,788] {scheduler_job.py:1379} INFO - Searching for files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-12 11:43:33,791] {scheduler_job.py:1381} INFO - There are 27 files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-12 11:43:33,791] {scheduler_job.py:1438} INFO - Resetting orphaned tasks for active dag runs
[2020-11-12 11:43:33,797] {dag_processing.py:562} INFO - Launched DagFileProcessorManager with pid: 16111
[2020-11-12 11:43:33,799] {settings.py:55} INFO - Configured default timezone <Timezone [UTC]>
[2020-11-12 11:43:35,807] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:36:00+00:00 [scheduled]>
[2020-11-12 11:43:35,811] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:43:35,812] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:43:35,814] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:36:00+00:00 [scheduled]>
[2020-11-12 11:43:35,821] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:36:00+00:00 [queued]>
[2020-11-12 11:43:35,821] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 36, tzinfo=<Timezone [UTC]>), 2) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:43:35,822] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:36:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:43:49,823] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:36:00+00:00 exited with status success for try_number 2
[2020-11-12 11:44:01,835] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:42:00+00:00 [scheduled]>
[2020-11-12 11:44:01,837] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:44:01,837] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:44:01,839] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:42:00+00:00 [scheduled]>
[2020-11-12 11:44:01,845] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:42:00+00:00 [queued]>
[2020-11-12 11:44:01,845] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 42, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:44:01,846] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:42:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:44:15,848] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:42:00+00:00 exited with status success for try_number 1
[2020-11-12 11:45:07,910] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:38:00+00:00 [scheduled]>
[2020-11-12 11:45:07,920] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:45:07,920] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:45:07,929] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:38:00+00:00 [scheduled]>
[2020-11-12 11:45:07,939] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:38:00+00:00 [queued]>
[2020-11-12 11:45:07,940] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 38, tzinfo=<Timezone [UTC]>), 2) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:45:07,940] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:38:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:45:21,923] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:38:00+00:00 exited with status success for try_number 2
[2020-11-12 11:46:13,965] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:44:00+00:00 [scheduled]>
[2020-11-12 11:46:13,975] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:46:13,976] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:46:13,985] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:44:00+00:00 [scheduled]>
[2020-11-12 11:46:13,999] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:44:00+00:00 [queued]>
[2020-11-12 11:46:13,999] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 44, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:46:14,000] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:44:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:46:27,989] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:44:00+00:00 exited with status success for try_number 1
[2020-11-12 11:47:06,020] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:40:00+00:00 [scheduled]>
[2020-11-12 11:47:06,030] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:47:06,030] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:47:06,038] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:40:00+00:00 [scheduled]>
[2020-11-12 11:47:06,047] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:40:00+00:00 [queued]>
[2020-11-12 11:47:06,048] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 40, tzinfo=<Timezone [UTC]>), 2) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:47:06,048] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:47:20,033] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:40:00+00:00 exited with status success for try_number 2
[2020-11-12 11:48:12,070] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:46:00+00:00 [scheduled]>
[2020-11-12 11:48:12,072] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:48:12,073] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:48:12,074] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:46:00+00:00 [scheduled]>
[2020-11-12 11:48:12,081] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:46:00+00:00 [queued]>
[2020-11-12 11:48:12,082] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 46, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:48:12,082] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:46:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:48:26,080] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:46:00+00:00 exited with status success for try_number 1
[2020-11-12 11:49:04,115] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:42:00+00:00 [scheduled]>
[2020-11-12 11:49:04,118] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:49:04,118] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:49:04,120] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:42:00+00:00 [scheduled]>
[2020-11-12 11:49:04,126] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:42:00+00:00 [queued]>
[2020-11-12 11:49:04,127] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 42, tzinfo=<Timezone [UTC]>), 2) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:49:04,127] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:42:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:49:18,146] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:48:00+00:00 [scheduled]>
[2020-11-12 11:49:18,156] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:49:18,157] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:49:18,166] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:48:00+00:00 [scheduled]>
[2020-11-12 11:49:18,182] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:48:00+00:00 [queued]>
[2020-11-12 11:49:18,182] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 48, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:49:18,183] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:48:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:49:18,245] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:42:00+00:00 exited with status success for try_number 2
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2020-11-12 11:49:28,456] {__init__.py:50} INFO - Using executor CeleryExecutor
[2020-11-12 11:49:28,463] {scheduler_job.py:1367} INFO - Starting the scheduler
[2020-11-12 11:49:28,463] {scheduler_job.py:1375} INFO - Running execute loop for -1 seconds
[2020-11-12 11:49:28,463] {scheduler_job.py:1376} INFO - Processing each file at most -1 times
[2020-11-12 11:49:28,463] {scheduler_job.py:1379} INFO - Searching for files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-12 11:49:28,465] {scheduler_job.py:1381} INFO - There are 27 files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-12 11:49:28,466] {scheduler_job.py:1438} INFO - Resetting orphaned tasks for active dag runs
[2020-11-12 11:49:28,471] {dag_processing.py:562} INFO - Launched DagFileProcessorManager with pid: 18563
[2020-11-12 11:49:28,474] {settings.py:55} INFO - Configured default timezone <Timezone [UTC]>
[2020-11-12 11:50:10,536] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:49:00+00:00 [scheduled]>
[2020-11-12 11:50:10,548] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:50:10,549] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:50:10,558] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:49:00+00:00 [scheduled]>
[2020-11-12 11:50:10,573] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:49:00+00:00 [queued]>
[2020-11-12 11:50:10,573] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 49, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:50:10,574] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:49:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:50:24,537] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:50:22.077376+00:00 [scheduled]>
[2020-11-12 11:50:24,542] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:50:24,542] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:50:24,545] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:50:22.077376+00:00 [scheduled]>
[2020-11-12 11:50:24,553] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:50:22.077376+00:00 [queued]>
[2020-11-12 11:50:24,553] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 50, 22, 77376, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:50:24,553] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:50:22.077376+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:50:24,620] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:49:00+00:00 exited with status success for try_number 1
[2020-11-12 11:50:36,549] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:50:22.077376+00:00 exited with status success for try_number 1
[2020-11-12 11:51:04,579] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:50:00+00:00 [scheduled]>
[2020-11-12 11:51:04,583] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:51:04,583] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:51:04,586] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:50:00+00:00 [scheduled]>
[2020-11-12 11:51:04,593] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:50:00+00:00 [queued]>
[2020-11-12 11:51:04,593] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:51:04,593] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:51:16,584] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:44:00+00:00 [scheduled]>
[2020-11-12 11:51:16,587] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:51:16,587] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:51:16,589] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:44:00+00:00 [scheduled]>
[2020-11-12 11:51:16,595] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:44:00+00:00 [queued]>
[2020-11-12 11:51:16,595] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 44, tzinfo=<Timezone [UTC]>), 2) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:51:16,596] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:44:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:51:16,648] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:50:00+00:00 exited with status success for try_number 1
[2020-11-12 11:51:30,596] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:44:00+00:00 exited with status success for try_number 2
[2020-11-12 11:52:08,639] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:51:00+00:00 [scheduled]>
[2020-11-12 11:52:08,643] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:52:08,644] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:52:08,647] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:51:00+00:00 [scheduled]>
[2020-11-12 11:52:08,657] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:51:00+00:00 [queued]>
[2020-11-12 11:52:08,658] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 51, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:52:08,658] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:51:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:52:22,651] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:51:00+00:00 exited with status success for try_number 1
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2020-11-12 11:52:29,040] {__init__.py:50} INFO - Using executor CeleryExecutor
[2020-11-12 11:52:29,048] {scheduler_job.py:1367} INFO - Starting the scheduler
[2020-11-12 11:52:29,048] {scheduler_job.py:1375} INFO - Running execute loop for -1 seconds
[2020-11-12 11:52:29,049] {scheduler_job.py:1376} INFO - Processing each file at most -1 times
[2020-11-12 11:52:29,049] {scheduler_job.py:1379} INFO - Searching for files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-12 11:52:29,051] {scheduler_job.py:1381} INFO - There are 27 files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-12 11:52:29,051] {scheduler_job.py:1438} INFO - Resetting orphaned tasks for active dag runs
[2020-11-12 11:52:29,058] {dag_processing.py:562} INFO - Launched DagFileProcessorManager with pid: 19870
[2020-11-12 11:52:29,061] {settings.py:55} INFO - Configured default timezone <Timezone [UTC]>
[2020-11-12 11:53:25,121] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:46:00+00:00 [scheduled]>
[2020-11-12 11:53:25,125] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:53:25,125] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:53:25,127] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:46:00+00:00 [scheduled]>
[2020-11-12 11:53:25,134] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:46:00+00:00 [queued]>
[2020-11-12 11:53:25,134] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 46, tzinfo=<Timezone [UTC]>), 2) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:53:25,134] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:46:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:53:37,151] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:46:00+00:00 exited with status success for try_number 2
[2020-11-12 11:54:05,173] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:52:00+00:00 [scheduled]>
[2020-11-12 11:54:05,183] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:54:05,184] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:54:05,192] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:52:00+00:00 [scheduled]>
[2020-11-12 11:54:05,205] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:52:00+00:00 [queued]>
[2020-11-12 11:54:05,206] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 52, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:54:05,206] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:52:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:54:17,180] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:52:00+00:00 exited with status success for try_number 1
[2020-11-12 11:56:03,288] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:54:00+00:00 [scheduled]>
[2020-11-12 11:56:03,297] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:56:03,298] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:56:03,306] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:54:00+00:00 [scheduled]>
[2020-11-12 11:56:03,321] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:54:00+00:00 [queued]>
[2020-11-12 11:56:03,322] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 54, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:56:03,322] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:54:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:56:15,281] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:54:00+00:00 exited with status success for try_number 1
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2020-11-12 11:56:39,103] {__init__.py:50} INFO - Using executor CeleryExecutor
[2020-11-12 11:56:39,113] {scheduler_job.py:1367} INFO - Starting the scheduler
[2020-11-12 11:56:39,113] {scheduler_job.py:1375} INFO - Running execute loop for -1 seconds
[2020-11-12 11:56:39,114] {scheduler_job.py:1376} INFO - Processing each file at most -1 times
[2020-11-12 11:56:39,114] {scheduler_job.py:1379} INFO - Searching for files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-12 11:56:39,116] {scheduler_job.py:1381} INFO - There are 27 files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-12 11:56:39,116] {scheduler_job.py:1438} INFO - Resetting orphaned tasks for active dag runs
[2020-11-12 11:56:39,124] {dag_processing.py:562} INFO - Launched DagFileProcessorManager with pid: 21403
[2020-11-12 11:56:39,126] {settings.py:55} INFO - Configured default timezone <Timezone [UTC]>
[2020-11-12 11:58:09,238] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:56:00+00:00 [scheduled]>
[2020-11-12 11:58:09,252] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 11:58:09,253] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 11:58:09,262] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:56:00+00:00 [scheduled]>
[2020-11-12 11:58:09,278] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:56:00+00:00 [queued]>
[2020-11-12 11:58:09,278] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 56, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 11:58:09,279] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:56:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 11:58:21,252] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:56:00+00:00 exited with status success for try_number 1
[2020-11-12 12:00:07,331] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:58:00+00:00 [scheduled]>
[2020-11-12 12:00:07,334] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 12:00:07,334] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 12:00:07,337] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:58:00+00:00 [scheduled]>
[2020-11-12 12:00:07,345] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 04:58:00+00:00 [queued]>
[2020-11-12 12:00:07,345] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 4, 58, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 12:00:07,346] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T04:58:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 12:00:19,345] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 04:58:00+00:00 exited with status success for try_number 1
[2020-11-12 12:02:05,461] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:00:00+00:00 [scheduled]>
[2020-11-12 12:02:05,472] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 12:02:05,473] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 12:02:05,481] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:00:00+00:00 [scheduled]>
[2020-11-12 12:02:05,496] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:00:00+00:00 [queued]>
[2020-11-12 12:02:05,496] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 5, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 12:02:05,497] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T05:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 12:02:17,457] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 05:00:00+00:00 exited with status success for try_number 1
[2020-11-12 12:04:03,578] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:02:00+00:00 [scheduled]>
[2020-11-12 12:04:03,588] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 12:04:03,588] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 12:04:03,590] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:02:00+00:00 [scheduled]>
[2020-11-12 12:04:03,597] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:02:00+00:00 [queued]>
[2020-11-12 12:04:03,597] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 5, 2, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 12:04:03,597] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T05:02:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 12:04:17,586] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 05:02:00+00:00 exited with status success for try_number 1
[2020-11-12 12:06:01,695] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:04:00+00:00 [scheduled]>
[2020-11-12 12:06:01,705] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 12:06:01,705] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 12:06:01,707] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:04:00+00:00 [scheduled]>
[2020-11-12 12:06:01,715] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:04:00+00:00 [queued]>
[2020-11-12 12:06:01,715] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 5, 4, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 12:06:01,716] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T05:04:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 12:06:15,713] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 05:04:00+00:00 exited with status success for try_number 1
[2020-11-12 12:08:13,820] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:06:00+00:00 [scheduled]>
[2020-11-12 12:08:13,832] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 12:08:13,832] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 12:08:13,841] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:06:00+00:00 [scheduled]>
[2020-11-12 12:08:13,855] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:06:00+00:00 [queued]>
[2020-11-12 12:08:13,855] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 5, 6, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 12:08:13,856] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T05:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 12:08:25,827] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 05:06:00+00:00 exited with status success for try_number 1
[2020-11-12 12:10:11,924] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:08:00+00:00 [scheduled]>
[2020-11-12 12:10:11,927] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 12:10:11,927] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 12:10:11,930] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:08:00+00:00 [scheduled]>
[2020-11-12 12:10:11,937] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:08:00+00:00 [queued]>
[2020-11-12 12:10:11,937] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 5, 8, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 12:10:11,937] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T05:08:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 12:10:25,934] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 05:08:00+00:00 exited with status success for try_number 1
[2020-11-12 12:12:10,029] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:10:00+00:00 [scheduled]>
[2020-11-12 12:12:10,031] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 12:12:10,031] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 12:12:10,033] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:10:00+00:00 [scheduled]>
[2020-11-12 12:12:10,039] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:10:00+00:00 [queued]>
[2020-11-12 12:12:10,039] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 5, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 12:12:10,039] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T05:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 12:12:24,046] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 05:10:00+00:00 exited with status success for try_number 1
[2020-11-12 12:14:08,161] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:12:00+00:00 [scheduled]>
[2020-11-12 12:14:08,171] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 12:14:08,172] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 12:14:08,181] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:12:00+00:00 [scheduled]>
[2020-11-12 12:14:08,194] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:12:00+00:00 [queued]>
[2020-11-12 12:14:08,195] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 5, 12, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 12:14:08,196] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T05:12:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 12:14:22,159] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 05:12:00+00:00 exited with status success for try_number 1
[2020-11-12 12:16:06,275] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:14:00+00:00 [scheduled]>
[2020-11-12 12:16:06,285] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 12:16:06,285] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 12:16:06,294] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:14:00+00:00 [scheduled]>
[2020-11-12 12:16:06,304] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:14:00+00:00 [queued]>
[2020-11-12 12:16:06,305] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 5, 14, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 12:16:06,305] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T05:14:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 12:16:20,274] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 05:14:00+00:00 exited with status success for try_number 1
[2020-11-12 12:18:06,375] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:16:00+00:00 [scheduled]>
[2020-11-12 12:18:06,377] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 12:18:06,377] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 12:18:06,379] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:16:00+00:00 [scheduled]>
[2020-11-12 12:18:06,386] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:16:00+00:00 [queued]>
[2020-11-12 12:18:06,386] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 5, 16, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 12:18:06,386] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T05:16:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 12:18:18,388] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 05:16:00+00:00 exited with status success for try_number 1
[2020-11-12 12:20:04,488] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:18:00+00:00 [scheduled]>
[2020-11-12 12:20:04,490] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 12:20:04,490] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 12:20:04,492] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:18:00+00:00 [scheduled]>
[2020-11-12 12:20:04,500] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:18:00+00:00 [queued]>
[2020-11-12 12:20:04,500] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 5, 18, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 12:20:04,500] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T05:18:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 12:20:16,512] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 05:18:00+00:00 exited with status success for try_number 1
[2020-11-12 12:22:02,602] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:20:00+00:00 [scheduled]>
[2020-11-12 12:22:02,604] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 12:22:02,604] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 12:22:02,606] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:20:00+00:00 [scheduled]>
[2020-11-12 12:22:02,613] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:20:00+00:00 [queued]>
[2020-11-12 12:22:02,613] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 5, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 12:22:02,613] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T05:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 12:22:14,614] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 05:20:00+00:00 exited with status success for try_number 1
[2020-11-12 12:24:12,737] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:22:00+00:00 [scheduled]>
[2020-11-12 12:24:12,747] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 12:24:12,747] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 12:24:12,756] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:22:00+00:00 [scheduled]>
[2020-11-12 12:24:12,770] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:22:00+00:00 [queued]>
[2020-11-12 12:24:12,770] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 5, 22, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 12:24:12,771] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T05:22:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 12:24:26,737] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 05:22:00+00:00 exited with status success for try_number 1
[2020-11-12 12:26:12,838] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:24:00+00:00 [scheduled]>
[2020-11-12 12:26:12,840] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 12:26:12,840] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 12:26:12,842] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:24:00+00:00 [scheduled]>
[2020-11-12 12:26:12,849] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:24:00+00:00 [queued]>
[2020-11-12 12:26:12,849] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 5, 24, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 12:26:12,850] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T05:24:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 12:26:24,865] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 05:24:00+00:00 exited with status success for try_number 1
[2020-11-12 12:28:10,967] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:26:00+00:00 [scheduled]>
[2020-11-12 12:28:10,977] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 12:28:10,977] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 12:28:10,986] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:26:00+00:00 [scheduled]>
[2020-11-12 12:28:10,998] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:26:00+00:00 [queued]>
[2020-11-12 12:28:10,998] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 5, 26, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 12:28:10,999] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T05:26:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 12:28:22,980] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 05:26:00+00:00 exited with status success for try_number 1
[2020-11-12 12:30:09,062] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:28:00+00:00 [scheduled]>
[2020-11-12 12:30:09,066] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 12:30:09,067] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 12:30:09,071] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:28:00+00:00 [scheduled]>
[2020-11-12 12:30:09,082] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:28:00+00:00 [queued]>
[2020-11-12 12:30:09,082] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 5, 28, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 12:30:09,083] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T05:28:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 12:30:23,077] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 05:28:00+00:00 exited with status success for try_number 1
[2020-11-12 12:32:07,174] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:30:00+00:00 [scheduled]>
[2020-11-12 12:32:07,176] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 12:32:07,176] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 12:32:07,178] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:30:00+00:00 [scheduled]>
[2020-11-12 12:32:07,189] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:30:00+00:00 [queued]>
[2020-11-12 12:32:07,190] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 5, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 12:32:07,190] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T05:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 12:32:21,188] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 05:30:00+00:00 exited with status success for try_number 1
[2020-11-12 12:34:05,294] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:32:00+00:00 [scheduled]>
[2020-11-12 12:34:05,303] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 12:34:05,304] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 12:34:05,312] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:32:00+00:00 [scheduled]>
[2020-11-12 12:34:05,326] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:32:00+00:00 [queued]>
[2020-11-12 12:34:05,327] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 5, 32, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 12:34:05,327] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T05:32:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 12:34:19,298] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 05:32:00+00:00 exited with status success for try_number 1
[2020-11-12 12:36:03,412] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:34:00+00:00 [scheduled]>
[2020-11-12 12:36:03,422] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 12:36:03,422] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 12:36:03,431] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:34:00+00:00 [scheduled]>
[2020-11-12 12:36:03,444] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:34:00+00:00 [queued]>
[2020-11-12 12:36:03,445] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 5, 34, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 12:36:03,445] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T05:34:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 12:36:17,415] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 05:34:00+00:00 exited with status success for try_number 1
[2020-11-12 12:38:03,530] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:36:00+00:00 [scheduled]>
[2020-11-12 12:38:03,539] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 12:38:03,540] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 12:38:03,548] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:36:00+00:00 [scheduled]>
[2020-11-12 12:38:03,561] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:36:00+00:00 [queued]>
[2020-11-12 12:38:03,562] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 5, 36, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 12:38:03,562] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T05:36:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 12:38:15,525] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 05:36:00+00:00 exited with status success for try_number 1
[2020-11-12 12:40:13,654] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:38:00+00:00 [scheduled]>
[2020-11-12 12:40:13,664] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 12:40:13,664] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 12:40:13,673] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:38:00+00:00 [scheduled]>
[2020-11-12 12:40:13,686] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:38:00+00:00 [queued]>
[2020-11-12 12:40:13,687] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 5, 38, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 12:40:13,688] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T05:38:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 12:40:27,671] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 05:38:00+00:00 exited with status success for try_number 1
[2020-11-12 12:42:11,761] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:40:00+00:00 [scheduled]>
[2020-11-12 12:42:11,763] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 12:42:11,763] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 12:42:11,765] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:40:00+00:00 [scheduled]>
[2020-11-12 12:42:11,772] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:40:00+00:00 [queued]>
[2020-11-12 12:42:11,772] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 5, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 12:42:11,772] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T05:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 12:42:25,778] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 05:40:00+00:00 exited with status success for try_number 1
[2020-11-12 12:44:11,878] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:42:00+00:00 [scheduled]>
[2020-11-12 12:44:11,888] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 12:44:11,888] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 12:44:11,896] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:42:00+00:00 [scheduled]>
[2020-11-12 12:44:11,909] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:42:00+00:00 [queued]>
[2020-11-12 12:44:11,909] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 5, 42, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 12:44:11,910] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T05:42:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 12:44:23,878] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 05:42:00+00:00 exited with status success for try_number 1
[2020-11-12 12:46:09,996] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:44:00+00:00 [scheduled]>
[2020-11-12 12:46:10,006] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 12:46:10,007] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 12:46:10,015] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:44:00+00:00 [scheduled]>
[2020-11-12 12:46:10,029] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:44:00+00:00 [queued]>
[2020-11-12 12:46:10,030] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 5, 44, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 12:46:10,031] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T05:44:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 12:46:21,992] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 05:44:00+00:00 exited with status success for try_number 1
[2020-11-12 12:48:08,113] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:46:00+00:00 [scheduled]>
[2020-11-12 12:48:08,123] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 12:48:08,123] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 12:48:08,132] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:46:00+00:00 [scheduled]>
[2020-11-12 12:48:08,146] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:46:00+00:00 [queued]>
[2020-11-12 12:48:08,146] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 5, 46, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 12:48:08,147] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T05:46:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 12:48:22,127] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 05:46:00+00:00 exited with status success for try_number 1
[2020-11-12 12:50:06,223] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:48:00+00:00 [scheduled]>
[2020-11-12 12:50:06,232] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 12:50:06,233] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 12:50:06,241] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:48:00+00:00 [scheduled]>
[2020-11-12 12:50:06,253] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:48:00+00:00 [queued]>
[2020-11-12 12:50:06,254] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 5, 48, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 12:50:06,254] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T05:48:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 12:50:20,236] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 05:48:00+00:00 exited with status success for try_number 1
[2020-11-12 12:52:04,335] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:50:00+00:00 [scheduled]>
[2020-11-12 12:52:04,344] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 12:52:04,345] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 12:52:04,353] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:50:00+00:00 [scheduled]>
[2020-11-12 12:52:04,367] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:50:00+00:00 [queued]>
[2020-11-12 12:52:04,367] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 5, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 12:52:04,368] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T05:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 12:52:18,352] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 05:50:00+00:00 exited with status success for try_number 1
[2020-11-12 12:54:02,434] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:52:00+00:00 [scheduled]>
[2020-11-12 12:54:02,437] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 12:54:02,437] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 12:54:02,439] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:52:00+00:00 [scheduled]>
[2020-11-12 12:54:02,447] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:52:00+00:00 [queued]>
[2020-11-12 12:54:02,447] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 5, 52, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 12:54:02,447] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T05:52:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 12:54:16,448] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 05:52:00+00:00 exited with status success for try_number 1
[2020-11-12 12:56:14,582] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:54:00+00:00 [scheduled]>
[2020-11-12 12:56:14,584] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 12:56:14,584] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 12:56:14,586] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:54:00+00:00 [scheduled]>
[2020-11-12 12:56:14,593] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:54:00+00:00 [queued]>
[2020-11-12 12:56:14,593] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 5, 54, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 12:56:14,593] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T05:54:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 12:56:28,613] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 05:54:00+00:00 exited with status success for try_number 1
[2020-11-12 12:58:12,689] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:56:00+00:00 [scheduled]>
[2020-11-12 12:58:12,691] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 12:58:12,691] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 12:58:12,693] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:56:00+00:00 [scheduled]>
[2020-11-12 12:58:12,699] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:56:00+00:00 [queued]>
[2020-11-12 12:58:12,699] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 5, 56, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 12:58:12,700] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T05:56:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 12:58:26,717] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 05:56:00+00:00 exited with status success for try_number 1
[2020-11-12 13:00:12,813] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:58:00+00:00 [scheduled]>
[2020-11-12 13:00:12,817] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 13:00:12,818] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 13:00:12,820] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:58:00+00:00 [scheduled]>
[2020-11-12 13:00:12,827] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 05:58:00+00:00 [queued]>
[2020-11-12 13:00:12,827] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 5, 58, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 13:00:12,827] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T05:58:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 13:00:24,814] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 05:58:00+00:00 exited with status success for try_number 1
[2020-11-12 13:02:10,922] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:00:00+00:00 [scheduled]>
[2020-11-12 13:02:10,931] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 13:02:10,932] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 13:02:10,940] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:00:00+00:00 [scheduled]>
[2020-11-12 13:02:10,954] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:00:00+00:00 [queued]>
[2020-11-12 13:02:10,954] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 6, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 13:02:10,954] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T06:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 13:02:22,920] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 06:00:00+00:00 exited with status success for try_number 1
[2020-11-12 13:04:09,020] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:02:00+00:00 [scheduled]>
[2020-11-12 13:04:09,030] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 13:04:09,030] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 13:04:09,039] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:02:00+00:00 [scheduled]>
[2020-11-12 13:04:09,050] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:02:00+00:00 [queued]>
[2020-11-12 13:04:09,051] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 6, 2, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 13:04:09,051] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T06:02:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 13:04:21,014] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 06:02:00+00:00 exited with status success for try_number 1
[2020-11-12 13:06:07,127] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:04:00+00:00 [scheduled]>
[2020-11-12 13:06:07,136] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 13:06:07,137] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 13:06:07,145] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:04:00+00:00 [scheduled]>
[2020-11-12 13:06:07,160] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:04:00+00:00 [queued]>
[2020-11-12 13:06:07,161] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 6, 4, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 13:06:07,161] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T06:04:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 13:06:21,123] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 06:04:00+00:00 exited with status success for try_number 1
[2020-11-12 13:08:05,237] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:06:00+00:00 [scheduled]>
[2020-11-12 13:08:05,246] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 13:08:05,247] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 13:08:05,255] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:06:00+00:00 [scheduled]>
[2020-11-12 13:08:05,270] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:06:00+00:00 [queued]>
[2020-11-12 13:08:05,270] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 6, 6, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 13:08:05,271] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T06:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 13:08:19,252] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 06:06:00+00:00 exited with status success for try_number 1
[2020-11-12 13:10:05,339] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:08:00+00:00 [scheduled]>
[2020-11-12 13:10:05,347] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 13:10:05,348] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 13:10:05,355] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:08:00+00:00 [scheduled]>
[2020-11-12 13:10:05,367] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:08:00+00:00 [queued]>
[2020-11-12 13:10:05,368] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 6, 8, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 13:10:05,369] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T06:08:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 13:10:17,355] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 06:08:00+00:00 exited with status success for try_number 1
[2020-11-12 13:12:03,454] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:10:00+00:00 [scheduled]>
[2020-11-12 13:12:03,456] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 13:12:03,456] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 13:12:03,458] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:10:00+00:00 [scheduled]>
[2020-11-12 13:12:03,465] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:10:00+00:00 [queued]>
[2020-11-12 13:12:03,465] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 6, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 13:12:03,465] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T06:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 13:12:15,454] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 06:10:00+00:00 exited with status success for try_number 1
[2020-11-12 13:14:15,580] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:12:00+00:00 [scheduled]>
[2020-11-12 13:14:15,589] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 13:14:15,590] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 13:14:15,598] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:12:00+00:00 [scheduled]>
[2020-11-12 13:14:15,613] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:12:00+00:00 [queued]>
[2020-11-12 13:14:15,614] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 6, 12, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 13:14:15,614] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T06:12:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 13:14:27,578] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 06:12:00+00:00 exited with status success for try_number 1
[2020-11-12 13:16:13,691] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:14:00+00:00 [scheduled]>
[2020-11-12 13:16:13,700] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 13:16:13,701] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 13:16:13,709] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:14:00+00:00 [scheduled]>
[2020-11-12 13:16:13,725] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:14:00+00:00 [queued]>
[2020-11-12 13:16:13,726] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 6, 14, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 13:16:13,726] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T06:14:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 13:16:25,688] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 06:14:00+00:00 exited with status success for try_number 1
[2020-11-12 13:18:11,782] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:16:00+00:00 [scheduled]>
[2020-11-12 13:18:11,785] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 13:18:11,785] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 13:18:11,787] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:16:00+00:00 [scheduled]>
[2020-11-12 13:18:11,794] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:16:00+00:00 [queued]>
[2020-11-12 13:18:11,795] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 6, 16, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 13:18:11,795] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T06:16:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 13:18:25,799] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 06:16:00+00:00 exited with status success for try_number 1
[2020-11-12 13:20:09,902] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:18:00+00:00 [scheduled]>
[2020-11-12 13:20:09,907] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 13:20:09,907] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 13:20:09,910] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:18:00+00:00 [scheduled]>
[2020-11-12 13:20:09,917] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:18:00+00:00 [queued]>
[2020-11-12 13:20:09,918] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 6, 18, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 13:20:09,918] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T06:18:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 13:20:23,922] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 06:18:00+00:00 exited with status success for try_number 1
[2020-11-12 13:22:08,013] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:20:00+00:00 [scheduled]>
[2020-11-12 13:22:08,022] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 13:22:08,023] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 13:22:08,032] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:20:00+00:00 [scheduled]>
[2020-11-12 13:22:08,047] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:20:00+00:00 [queued]>
[2020-11-12 13:22:08,047] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 6, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 13:22:08,048] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T06:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 13:22:22,012] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 06:20:00+00:00 exited with status success for try_number 1
[2020-11-12 13:24:08,123] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:22:00+00:00 [scheduled]>
[2020-11-12 13:24:08,133] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 13:24:08,133] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 13:24:08,141] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:22:00+00:00 [scheduled]>
[2020-11-12 13:24:08,155] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:22:00+00:00 [queued]>
[2020-11-12 13:24:08,156] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 6, 22, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 13:24:08,157] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T06:22:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 13:24:20,135] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 06:22:00+00:00 exited with status success for try_number 1
[2020-11-12 13:26:06,223] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:24:00+00:00 [scheduled]>
[2020-11-12 13:26:06,232] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 13:26:06,232] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 13:26:06,241] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:24:00+00:00 [scheduled]>
[2020-11-12 13:26:06,254] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:24:00+00:00 [queued]>
[2020-11-12 13:26:06,254] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 6, 24, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 13:26:06,255] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T06:24:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 13:26:18,220] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 06:24:00+00:00 exited with status success for try_number 1
[2020-11-12 13:28:04,333] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:26:00+00:00 [scheduled]>
[2020-11-12 13:28:04,343] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 13:28:04,344] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 13:28:04,347] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:26:00+00:00 [scheduled]>
[2020-11-12 13:28:04,353] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:26:00+00:00 [queued]>
[2020-11-12 13:28:04,353] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 6, 26, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 13:28:04,354] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T06:26:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 13:28:18,334] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 06:26:00+00:00 exited with status success for try_number 1
[2020-11-12 13:30:02,425] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:28:00+00:00 [scheduled]>
[2020-11-12 13:30:02,429] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 13:30:02,429] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 13:30:02,433] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:28:00+00:00 [scheduled]>
[2020-11-12 13:30:02,443] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 06:28:00+00:00 [queued]>
[2020-11-12 13:30:02,443] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 6, 28, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 13:30:02,443] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T06:28:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 13:30:16,443] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 06:28:00+00:00 exited with status success for try_number 1
[2020-11-12 14:31:14,644] {scheduler_job.py:237} WARNING - Killing PID 65191
[2020-11-12 14:31:15,583] {scheduler_job.py:237} WARNING - Killing PID 65232
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2020-11-12 16:09:10,147] {__init__.py:50} INFO - Using executor CeleryExecutor
[2020-11-12 16:09:10,164] {scheduler_job.py:1367} INFO - Starting the scheduler
[2020-11-12 16:09:10,164] {scheduler_job.py:1375} INFO - Running execute loop for -1 seconds
[2020-11-12 16:09:10,165] {scheduler_job.py:1376} INFO - Processing each file at most -1 times
[2020-11-12 16:09:10,165] {scheduler_job.py:1379} INFO - Searching for files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-12 16:09:10,201] {scheduler_job.py:1381} INFO - There are 27 files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-12 16:09:10,201] {scheduler_job.py:1438} INFO - Resetting orphaned tasks for active dag runs
[2020-11-12 16:09:10,215] {dag_processing.py:562} INFO - Launched DagFileProcessorManager with pid: 21417
[2020-11-12 16:09:10,218] {settings.py:55} INFO - Configured default timezone <Timezone [UTC]>
[2020-11-12 16:09:32,271] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:06:00+00:00 [scheduled]>
[2020-11-12 16:09:32,283] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:09:32,284] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:09:32,290] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:06:00+00:00 [scheduled]>
[2020-11-12 16:09:32,304] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:06:00+00:00 [queued]>
[2020-11-12 16:09:32,304] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 6, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:09:32,305] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 16:09:44,278] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 09:06:00+00:00 exited with status success for try_number 1
[2020-11-12 16:10:10,300] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:08:00+00:00 [scheduled]>
[2020-11-12 16:10:10,311] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:10:10,311] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:10:10,321] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:08:00+00:00 [scheduled]>
[2020-11-12 16:10:10,336] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:08:00+00:00 [queued]>
[2020-11-12 16:10:10,338] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 8, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:10:10,338] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:08:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2020-11-12 16:11:01,755] {__init__.py:50} INFO - Using executor CeleryExecutor
[2020-11-12 16:11:01,764] {scheduler_job.py:1367} INFO - Starting the scheduler
[2020-11-12 16:11:01,764] {scheduler_job.py:1375} INFO - Running execute loop for -1 seconds
[2020-11-12 16:11:01,764] {scheduler_job.py:1376} INFO - Processing each file at most -1 times
[2020-11-12 16:11:01,764] {scheduler_job.py:1379} INFO - Searching for files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-12 16:11:01,766] {scheduler_job.py:1381} INFO - There are 27 files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-12 16:11:01,766] {scheduler_job.py:1438} INFO - Resetting orphaned tasks for active dag runs
[2020-11-12 16:11:01,772] {dag_processing.py:562} INFO - Launched DagFileProcessorManager with pid: 22221
[2020-11-12 16:11:01,775] {settings.py:55} INFO - Configured default timezone <Timezone [UTC]>
[2020-11-12 16:12:11,853] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:10:00+00:00 [scheduled]>
[2020-11-12 16:12:11,859] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:12:11,859] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:12:11,863] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:10:00+00:00 [scheduled]>
[2020-11-12 16:12:11,871] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:10:00+00:00 [queued]>
[2020-11-12 16:12:11,871] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:12:11,871] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 16:12:25,871] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 09:10:00+00:00 exited with status success for try_number 1
[2020-11-12 16:14:09,971] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:12:00+00:00 [scheduled]>
[2020-11-12 16:14:09,982] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:14:09,982] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:14:09,991] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:12:00+00:00 [scheduled]>
[2020-11-12 16:14:10,005] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:12:00+00:00 [queued]>
[2020-11-12 16:14:10,006] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 12, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:14:10,006] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:12:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 16:14:23,966] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 09:12:00+00:00 exited with status success for try_number 1
[2020-11-12 16:16:08,078] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:14:00+00:00 [scheduled]>
[2020-11-12 16:16:08,088] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:16:08,088] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:16:08,097] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:14:00+00:00 [scheduled]>
[2020-11-12 16:16:08,114] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:14:00+00:00 [queued]>
[2020-11-12 16:16:08,114] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 14, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:16:08,115] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:14:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 16:16:22,075] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 09:14:00+00:00 exited with status success for try_number 1
[2020-11-12 16:18:08,190] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:16:00+00:00 [scheduled]>
[2020-11-12 16:18:08,199] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:18:08,200] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:18:08,209] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:16:00+00:00 [scheduled]>
[2020-11-12 16:18:08,220] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:16:00+00:00 [queued]>
[2020-11-12 16:18:08,220] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 16, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:18:08,221] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:16:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 16:18:20,189] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 09:16:00+00:00 exited with status success for try_number 1
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2020-11-12 16:20:14,064] {__init__.py:50} INFO - Using executor CeleryExecutor
[2020-11-12 16:20:14,073] {scheduler_job.py:1367} INFO - Starting the scheduler
[2020-11-12 16:20:14,073] {scheduler_job.py:1375} INFO - Running execute loop for -1 seconds
[2020-11-12 16:20:14,073] {scheduler_job.py:1376} INFO - Processing each file at most -1 times
[2020-11-12 16:20:14,073] {scheduler_job.py:1379} INFO - Searching for files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-12 16:20:14,075] {scheduler_job.py:1381} INFO - There are 27 files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-12 16:20:14,076] {scheduler_job.py:1438} INFO - Resetting orphaned tasks for active dag runs
[2020-11-12 16:20:14,082] {dag_processing.py:562} INFO - Launched DagFileProcessorManager with pid: 25115
[2020-11-12 16:20:14,084] {settings.py:55} INFO - Configured default timezone <Timezone [UTC]>
[2020-11-12 16:20:26,104] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:18:00+00:00 [scheduled]>
[2020-11-12 16:20:26,109] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:20:26,110] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:20:26,113] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:18:00+00:00 [scheduled]>
[2020-11-12 16:20:26,122] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:18:00+00:00 [queued]>
[2020-11-12 16:20:26,123] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 18, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:20:26,123] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:18:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 16:20:38,116] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 09:18:00+00:00 exited with status success for try_number 1
[2020-11-12 16:22:10,210] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:20:00+00:00 [scheduled]>
[2020-11-12 16:22:10,219] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:22:10,220] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:22:10,228] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:20:00+00:00 [scheduled]>
[2020-11-12 16:22:10,240] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:20:00+00:00 [queued]>
[2020-11-12 16:22:10,241] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:22:10,241] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 16:22:24,207] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 09:20:00+00:00 exited with status success for try_number 1
[2020-11-12 16:24:08,324] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:22:00+00:00 [scheduled]>
[2020-11-12 16:24:08,334] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:24:08,335] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:24:08,343] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:22:00+00:00 [scheduled]>
[2020-11-12 16:24:08,355] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:22:00+00:00 [queued]>
[2020-11-12 16:24:08,356] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 22, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:24:08,356] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:22:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 16:24:22,334] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 09:22:00+00:00 exited with status success for try_number 1
[2020-11-12 16:26:08,436] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:24:00+00:00 [scheduled]>
[2020-11-12 16:26:08,446] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:26:08,446] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:26:08,455] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:24:00+00:00 [scheduled]>
[2020-11-12 16:26:08,469] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:24:00+00:00 [queued]>
[2020-11-12 16:26:08,469] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 24, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:26:08,470] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:24:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 16:26:20,433] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 09:24:00+00:00 exited with status success for try_number 1
[2020-11-12 16:28:06,545] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:26:00+00:00 [scheduled]>
[2020-11-12 16:28:06,554] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:28:06,555] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:28:06,564] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:26:00+00:00 [scheduled]>
[2020-11-12 16:28:06,575] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:26:00+00:00 [queued]>
[2020-11-12 16:28:06,576] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 26, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:28:06,576] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:26:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 16:28:18,537] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 09:26:00+00:00 exited with status success for try_number 1
[2020-11-12 16:30:04,647] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:28:00+00:00 [scheduled]>
[2020-11-12 16:30:04,651] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:30:04,651] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:30:04,653] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:28:00+00:00 [scheduled]>
[2020-11-12 16:30:04,660] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:28:00+00:00 [queued]>
[2020-11-12 16:30:04,660] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 28, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:30:04,660] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:28:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 16:30:16,673] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 09:28:00+00:00 exited with status success for try_number 1
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2020-11-12 16:31:17,775] {__init__.py:50} INFO - Using executor CeleryExecutor
[2020-11-12 16:31:17,782] {scheduler_job.py:1367} INFO - Starting the scheduler
[2020-11-12 16:31:17,782] {scheduler_job.py:1375} INFO - Running execute loop for -1 seconds
[2020-11-12 16:31:17,782] {scheduler_job.py:1376} INFO - Processing each file at most -1 times
[2020-11-12 16:31:17,782] {scheduler_job.py:1379} INFO - Searching for files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-12 16:31:17,785] {scheduler_job.py:1381} INFO - There are 27 files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-12 16:31:17,785] {scheduler_job.py:1438} INFO - Resetting orphaned tasks for active dag runs
[2020-11-12 16:31:17,791] {dag_processing.py:562} INFO - Launched DagFileProcessorManager with pid: 29336
[2020-11-12 16:31:17,793] {settings.py:55} INFO - Configured default timezone <Timezone [UTC]>
[2020-11-12 16:32:01,856] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:30:00+00:00 [scheduled]>
[2020-11-12 16:32:01,868] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:32:01,869] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:32:01,878] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:30:00+00:00 [scheduled]>
[2020-11-12 16:32:01,890] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:30:00+00:00 [queued]>
[2020-11-12 16:32:01,890] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:32:01,891] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 16:32:15,870] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 09:30:00+00:00 exited with status success for try_number 1
[2020-11-12 16:33:21,929] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:26:00+00:00 [scheduled]>
[2020-11-12 16:33:21,938] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:33:21,939] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:33:21,948] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:26:00+00:00 [scheduled]>
[2020-11-12 16:33:21,958] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:26:00+00:00 [queued]>
[2020-11-12 16:33:21,959] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 26, tzinfo=<Timezone [UTC]>), 2) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:33:21,959] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:26:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 16:33:33,931] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 09:26:00+00:00 exited with status success for try_number 2
[2020-11-12 16:34:13,970] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:32:00+00:00 [scheduled]>
[2020-11-12 16:34:13,976] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:34:13,976] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:34:13,981] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:32:00+00:00 [scheduled]>
[2020-11-12 16:34:13,993] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:32:00+00:00 [queued]>
[2020-11-12 16:34:13,994] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 32, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:34:13,995] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:32:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 16:34:27,999] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 09:32:00+00:00 exited with status success for try_number 1
[2020-11-12 16:35:20,028] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:28:00+00:00 [scheduled]>
[2020-11-12 16:35:20,031] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:35:20,031] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:35:20,033] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:28:00+00:00 [scheduled]>
[2020-11-12 16:35:20,040] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:28:00+00:00 [queued]>
[2020-11-12 16:35:20,040] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 28, tzinfo=<Timezone [UTC]>), 2) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:35:20,040] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:28:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 16:35:34,041] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 09:28:00+00:00 exited with status success for try_number 2
[2020-11-12 16:36:12,080] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:34:00+00:00 [scheduled]>
[2020-11-12 16:36:12,085] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:36:12,085] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:36:12,089] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:34:00+00:00 [scheduled]>
[2020-11-12 16:36:12,098] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:34:00+00:00 [queued]>
[2020-11-12 16:36:12,099] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 34, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:36:12,099] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:34:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 16:36:26,087] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 09:34:00+00:00 exited with status success for try_number 1
[2020-11-12 16:37:06,129] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:30:00+00:00 [scheduled]>
[2020-11-12 16:37:06,133] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:37:06,133] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:37:06,137] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:30:00+00:00 [scheduled]>
[2020-11-12 16:37:06,146] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:30:00+00:00 [queued]>
[2020-11-12 16:37:06,146] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 30, tzinfo=<Timezone [UTC]>), 2) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:37:06,147] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 16:37:18,141] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 09:30:00+00:00 exited with status success for try_number 2
[2020-11-12 16:38:10,181] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:36:00+00:00 [scheduled]>
[2020-11-12 16:38:10,184] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:38:10,184] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:38:10,186] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:36:00+00:00 [scheduled]>
[2020-11-12 16:38:10,192] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:36:00+00:00 [queued]>
[2020-11-12 16:38:10,193] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 36, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:38:10,193] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:36:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 16:38:24,198] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 09:36:00+00:00 exited with status success for try_number 1
[2020-11-12 16:39:30,279] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:32:00+00:00 [scheduled]>
[2020-11-12 16:39:30,290] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:39:30,290] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:39:30,298] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:32:00+00:00 [scheduled]>
[2020-11-12 16:39:30,309] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:32:00+00:00 [queued]>
[2020-11-12 16:39:30,309] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 32, tzinfo=<Timezone [UTC]>), 2) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:39:30,310] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:32:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 16:39:42,292] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 09:32:00+00:00 exited with status success for try_number 2
[2020-11-12 16:40:10,303] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:38:00+00:00 [scheduled]>
[2020-11-12 16:40:10,305] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:40:10,306] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:40:10,308] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:38:00+00:00 [scheduled]>
[2020-11-12 16:40:10,317] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:38:00+00:00 [queued]>
[2020-11-12 16:40:10,318] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 38, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:40:10,319] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:38:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 16:40:22,331] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 09:38:00+00:00 exited with status success for try_number 1
[2020-11-12 16:41:16,363] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:34:00+00:00 [scheduled]>
[2020-11-12 16:41:16,365] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:41:16,365] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:41:16,367] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:34:00+00:00 [scheduled]>
[2020-11-12 16:41:16,374] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:34:00+00:00 [queued]>
[2020-11-12 16:41:16,374] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 34, tzinfo=<Timezone [UTC]>), 2) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:41:16,374] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:34:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2020-11-12 16:41:28,629] {__init__.py:50} INFO - Using executor CeleryExecutor
[2020-11-12 16:41:28,637] {scheduler_job.py:1367} INFO - Starting the scheduler
[2020-11-12 16:41:28,637] {scheduler_job.py:1375} INFO - Running execute loop for -1 seconds
[2020-11-12 16:41:28,637] {scheduler_job.py:1376} INFO - Processing each file at most -1 times
[2020-11-12 16:41:28,637] {scheduler_job.py:1379} INFO - Searching for files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-12 16:41:28,640] {scheduler_job.py:1381} INFO - There are 27 files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-12 16:41:28,640] {scheduler_job.py:1438} INFO - Resetting orphaned tasks for active dag runs
[2020-11-12 16:41:28,649] {dag_processing.py:562} INFO - Launched DagFileProcessorManager with pid: 33012
[2020-11-12 16:41:28,653] {settings.py:55} INFO - Configured default timezone <Timezone [UTC]>
[2020-11-12 16:42:06,709] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:40:00+00:00 [scheduled]>
[2020-11-12 16:42:06,714] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:42:06,714] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:42:06,716] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:40:00+00:00 [scheduled]>
[2020-11-12 16:42:06,723] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:40:00+00:00 [queued]>
[2020-11-12 16:42:06,723] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:42:06,724] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 16:42:18,708] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 09:40:00+00:00 exited with status success for try_number 1
[2020-11-12 16:43:24,786] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:36:00+00:00 [scheduled]>
[2020-11-12 16:43:24,796] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:43:24,797] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:43:24,806] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:36:00+00:00 [scheduled]>
[2020-11-12 16:43:24,821] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:36:00+00:00 [queued]>
[2020-11-12 16:43:24,822] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 36, tzinfo=<Timezone [UTC]>), 2) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:43:24,822] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:36:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 16:43:38,801] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 09:36:00+00:00 exited with status success for try_number 2
[2020-11-12 16:44:04,818] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:42:00+00:00 [scheduled]>
[2020-11-12 16:44:04,821] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:44:04,821] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:44:04,823] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:42:00+00:00 [scheduled]>
[2020-11-12 16:44:04,830] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:42:00+00:00 [queued]>
[2020-11-12 16:44:04,830] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 42, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:44:04,831] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:42:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 16:44:18,838] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 09:42:00+00:00 exited with status success for try_number 1
[2020-11-12 16:45:22,883] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:38:00+00:00 [scheduled]>
[2020-11-12 16:45:22,885] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:45:22,885] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:45:22,887] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:38:00+00:00 [scheduled]>
[2020-11-12 16:45:22,893] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:38:00+00:00 [queued]>
[2020-11-12 16:45:22,894] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 38, tzinfo=<Timezone [UTC]>), 2) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:45:22,894] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:38:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 16:45:36,899] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 09:38:00+00:00 exited with status success for try_number 2
[2020-11-12 16:46:02,921] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:44:00+00:00 [scheduled]>
[2020-11-12 16:46:02,923] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:46:02,924] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:46:02,926] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:44:00+00:00 [scheduled]>
[2020-11-12 16:46:02,933] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:44:00+00:00 [queued]>
[2020-11-12 16:46:02,933] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 44, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:46:02,934] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:44:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 16:46:16,947] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 09:44:00+00:00 exited with status success for try_number 1
[2020-11-12 16:48:15,047] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:46:00+00:00 [scheduled]>
[2020-11-12 16:48:15,049] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:48:15,050] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:48:15,051] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:46:00+00:00 [scheduled]>
[2020-11-12 16:48:15,058] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:46:00+00:00 [queued]>
[2020-11-12 16:48:15,058] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 46, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:48:15,058] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:46:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 16:48:29,064] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 09:46:00+00:00 exited with status success for try_number 1
[2020-11-12 16:50:13,158] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:48:00+00:00 [scheduled]>
[2020-11-12 16:50:13,161] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:50:13,162] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:50:13,165] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:48:00+00:00 [scheduled]>
[2020-11-12 16:50:13,173] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:48:00+00:00 [queued]>
[2020-11-12 16:50:13,174] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 48, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:50:13,175] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:48:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 16:50:27,187] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 09:48:00+00:00 exited with status success for try_number 1
[2020-11-12 16:52:11,264] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:50:00+00:00 [scheduled]>
[2020-11-12 16:52:11,267] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:52:11,267] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:52:11,269] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:50:00+00:00 [scheduled]>
[2020-11-12 16:52:11,276] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:50:00+00:00 [queued]>
[2020-11-12 16:52:11,276] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:52:11,276] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 16:52:25,279] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 09:50:00+00:00 exited with status success for try_number 1
[2020-11-12 16:54:11,378] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:52:00+00:00 [scheduled]>
[2020-11-12 16:54:11,380] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:54:11,380] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:54:11,383] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:52:00+00:00 [scheduled]>
[2020-11-12 16:54:11,389] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:52:00+00:00 [queued]>
[2020-11-12 16:54:11,390] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 52, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:54:11,390] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:52:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 16:54:23,388] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 09:52:00+00:00 exited with status success for try_number 1
[2020-11-12 16:56:09,482] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:54:00+00:00 [scheduled]>
[2020-11-12 16:56:09,484] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:56:09,484] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:56:09,486] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:54:00+00:00 [scheduled]>
[2020-11-12 16:56:09,492] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:54:00+00:00 [queued]>
[2020-11-12 16:56:09,492] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 54, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:56:09,492] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:54:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 16:56:21,493] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 09:54:00+00:00 exited with status success for try_number 1
[2020-11-12 16:58:07,605] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:56:00+00:00 [scheduled]>
[2020-11-12 16:58:07,615] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 16:58:07,616] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 16:58:07,624] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:56:00+00:00 [scheduled]>
[2020-11-12 16:58:07,639] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:56:00+00:00 [queued]>
[2020-11-12 16:58:07,639] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 56, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 16:58:07,640] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:56:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 16:58:21,620] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 09:56:00+00:00 exited with status success for try_number 1
[2020-11-12 17:00:07,701] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:58:00+00:00 [scheduled]>
[2020-11-12 17:00:07,704] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 17:00:07,704] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 17:00:07,707] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:58:00+00:00 [scheduled]>
[2020-11-12 17:00:07,715] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 09:58:00+00:00 [queued]>
[2020-11-12 17:00:07,715] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 9, 58, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 17:00:07,715] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T09:58:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 17:00:19,720] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 09:58:00+00:00 exited with status success for try_number 1
[2020-11-12 17:02:05,810] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:00:00+00:00 [scheduled]>
[2020-11-12 17:02:05,812] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 17:02:05,812] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 17:02:05,814] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:00:00+00:00 [scheduled]>
[2020-11-12 17:02:05,821] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:00:00+00:00 [queued]>
[2020-11-12 17:02:05,821] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 10, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 17:02:05,821] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T10:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 17:02:17,847] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 10:00:00+00:00 exited with status success for try_number 1
[2020-11-12 17:04:03,940] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:02:00+00:00 [scheduled]>
[2020-11-12 17:04:03,950] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 17:04:03,950] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 17:04:03,959] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:02:00+00:00 [scheduled]>
[2020-11-12 17:04:03,974] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:02:00+00:00 [queued]>
[2020-11-12 17:04:03,974] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 10, 2, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 17:04:03,975] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T10:02:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 17:04:17,952] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 10:02:00+00:00 exited with status success for try_number 1
[2020-11-12 17:06:02,045] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:04:00+00:00 [scheduled]>
[2020-11-12 17:06:02,054] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 17:06:02,055] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 17:06:02,063] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:04:00+00:00 [scheduled]>
[2020-11-12 17:06:02,077] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:04:00+00:00 [queued]>
[2020-11-12 17:06:02,077] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 10, 4, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 17:06:02,077] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T10:04:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 17:06:16,060] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 10:04:00+00:00 exited with status success for try_number 1
[2020-11-12 17:08:14,174] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:06:00+00:00 [scheduled]>
[2020-11-12 17:08:14,183] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 17:08:14,184] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 17:08:14,193] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:06:00+00:00 [scheduled]>
[2020-11-12 17:08:14,208] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:06:00+00:00 [queued]>
[2020-11-12 17:08:14,208] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 10, 6, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 17:08:14,209] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T10:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 17:08:28,189] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 10:06:00+00:00 exited with status success for try_number 1
[2020-11-12 17:10:14,289] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:08:00+00:00 [scheduled]>
[2020-11-12 17:10:14,300] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 17:10:14,300] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 17:10:14,307] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:08:00+00:00 [scheduled]>
[2020-11-12 17:10:14,318] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:08:00+00:00 [queued]>
[2020-11-12 17:10:14,319] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 10, 8, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 17:10:14,319] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T10:08:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 17:10:26,299] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 10:08:00+00:00 exited with status success for try_number 1
[2020-11-12 17:12:12,391] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:10:00+00:00 [scheduled]>
[2020-11-12 17:12:12,394] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 17:12:12,394] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 17:12:12,396] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:10:00+00:00 [scheduled]>
[2020-11-12 17:12:12,402] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:10:00+00:00 [queued]>
[2020-11-12 17:12:12,402] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 10, 10, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 17:12:12,402] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T10:10:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 17:12:24,414] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 10:10:00+00:00 exited with status success for try_number 1
[2020-11-12 17:14:10,514] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:12:00+00:00 [scheduled]>
[2020-11-12 17:14:10,523] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 17:14:10,523] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 17:14:10,529] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:12:00+00:00 [scheduled]>
[2020-11-12 17:14:10,538] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:12:00+00:00 [queued]>
[2020-11-12 17:14:10,538] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 10, 12, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 17:14:10,538] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T10:12:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 17:14:24,531] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 10:12:00+00:00 exited with status success for try_number 1
[2020-11-12 17:16:08,613] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:14:00+00:00 [scheduled]>
[2020-11-12 17:16:08,615] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 17:16:08,615] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 17:16:08,617] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:14:00+00:00 [scheduled]>
[2020-11-12 17:16:08,627] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:14:00+00:00 [queued]>
[2020-11-12 17:16:08,627] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 10, 14, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 17:16:08,628] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T10:14:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 17:16:22,643] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 10:14:00+00:00 exited with status success for try_number 1
[2020-11-12 17:18:06,736] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:16:00+00:00 [scheduled]>
[2020-11-12 17:18:06,745] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 17:18:06,746] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 17:18:06,754] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:16:00+00:00 [scheduled]>
[2020-11-12 17:18:06,766] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:16:00+00:00 [queued]>
[2020-11-12 17:18:06,766] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 10, 16, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 17:18:06,766] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T10:16:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 17:18:20,741] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 10:16:00+00:00 exited with status success for try_number 1
[2020-11-12 17:20:06,835] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:18:00+00:00 [scheduled]>
[2020-11-12 17:20:06,838] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 17:20:06,838] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 17:20:06,840] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:18:00+00:00 [scheduled]>
[2020-11-12 17:20:06,846] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:18:00+00:00 [queued]>
[2020-11-12 17:20:06,846] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 10, 18, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 17:20:06,846] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T10:18:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 17:20:18,862] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 10:18:00+00:00 exited with status success for try_number 1
[2020-11-12 17:22:04,948] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:20:00+00:00 [scheduled]>
[2020-11-12 17:22:04,952] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 17:22:04,952] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 17:22:04,954] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:20:00+00:00 [scheduled]>
[2020-11-12 17:22:04,961] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:20:00+00:00 [queued]>
[2020-11-12 17:22:04,962] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 10, 20, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 17:22:04,962] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T10:20:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 17:22:16,965] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 10:20:00+00:00 exited with status success for try_number 1
[2020-11-12 17:24:03,066] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:22:00+00:00 [scheduled]>
[2020-11-12 17:24:03,076] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 17:24:03,076] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 17:24:03,085] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:22:00+00:00 [scheduled]>
[2020-11-12 17:24:03,099] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:22:00+00:00 [queued]>
[2020-11-12 17:24:03,100] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 10, 22, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 17:24:03,100] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T10:22:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 17:24:17,067] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 10:22:00+00:00 exited with status success for try_number 1
[2020-11-12 17:26:15,195] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:24:00+00:00 [scheduled]>
[2020-11-12 17:26:15,205] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 17:26:15,206] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 17:26:15,214] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:24:00+00:00 [scheduled]>
[2020-11-12 17:26:15,228] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:24:00+00:00 [queued]>
[2020-11-12 17:26:15,229] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 10, 24, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 17:26:15,230] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T10:24:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 17:26:27,207] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 10:24:00+00:00 exited with status success for try_number 1
[2020-11-12 17:28:13,303] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:26:00+00:00 [scheduled]>
[2020-11-12 17:28:13,312] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 17:28:13,313] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 17:28:13,321] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:26:00+00:00 [scheduled]>
[2020-11-12 17:28:13,337] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:26:00+00:00 [queued]>
[2020-11-12 17:28:13,337] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 10, 26, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 17:28:13,338] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T10:26:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 17:28:27,301] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 10:26:00+00:00 exited with status success for try_number 1
[2020-11-12 17:30:11,419] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:28:00+00:00 [scheduled]>
[2020-11-12 17:30:11,428] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 17:30:11,429] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 17:30:11,437] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:28:00+00:00 [scheduled]>
[2020-11-12 17:30:11,451] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:28:00+00:00 [queued]>
[2020-11-12 17:30:11,451] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 10, 28, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 17:30:11,452] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T10:28:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 17:30:25,416] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 10:28:00+00:00 exited with status success for try_number 1
[2020-11-12 17:32:11,535] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:30:00+00:00 [scheduled]>
[2020-11-12 17:32:11,546] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 17:32:11,547] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 17:32:11,554] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:30:00+00:00 [scheduled]>
[2020-11-12 17:32:11,565] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:30:00+00:00 [queued]>
[2020-11-12 17:32:11,565] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 10, 30, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 17:32:11,565] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T10:30:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 17:32:23,549] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 10:30:00+00:00 exited with status success for try_number 1
[2020-11-12 17:34:09,643] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:32:00+00:00 [scheduled]>
[2020-11-12 17:34:09,653] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 17:34:09,654] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 17:34:09,663] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:32:00+00:00 [scheduled]>
[2020-11-12 17:34:09,677] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:32:00+00:00 [queued]>
[2020-11-12 17:34:09,678] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 10, 32, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 17:34:09,679] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T10:32:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 17:34:23,657] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 10:32:00+00:00 exited with status success for try_number 1
[2020-11-12 17:36:07,741] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:34:00+00:00 [scheduled]>
[2020-11-12 17:36:07,747] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 17:36:07,748] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 17:36:07,753] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:34:00+00:00 [scheduled]>
[2020-11-12 17:36:07,765] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:34:00+00:00 [queued]>
[2020-11-12 17:36:07,766] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 10, 34, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 17:36:07,766] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T10:34:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 17:36:21,750] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 10:34:00+00:00 exited with status success for try_number 1
[2020-11-12 17:38:07,860] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:36:00+00:00 [scheduled]>
[2020-11-12 17:38:07,868] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 17:38:07,869] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 17:38:07,878] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:36:00+00:00 [scheduled]>
[2020-11-12 17:38:07,891] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:36:00+00:00 [queued]>
[2020-11-12 17:38:07,892] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 10, 36, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 17:38:07,892] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T10:36:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 17:38:19,862] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 10:36:00+00:00 exited with status success for try_number 1
[2020-11-12 17:40:05,973] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:38:00+00:00 [scheduled]>
[2020-11-12 17:40:05,983] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 17:40:05,984] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 17:40:05,992] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:38:00+00:00 [scheduled]>
[2020-11-12 17:40:06,005] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:38:00+00:00 [queued]>
[2020-11-12 17:40:06,005] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 10, 38, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 17:40:06,005] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T10:38:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 17:40:19,976] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 10:38:00+00:00 exited with status success for try_number 1
[2020-11-12 17:42:04,079] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:40:00+00:00 [scheduled]>
[2020-11-12 17:42:04,088] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 17:42:04,089] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 17:42:04,098] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:40:00+00:00 [scheduled]>
[2020-11-12 17:42:04,112] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:40:00+00:00 [queued]>
[2020-11-12 17:42:04,113] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 10, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 17:42:04,113] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T10:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 17:42:18,094] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 10:40:00+00:00 exited with status success for try_number 1
[2020-11-12 17:44:02,188] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:42:00+00:00 [scheduled]>
[2020-11-12 17:44:02,198] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 17:44:02,199] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 17:44:02,206] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:42:00+00:00 [scheduled]>
[2020-11-12 17:44:02,217] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:42:00+00:00 [queued]>
[2020-11-12 17:44:02,217] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 10, 42, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 17:44:02,217] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T10:42:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 17:44:16,186] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 10:42:00+00:00 exited with status success for try_number 1
[2020-11-12 17:46:14,313] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:44:00+00:00 [scheduled]>
[2020-11-12 17:46:14,322] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 17:46:14,323] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 17:46:14,331] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:44:00+00:00 [scheduled]>
[2020-11-12 17:46:14,345] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:44:00+00:00 [queued]>
[2020-11-12 17:46:14,346] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 10, 44, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 17:46:14,346] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T10:44:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 17:46:28,329] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 10:44:00+00:00 exited with status success for try_number 1
[2020-11-12 17:48:12,407] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:46:00+00:00 [scheduled]>
[2020-11-12 17:48:12,409] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 17:48:12,409] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 17:48:12,412] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:46:00+00:00 [scheduled]>
[2020-11-12 17:48:12,418] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:46:00+00:00 [queued]>
[2020-11-12 17:48:12,418] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 10, 46, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 17:48:12,418] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T10:46:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 17:48:26,440] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 10:46:00+00:00 exited with status success for try_number 1
[2020-11-12 17:50:12,537] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:48:00+00:00 [scheduled]>
[2020-11-12 17:50:12,547] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 17:50:12,547] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 17:50:12,553] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:48:00+00:00 [scheduled]>
[2020-11-12 17:50:12,563] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:48:00+00:00 [queued]>
[2020-11-12 17:50:12,563] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 10, 48, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 17:50:12,564] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T10:48:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 17:50:24,541] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 10:48:00+00:00 exited with status success for try_number 1
[2020-11-12 17:52:10,649] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:50:00+00:00 [scheduled]>
[2020-11-12 17:52:10,659] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 17:52:10,659] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 17:52:10,667] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:50:00+00:00 [scheduled]>
[2020-11-12 17:52:10,678] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:50:00+00:00 [queued]>
[2020-11-12 17:52:10,678] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 10, 50, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 17:52:10,679] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T10:50:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 17:52:22,663] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 10:50:00+00:00 exited with status success for try_number 1
[2020-11-12 17:54:08,759] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:52:00+00:00 [scheduled]>
[2020-11-12 17:54:08,767] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 17:54:08,768] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 17:54:08,773] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:52:00+00:00 [scheduled]>
[2020-11-12 17:54:08,781] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:52:00+00:00 [queued]>
[2020-11-12 17:54:08,782] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 10, 52, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 17:54:08,782] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T10:52:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 17:54:22,775] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 10:52:00+00:00 exited with status success for try_number 1
[2020-11-12 17:56:06,867] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:54:00+00:00 [scheduled]>
[2020-11-12 17:56:06,877] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 17:56:06,877] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 17:56:06,886] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:54:00+00:00 [scheduled]>
[2020-11-12 17:56:06,898] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:54:00+00:00 [queued]>
[2020-11-12 17:56:06,898] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 10, 54, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 17:56:06,899] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T10:54:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 17:56:20,870] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 10:54:00+00:00 exited with status success for try_number 1
[2020-11-12 17:58:04,969] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:56:00+00:00 [scheduled]>
[2020-11-12 17:58:04,971] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 17:58:04,971] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 17:58:04,973] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:56:00+00:00 [scheduled]>
[2020-11-12 17:58:04,980] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:56:00+00:00 [queued]>
[2020-11-12 17:58:04,980] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 10, 56, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 17:58:04,980] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T10:56:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 17:58:18,983] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 10:56:00+00:00 exited with status success for try_number 1
[2020-11-12 18:00:03,077] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:58:00+00:00 [scheduled]>
[2020-11-12 18:00:03,079] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 18:00:03,079] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 18:00:03,081] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:58:00+00:00 [scheduled]>
[2020-11-12 18:00:03,088] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 10:58:00+00:00 [queued]>
[2020-11-12 18:00:03,089] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 10, 58, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 18:00:03,089] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T10:58:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 18:00:17,095] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 10:58:00+00:00 exited with status success for try_number 1
[2020-11-12 18:02:03,208] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 11:00:00+00:00 [scheduled]>
[2020-11-12 18:02:03,218] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 18:02:03,218] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 18:02:03,227] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 11:00:00+00:00 [scheduled]>
[2020-11-12 18:02:03,241] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 11:00:00+00:00 [queued]>
[2020-11-12 18:02:03,242] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 11, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 18:02:03,242] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T11:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 18:02:15,204] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 11:00:00+00:00 exited with status success for try_number 1
[2020-11-12 18:04:13,319] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 11:02:00+00:00 [scheduled]>
[2020-11-12 18:04:13,322] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 18:04:13,322] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 18:04:13,325] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 11:02:00+00:00 [scheduled]>
[2020-11-12 18:04:13,334] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 11:02:00+00:00 [queued]>
[2020-11-12 18:04:13,335] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 11, 2, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 18:04:13,335] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T11:02:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 18:04:27,329] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 11:02:00+00:00 exited with status success for try_number 1
[2020-11-12 18:06:13,440] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 11:04:00+00:00 [scheduled]>
[2020-11-12 18:06:13,450] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 18:06:13,450] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 18:06:13,459] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 11:04:00+00:00 [scheduled]>
[2020-11-12 18:06:13,473] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 11:04:00+00:00 [queued]>
[2020-11-12 18:06:13,474] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 11, 4, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 18:06:13,474] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T11:04:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 18:06:25,439] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 11:04:00+00:00 exited with status success for try_number 1
[2020-11-12 18:08:11,554] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 11:06:00+00:00 [scheduled]>
[2020-11-12 18:08:11,564] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 18:08:11,565] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 18:08:11,575] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 11:06:00+00:00 [scheduled]>
[2020-11-12 18:08:11,590] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 11:06:00+00:00 [queued]>
[2020-11-12 18:08:11,591] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 11, 6, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 18:08:11,592] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T11:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 18:08:25,570] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 11:06:00+00:00 exited with status success for try_number 1
[2020-11-12 18:10:09,650] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 11:08:00+00:00 [scheduled]>
[2020-11-12 18:10:09,653] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-12 18:10:09,653] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-12 18:10:09,655] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 11:08:00+00:00 [scheduled]>
[2020-11-12 18:10:09,662] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-12 11:08:00+00:00 [queued]>
[2020-11-12 18:10:09,662] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 12, 11, 8, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-12 18:10:09,663] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-12T11:08:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-12 18:10:23,678] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-12 11:08:00+00:00 exited with status success for try_number 1
Process DagFileProcessor10696-Process:
Traceback (most recent call last):
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 493, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/__init__.py", line 85, in Connect
    return Connection(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/connections.py", line 208, in __init__
    super(Connection, self).__init__(*args, **kwargs2)
_mysql_exceptions.OperationalError: (2006, "Lost connection to MySQL server at 'reading initial communication packet', system error: 104")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/jobs/scheduler_job.py", line 157, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/jobs/scheduler_job.py", line 1609, in process_file
    dag.sync_to_db()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/models/dag.py", line 1514, in sync_to_db
    orm_dag = session.query(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3429, in first
    ret = list(self[0:1])
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3203, in __getitem__
    return list(res)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3535, in __iter__
    return self._execute_and_instances(context)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3556, in _execute_and_instances
    conn = self._get_bind_args(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3571, in _get_bind_args
    return fn(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3550, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1138, in connection
    return self._connection_for_bind(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1146, in _connection_for_bind
    return self.transaction._connection_for_bind(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 433, in _connection_for_bind
    conn = bind._contextual_connect()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2302, in _contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2339, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1583, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
Process DagFileProcessor10697-Process:
Traceback (most recent call last):
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 493, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/__init__.py", line 85, in Connect
    return Connection(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/connections.py", line 208, in __init__
    super(Connection, self).__init__(*args, **kwargs2)
_mysql_exceptions.OperationalError: (2006, "Lost connection to MySQL server at 'reading initial communication packet', system error: 104")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/jobs/scheduler_job.py", line 157, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/jobs/scheduler_job.py", line 1609, in process_file
    dag.sync_to_db()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/models/dag.py", line 1514, in sync_to_db
    orm_dag = session.query(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3429, in first
    ret = list(self[0:1])
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3203, in __getitem__
    return list(res)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3535, in __iter__
    return self._execute_and_instances(context)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3556, in _execute_and_instances
    conn = self._get_bind_args(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3571, in _get_bind_args
    return fn(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3550, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1138, in connection
    return self._connection_for_bind(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1146, in _connection_for_bind
    return self.transaction._connection_for_bind(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 433, in _connection_for_bind
    conn = bind._contextual_connect()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2302, in _contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2339, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1583, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 493, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/__init__.py", line 85, in Connect
    return Connection(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/connections.py", line 208, in __init__
    super(Connection, self).__init__(*args, **kwargs2)
sqlalchemy.exc.OperationalError: (_mysql_exceptions.OperationalError) (2006, "Lost connection to MySQL server at 'reading initial communication packet', system error: 104")
(Background on this error at: http://sqlalche.me/e/13/e3q8)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 493, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/__init__.py", line 85, in Connect
    return Connection(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/connections.py", line 208, in __init__
    super(Connection, self).__init__(*args, **kwargs2)
sqlalchemy.exc.OperationalError: (_mysql_exceptions.OperationalError) (2006, "Lost connection to MySQL server at 'reading initial communication packet', system error: 104")
(Background on this error at: http://sqlalche.me/e/13/e3q8)
Process DagFileProcessor10698-Process:
Traceback (most recent call last):
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 493, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/__init__.py", line 85, in Connect
    return Connection(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/connections.py", line 208, in __init__
    super(Connection, self).__init__(*args, **kwargs2)
_mysql_exceptions.OperationalError: (2006, "Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/jobs/scheduler_job.py", line 157, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/jobs/scheduler_job.py", line 1609, in process_file
    dag.sync_to_db()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/models/dag.py", line 1514, in sync_to_db
    orm_dag = session.query(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3429, in first
    ret = list(self[0:1])
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3203, in __getitem__
    return list(res)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3535, in __iter__
    return self._execute_and_instances(context)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3556, in _execute_and_instances
    conn = self._get_bind_args(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3571, in _get_bind_args
    return fn(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3550, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1138, in connection
    return self._connection_for_bind(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1146, in _connection_for_bind
    return self.transaction._connection_for_bind(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 433, in _connection_for_bind
    conn = bind._contextual_connect()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2302, in _contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2339, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1583, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
Process DagFileProcessor10699-Process:
Traceback (most recent call last):
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 493, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/__init__.py", line 85, in Connect
    return Connection(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/connections.py", line 208, in __init__
    super(Connection, self).__init__(*args, **kwargs2)
_mysql_exceptions.OperationalError: (2006, "Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/jobs/scheduler_job.py", line 157, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/jobs/scheduler_job.py", line 1609, in process_file
    dag.sync_to_db()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/models/dag.py", line 1514, in sync_to_db
    orm_dag = session.query(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3429, in first
    ret = list(self[0:1])
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3203, in __getitem__
    return list(res)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3535, in __iter__
    return self._execute_and_instances(context)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3556, in _execute_and_instances
    conn = self._get_bind_args(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3571, in _get_bind_args
    return fn(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3550, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1138, in connection
    return self._connection_for_bind(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1146, in _connection_for_bind
    return self.transaction._connection_for_bind(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 433, in _connection_for_bind
    conn = bind._contextual_connect()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2302, in _contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2339, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1583, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 493, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/__init__.py", line 85, in Connect
    return Connection(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/connections.py", line 208, in __init__
    super(Connection, self).__init__(*args, **kwargs2)
sqlalchemy.exc.OperationalError: (_mysql_exceptions.OperationalError) (2006, "Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)")
(Background on this error at: http://sqlalche.me/e/13/e3q8)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 493, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/__init__.py", line 85, in Connect
    return Connection(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/connections.py", line 208, in __init__
    super(Connection, self).__init__(*args, **kwargs2)
sqlalchemy.exc.OperationalError: (_mysql_exceptions.OperationalError) (2006, "Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)")
(Background on this error at: http://sqlalche.me/e/13/e3q8)
Process ForkProcess-1:
Traceback (most recent call last):
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1276, in _execute_context
    self.dialect.do_execute(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/cursors.py", line 255, in execute
    self.errorhandler(self, exc, value)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/connections.py", line 50, in defaulterrorhandler
    raise errorvalue
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/cursors.py", line 252, in execute
    res = self._query(query)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/cursors.py", line 378, in _query
    db.query(q)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/connections.py", line 280, in query
    _mysql.connection.query(self, query)
_mysql_exceptions.OperationalError: (2006, 'MySQL server has gone away')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/utils/dag_processing.py", line 634, in _run_processor_manager
    processor_manager.start()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/utils/dag_processing.py", line 875, in start
    self._find_zombies()  # pylint: disable=no-value-for-parameter
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/utils/dag_processing.py", line 1319, in _find_zombies
    session.query(TI)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3373, in all
    return list(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3535, in __iter__
    return self._execute_and_instances(context)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3560, in _execute_and_instances
    result = conn.execute(querycontext.statement, self._params)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1124, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1316, in _execute_context
    self._handle_dbapi_exception(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1510, in _handle_dbapi_exception
    util.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1276, in _execute_context
    self.dialect.do_execute(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/cursors.py", line 255, in execute
    self.errorhandler(self, exc, value)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/connections.py", line 50, in defaulterrorhandler
    raise errorvalue
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/cursors.py", line 252, in execute
    res = self._query(query)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/cursors.py", line 378, in _query
    db.query(q)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/connections.py", line 280, in query
    _mysql.connection.query(self, query)
sqlalchemy.exc.OperationalError: (_mysql_exceptions.OperationalError) (2006, 'MySQL server has gone away')
[SQL: SELECT task_instance.try_number AS task_instance_try_number, task_instance.task_id AS task_instance_task_id, task_instance.dag_id AS task_instance_dag_id, task_instance.execution_date AS task_instance_execution_date, task_instance.start_date AS task_instance_start_date, task_instance.end_date AS task_instance_end_date, task_instance.duration AS task_instance_duration, task_instance.state AS task_instance_state, task_instance.max_tries AS task_instance_max_tries, task_instance.hostname AS task_instance_hostname, task_instance.unixname AS task_instance_unixname, task_instance.job_id AS task_instance_job_id, task_instance.pool AS task_instance_pool, task_instance.pool_slots AS task_instance_pool_slots, task_instance.queue AS task_instance_queue, task_instance.priority_weight AS task_instance_priority_weight, task_instance.operator AS task_instance_operator, task_instance.queued_dttm AS task_instance_queued_dttm, task_instance.pid AS task_instance_pid, task_instance.executor_config AS task_instance_executor_config 
FROM task_instance INNER JOIN job ON task_instance.job_id = job.id AND job.job_type IN (%s) 
WHERE task_instance.state = %s AND (job.state != %s OR job.latest_heartbeat < %s)]
[parameters: ('LocalTaskJob', 'running', 'running', datetime.datetime(2020, 11, 12, 11, 6, 51, 459264))]
(Background on this error at: http://sqlalche.me/e/13/e3q8)
[2020-11-12 18:11:51,735] {dag_processing.py:671} WARNING - DagFileProcessorManager (PID=33012) exited with exit code 1 - re-launching
[2020-11-12 18:11:51,741] {dag_processing.py:562} INFO - Launched DagFileProcessorManager with pid: 62835
[2020-11-12 18:11:51,752] {settings.py:55} INFO - Configured default timezone <Timezone [UTC]>
[2020-11-12 18:11:51,757] {base_job.py:202} ERROR - SchedulerJob heartbeat got an exception
Traceback (most recent call last):
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1276, in _execute_context
    self.dialect.do_execute(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/cursors.py", line 255, in execute
    self.errorhandler(self, exc, value)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/connections.py", line 50, in defaulterrorhandler
    raise errorvalue
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/cursors.py", line 252, in execute
    res = self._query(query)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/cursors.py", line 378, in _query
    db.query(q)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/connections.py", line 280, in query
    _mysql.connection.query(self, query)
_mysql_exceptions.OperationalError: (2006, 'MySQL server has gone away')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/jobs/base_job.py", line 172, in heartbeat
    session.merge(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 2162, in merge
    return self._merge(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 2240, in _merge
    merged = self.query(mapper.class_).get(key[1])
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 1018, in get
    return self._get_impl(ident, loading.load_on_pk_identity)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 1135, in _get_impl
    return db_load_fn(self, primary_key_identity)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/loading.py", line 286, in load_on_pk_identity
    return q.one()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3490, in one
    ret = self.one_or_none()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3459, in one_or_none
    ret = list(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3535, in __iter__
    return self._execute_and_instances(context)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3560, in _execute_and_instances
    result = conn.execute(querycontext.statement, self._params)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1124, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1316, in _execute_context
    self._handle_dbapi_exception(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1510, in _handle_dbapi_exception
    util.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1276, in _execute_context
    self.dialect.do_execute(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/cursors.py", line 255, in execute
    self.errorhandler(self, exc, value)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/connections.py", line 50, in defaulterrorhandler
    raise errorvalue
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/cursors.py", line 252, in execute
    res = self._query(query)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/cursors.py", line 378, in _query
    db.query(q)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/connections.py", line 280, in query
    _mysql.connection.query(self, query)
sqlalchemy.exc.OperationalError: (_mysql_exceptions.OperationalError) (2006, 'MySQL server has gone away')
[SQL: SELECT job.id AS job_id, job.dag_id AS job_dag_id, job.state AS job_state, job.job_type AS job_job_type, job.start_date AS job_start_date, job.end_date AS job_end_date, job.latest_heartbeat AS job_latest_heartbeat, job.executor_class AS job_executor_class, job.hostname AS job_hostname, job.unixname AS job_unixname 
FROM job 
WHERE job.id = %s AND job.job_type IN (%s)]
[parameters: (990, 'SchedulerJob')]
(Background on this error at: http://sqlalche.me/e/13/e3q8)
Process ForkProcess-250:
Traceback (most recent call last):
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 493, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/__init__.py", line 85, in Connect
    return Connection(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/connections.py", line 208, in __init__
    super(Connection, self).__init__(*args, **kwargs2)
_mysql_exceptions.OperationalError: (2006, "Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/utils/dag_processing.py", line 634, in _run_processor_manager
    processor_manager.start()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/utils/dag_processing.py", line 875, in start
    self._find_zombies()  # pylint: disable=no-value-for-parameter
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/utils/dag_processing.py", line 1319, in _find_zombies
    session.query(TI)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3373, in all
    return list(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3535, in __iter__
    return self._execute_and_instances(context)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3556, in _execute_and_instances
    conn = self._get_bind_args(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3571, in _get_bind_args
    return fn(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3550, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1138, in connection
    return self._connection_for_bind(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1146, in _connection_for_bind
    return self.transaction._connection_for_bind(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 433, in _connection_for_bind
    conn = bind._contextual_connect()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2302, in _contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2339, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1583, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 493, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/__init__.py", line 85, in Connect
    return Connection(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/connections.py", line 208, in __init__
    super(Connection, self).__init__(*args, **kwargs2)
sqlalchemy.exc.OperationalError: (_mysql_exceptions.OperationalError) (2006, "Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)")
(Background on this error at: http://sqlalche.me/e/13/e3q8)
[2020-11-12 18:11:52,565] {helpers.py:325} INFO - Sending Signals.SIGTERM to GPID 62835
[2020-11-12 18:11:52,565] {helpers.py:291} INFO - Process psutil.Process(pid=62835, status='terminated', exitcode=1, started='18:11:51') (62835) terminated with exit code 1
[2020-11-12 18:11:52,566] {scheduler_job.py:1404} INFO - Exited execute loop
Traceback (most recent call last):
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 500, in checkout
    rec._checkin_failed(err)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 497, in checkout
    dbapi_connection = rec.get_connection()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 610, in get_connection
    self.__connect()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 493, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/__init__.py", line 85, in Connect
    return Connection(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/connections.py", line 208, in __init__
    super(Connection, self).__init__(*args, **kwargs2)
_mysql_exceptions.OperationalError: (2006, "Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/bin/airflow", line 37, in <module>
    args.func(args)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/utils/cli.py", line 76, in wrapper
    return f(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/bin/cli.py", line 1221, in scheduler
    job.run()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/airflow/jobs/base_job.py", line 229, in run
    session.merge(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 2162, in merge
    return self._merge(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 2240, in _merge
    merged = self.query(mapper.class_).get(key[1])
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 1018, in get
    return self._get_impl(ident, loading.load_on_pk_identity)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 1135, in _get_impl
    return db_load_fn(self, primary_key_identity)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/loading.py", line 286, in load_on_pk_identity
    return q.one()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3490, in one
    ret = self.one_or_none()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3459, in one_or_none
    ret = list(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3535, in __iter__
    return self._execute_and_instances(context)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3556, in _execute_and_instances
    conn = self._get_bind_args(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3571, in _get_bind_args
    return fn(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3550, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1138, in connection
    return self._connection_for_bind(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1146, in _connection_for_bind
    return self.transaction._connection_for_bind(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 433, in _connection_for_bind
    conn = bind._contextual_connect()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2302, in _contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2339, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1583, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 500, in checkout
    rec._checkin_failed(err)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 497, in checkout
    dbapi_connection = rec.get_connection()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 610, in get_connection
    self.__connect()
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.raise_(
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 493, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/__init__.py", line 85, in Connect
    return Connection(*args, **kwargs)
  File "/home/nvt/.local/share/virtualenvs/test_airflow-kPS7EYZo/lib/python3.8/site-packages/MySQLdb/connections.py", line 208, in __init__
    super(Connection, self).__init__(*args, **kwargs2)
sqlalchemy.exc.OperationalError: (_mysql_exceptions.OperationalError) (2006, "Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)")
(Background on this error at: http://sqlalche.me/e/13/e3q8)
WARNING:root:/home/nvt/PycharmProjects/test_airflow/logs/scheduler/2020-11-13 already exists
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2020-11-13 09:41:30,699] {__init__.py:50} INFO - Using executor CeleryExecutor
[2020-11-13 09:41:30,721] {scheduler_job.py:1367} INFO - Starting the scheduler
[2020-11-13 09:41:30,721] {scheduler_job.py:1375} INFO - Running execute loop for -1 seconds
[2020-11-13 09:41:30,721] {scheduler_job.py:1376} INFO - Processing each file at most -1 times
[2020-11-13 09:41:30,721] {scheduler_job.py:1379} INFO - Searching for files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-13 09:41:30,757] {scheduler_job.py:1381} INFO - There are 27 files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-13 09:41:30,757] {scheduler_job.py:1438} INFO - Resetting orphaned tasks for active dag runs
[2020-11-13 09:41:30,768] {dag_processing.py:562} INFO - Launched DagFileProcessorManager with pid: 29145
[2020-11-13 09:41:30,771] {settings.py:55} INFO - Configured default timezone <Timezone [UTC]>
[2020-11-13 09:41:54,802] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 02:38:00+00:00 [scheduled]>
[2020-11-13 09:41:54,806] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-13 09:41:54,807] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-13 09:41:54,809] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 02:38:00+00:00 [scheduled]>
[2020-11-13 09:41:54,816] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 02:38:00+00:00 [queued]>
[2020-11-13 09:41:54,817] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 13, 2, 38, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-13 09:41:54,817] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-13T02:38:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-13 09:42:06,812] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 02:40:00+00:00 [scheduled]>
[2020-11-13 09:42:06,816] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-13 09:42:06,816] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-13 09:42:06,819] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 02:40:00+00:00 [scheduled]>
[2020-11-13 09:42:06,827] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 02:40:00+00:00 [queued]>
[2020-11-13 09:42:06,827] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 13, 2, 40, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-13 09:42:06,827] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-13T02:40:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-13 09:42:06,874] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-13 02:38:00+00:00 exited with status success for try_number 1
[2020-11-13 09:42:20,841] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-13 02:40:00+00:00 exited with status success for try_number 1
[2020-11-13 09:44:04,942] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 02:42:00+00:00 [scheduled]>
[2020-11-13 09:44:04,952] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-13 09:44:04,952] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-13 09:44:04,961] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 02:42:00+00:00 [scheduled]>
[2020-11-13 09:44:04,974] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 02:42:00+00:00 [queued]>
[2020-11-13 09:44:04,974] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 13, 2, 42, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-13 09:44:04,975] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-13T02:42:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-13 09:44:18,957] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-13 02:42:00+00:00 exited with status success for try_number 1
[2020-11-13 09:46:03,037] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 02:44:00+00:00 [scheduled]>
[2020-11-13 09:46:03,041] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-13 09:46:03,041] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-13 09:46:03,045] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 02:44:00+00:00 [scheduled]>
[2020-11-13 09:46:03,053] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 02:44:00+00:00 [queued]>
[2020-11-13 09:46:03,054] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 13, 2, 44, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-13 09:46:03,054] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-13T02:44:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-13 09:46:17,066] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-13 02:44:00+00:00 exited with status success for try_number 1
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2020-11-13 09:47:24,978] {__init__.py:50} INFO - Using executor CeleryExecutor
[2020-11-13 09:47:24,987] {scheduler_job.py:1367} INFO - Starting the scheduler
[2020-11-13 09:47:24,987] {scheduler_job.py:1375} INFO - Running execute loop for -1 seconds
[2020-11-13 09:47:24,987] {scheduler_job.py:1376} INFO - Processing each file at most -1 times
[2020-11-13 09:47:24,987] {scheduler_job.py:1379} INFO - Searching for files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-13 09:47:24,989] {scheduler_job.py:1381} INFO - There are 27 files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-13 09:47:24,990] {scheduler_job.py:1438} INFO - Resetting orphaned tasks for active dag runs
[2020-11-13 09:47:24,995] {dag_processing.py:562} INFO - Launched DagFileProcessorManager with pid: 31480
[2020-11-13 09:47:24,998] {settings.py:55} INFO - Configured default timezone <Timezone [UTC]>
[2020-11-13 09:48:03,057] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 02:46:00+00:00 [scheduled]>
[2020-11-13 09:48:03,071] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-13 09:48:03,072] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-13 09:48:03,082] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 02:46:00+00:00 [scheduled]>
[2020-11-13 09:48:03,100] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 02:46:00+00:00 [queued]>
[2020-11-13 09:48:03,101] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 13, 2, 46, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-13 09:48:03,101] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-13T02:46:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-13 09:48:15,066] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-13 02:46:00+00:00 exited with status success for try_number 1
[2020-11-13 09:50:13,175] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 02:48:00+00:00 [scheduled]>
[2020-11-13 09:50:13,184] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-13 09:50:13,185] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-13 09:50:13,193] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 02:48:00+00:00 [scheduled]>
[2020-11-13 09:50:13,209] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 02:48:00+00:00 [queued]>
[2020-11-13 09:50:13,210] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 13, 2, 48, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-13 09:50:13,210] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-13T02:48:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-13 09:50:27,176] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-13 02:48:00+00:00 exited with status success for try_number 1
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2020-11-13 09:59:54,275] {__init__.py:50} INFO - Using executor CeleryExecutor
[2020-11-13 09:59:54,282] {scheduler_job.py:1367} INFO - Starting the scheduler
[2020-11-13 09:59:54,282] {scheduler_job.py:1375} INFO - Running execute loop for -1 seconds
[2020-11-13 09:59:54,282] {scheduler_job.py:1376} INFO - Processing each file at most -1 times
[2020-11-13 09:59:54,283] {scheduler_job.py:1379} INFO - Searching for files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-13 09:59:54,285] {scheduler_job.py:1381} INFO - There are 27 files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-13 09:59:54,285] {scheduler_job.py:1438} INFO - Resetting orphaned tasks for active dag runs
[2020-11-13 09:59:54,291] {dag_processing.py:562} INFO - Launched DagFileProcessorManager with pid: 34617
[2020-11-13 09:59:54,293] {settings.py:55} INFO - Configured default timezone <Timezone [UTC]>
[2020-11-13 10:00:02,329] {scheduler_job.py:961} INFO - 3 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 02:46:00+00:00 [scheduled]>
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 02:48:00+00:00 [scheduled]>
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 02:56:00+00:00 [scheduled]>
[2020-11-13 10:00:02,341] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 3 task instances ready to be queued
[2020-11-13 10:00:02,342] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-13 10:00:02,342] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 1/16 running and queued tasks
[2020-11-13 10:00:02,343] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 2/16 running and queued tasks
[2020-11-13 10:00:02,348] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 02:46:00+00:00 [scheduled]>
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 02:48:00+00:00 [scheduled]>
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 02:56:00+00:00 [scheduled]>
[2020-11-13 10:00:02,363] {scheduler_job.py:1158} INFO - Setting the following 3 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 02:46:00+00:00 [queued]>
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 02:48:00+00:00 [queued]>
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 02:56:00+00:00 [queued]>
[2020-11-13 10:00:02,364] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 13, 2, 46, tzinfo=<Timezone [UTC]>), 2) to executor with priority 1 and queue test_airflow_queue
[2020-11-13 10:00:02,364] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-13T02:46:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-13 10:00:02,365] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 13, 2, 48, tzinfo=<Timezone [UTC]>), 2) to executor with priority 1 and queue test_airflow_queue
[2020-11-13 10:00:02,365] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-13T02:48:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-13 10:00:02,365] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 13, 2, 56, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-13 10:00:02,365] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-13T02:56:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-13 10:00:16,323] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 02:58:00+00:00 [scheduled]>
[2020-11-13 10:00:16,329] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-13 10:00:16,329] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-13 10:00:16,333] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 02:58:00+00:00 [scheduled]>
[2020-11-13 10:00:16,341] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 02:58:00+00:00 [queued]>
[2020-11-13 10:00:16,341] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 13, 2, 58, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-13 10:00:16,342] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-13T02:58:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-13 10:00:16,405] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-13 02:46:00+00:00 exited with status success for try_number 2
[2020-11-13 10:00:16,409] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-13 02:48:00+00:00 exited with status success for try_number 2
[2020-11-13 10:00:16,411] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-13 02:56:00+00:00 exited with status success for try_number 1
[2020-11-13 10:00:28,348] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-13 02:58:00+00:00 exited with status success for try_number 1
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2020-11-13 10:01:19,818] {__init__.py:50} INFO - Using executor CeleryExecutor
[2020-11-13 10:01:19,824] {scheduler_job.py:1367} INFO - Starting the scheduler
[2020-11-13 10:01:19,825] {scheduler_job.py:1375} INFO - Running execute loop for -1 seconds
[2020-11-13 10:01:19,825] {scheduler_job.py:1376} INFO - Processing each file at most -1 times
[2020-11-13 10:01:19,825] {scheduler_job.py:1379} INFO - Searching for files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-13 10:01:19,828] {scheduler_job.py:1381} INFO - There are 27 files in /home/nvt/PycharmProjects/test_airflow/dags
[2020-11-13 10:01:19,828] {scheduler_job.py:1438} INFO - Resetting orphaned tasks for active dag runs
[2020-11-13 10:01:19,834] {dag_processing.py:562} INFO - Launched DagFileProcessorManager with pid: 35324
[2020-11-13 10:01:19,837] {settings.py:55} INFO - Configured default timezone <Timezone [UTC]>
[2020-11-13 10:02:07,892] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 03:00:00+00:00 [scheduled]>
[2020-11-13 10:02:07,901] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-13 10:02:07,901] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-13 10:02:07,908] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 03:00:00+00:00 [scheduled]>
[2020-11-13 10:02:07,921] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 03:00:00+00:00 [queued]>
[2020-11-13 10:02:07,922] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 13, 3, 0, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-13 10:02:07,922] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-13T03:00:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-13 10:02:21,912] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-13 03:00:00+00:00 exited with status success for try_number 1
[2020-11-13 10:04:07,997] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 03:02:00+00:00 [scheduled]>
[2020-11-13 10:04:07,999] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-13 10:04:07,999] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-13 10:04:08,001] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 03:02:00+00:00 [scheduled]>
[2020-11-13 10:04:08,009] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 03:02:00+00:00 [queued]>
[2020-11-13 10:04:08,009] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 13, 3, 2, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-13 10:04:08,009] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-13T03:02:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
[2020-11-13 10:04:20,029] {scheduler_job.py:1331} INFO - Executor reports execution of aggregate_action_user.get_user_action execution_date=2020-11-13 03:02:00+00:00 exited with status success for try_number 1
[2020-11-13 10:06:06,123] {scheduler_job.py:961} INFO - 1 tasks up for execution:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 03:04:00+00:00 [scheduled]>
[2020-11-13 10:06:06,133] {scheduler_job.py:994} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2020-11-13 10:06:06,133] {scheduler_job.py:1023} INFO - DAG aggregate_action_user has 0/16 running and queued tasks
[2020-11-13 10:06:06,140] {scheduler_job.py:1084} INFO - Setting the following tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 03:04:00+00:00 [scheduled]>
[2020-11-13 10:06:06,149] {scheduler_job.py:1158} INFO - Setting the following 1 tasks to queued state:
	<TaskInstance: aggregate_action_user.get_user_action 2020-11-13 03:04:00+00:00 [queued]>
[2020-11-13 10:06:06,150] {scheduler_job.py:1193} INFO - Sending ('aggregate_action_user', 'get_user_action', datetime.datetime(2020, 11, 13, 3, 4, tzinfo=<Timezone [UTC]>), 1) to executor with priority 1 and queue test_airflow_queue
[2020-11-13 10:06:06,150] {base_executor.py:58} INFO - Adding to queue: ['airflow', 'run', 'aggregate_action_user', 'get_user_action', '2020-11-13T03:04:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/nvt/PycharmProjects/test_airflow/dags/aggregate_action_user.py']
